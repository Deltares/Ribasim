[
  {
    "objectID": "known_issues.html",
    "href": "known_issues.html",
    "title": "Known issues",
    "section": "",
    "text": "Known issues can be found on the GitHub issues page. Besides the issues that need to be fixed, there are also considerations that had to be made while developing the application.\n\n1 Core\n\nThe non-default solver option sparse = false doesn’t currently work.\n\n\n\n2 QGIS plugin\n\nInput tables that are in Arrow files are currently not automatically loaded in QGIS (#318).\nResults in NetCDF format are currently not automatically loaded in QGIS (#2519).",
    "crumbs": [
      "Overview",
      "Known issues"
    ]
  },
  {
    "objectID": "getting-started/tutorial/natural-flow.html",
    "href": "getting-started/tutorial/natural-flow.html",
    "title": "Natural flow",
    "section": "",
    "text": "from ribasim import run_ribasim",
    "crumbs": [
      "Getting started",
      "Tutorials",
      "Natural flow"
    ]
  },
  {
    "objectID": "getting-started/tutorial/natural-flow.html#learning-objectives",
    "href": "getting-started/tutorial/natural-flow.html#learning-objectives",
    "title": "Natural flow",
    "section": "1.1 Learning objectives",
    "text": "1.1 Learning objectives\nIn this tutorial, we will focus on a fictional river basin called Crystal, which will serve as our case study. The guide is divided into different modules, each covering various scenarios. These include simulating natural flow, implementing reservoirs, and observing the impact of other structures. While not all node types and possibilities will be demonstrated, the focus will be on the most commonly used and significant situations. By the end of the tutorial, users will be able to:\n\nSet up a basic Ribasim model: Understand how to create a new model for a river basin using the Ribasim Python package.\nEvaluate the impact of demands: Introduce water demand (such as irrigation) and assess their effects on the river basin.\nModify and update models: Learn how to update existing models with new data and changes.\nAnalyze simulation results: Use built-in tools to analyze and interpret the results of your simulations.",
    "crumbs": [
      "Getting started",
      "Tutorials",
      "Natural flow"
    ]
  },
  {
    "objectID": "getting-started/tutorial/natural-flow.html#natural-flow",
    "href": "getting-started/tutorial/natural-flow.html#natural-flow",
    "title": "Natural flow",
    "section": "2.1 Natural flow",
    "text": "2.1 Natural flow\n\n2.1.1 Import packages\nBefore building the model we need to import some modules. Open your favorite Python editor (Visual Studio Code, Jupyter, …) and create a new script or notebook and name it Crystal_1.1 and save it into your model folder Crystal_Basin. Import the following modules in Python:\n\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom ribasim import Model, Node\nfrom ribasim.nodes import basin, flow_boundary, tabulated_rating_curve\nfrom shapely.geometry import Point\n\n\n\n2.1.2 Setup paths and model configuration\nReference the paths of the Ribasim installation and model directory and define the time period. The used simulation period is defined by the starttime and endtime of the model, not by the input timeseries. For now we will look into the period from 2022-01-01 until 2023-01-01 for the model simulation. The coordinate reference system (CRS) is also required, and set to EPSG:4326, which means all coordinates are interpreted as latitude and longitude values. The CRS is important for correctly placing Ribasim models on the map, but since this is a fictional model, it is not important.\n\nbase_dir = Path(\"crystal-basin\")\n\nstarttime = \"2022-01-01\"\nendtime = \"2023-01-01\"\nmodel = Model(\n    starttime=starttime,\n    endtime=endtime,\n    crs=\"EPSG:4326\",\n)\n\n\n\n2.1.3 FlowBoundary nodes\nThe Crystal basin consists of two inflow points, the tributary and the main Crystal river, we will call them Minor and Main respectively. This is a monthly inflow timeseries from 2014 to 2023. The used simulation period is defined by the starttime and endtime of the model, not by the input timeseries.\n\ndata = pd.DataFrame({\n    \"time\": pd.date_range(start=\"2022-01-01\", end=\"2023-01-01\", freq=\"MS\"),\n    \"main\": [74.7, 57.9, 63.2, 183.9, 91.8, 47.5, 32.6, 27.6, 26.5, 25.1, 39.3, 37.8, 57.9],\n    \"minor\": [16.3, 3.8, 3.0, 37.6, 18.2, 11.1, 12.9, 12.2, 11.2, 10.8, 15.1, 14.3, 11.8]\n})  # fmt: skip\ndata[\"total\"] = data[\"minor\"] + data[\"main\"]\ndisplay(data)\n\n# Average and max inflow of the total inflow data over 2022\nprint(\"Average inflow [m3/s]:\", data[\"total\"].mean())\nprint(\"Maximum inflow [m3/s]:\", data[\"total\"].max())\n\nmain = model.flow_boundary.add(\n    Node(1, Point(0.0, 0.0), name=\"main\"),\n    [\n        flow_boundary.Time(\n            time=data.time,\n            flow_rate=data.main,\n        )\n    ],\n)\n\nminor = model.flow_boundary.add(\n    Node(2, Point(-3.0, 0.0), name=\"minor\"),\n    [\n        flow_boundary.Time(\n            time=data.time,\n            flow_rate=data.minor,\n        )\n    ],\n)\n\n\n\n\n\n\n\n\ntime\nmain\nminor\ntotal\n\n\n\n\n0\n2022-01-01\n74.7\n16.3\n91.0\n\n\n1\n2022-02-01\n57.9\n3.8\n61.7\n\n\n2\n2022-03-01\n63.2\n3.0\n66.2\n\n\n3\n2022-04-01\n183.9\n37.6\n221.5\n\n\n4\n2022-05-01\n91.8\n18.2\n110.0\n\n\n5\n2022-06-01\n47.5\n11.1\n58.6\n\n\n6\n2022-07-01\n32.6\n12.9\n45.5\n\n\n7\n2022-08-01\n27.6\n12.2\n39.8\n\n\n8\n2022-09-01\n26.5\n11.2\n37.7\n\n\n9\n2022-10-01\n25.1\n10.8\n35.9\n\n\n10\n2022-11-01\n39.3\n15.1\n54.4\n\n\n11\n2022-12-01\n37.8\n14.3\n52.1\n\n\n12\n2023-01-01\n57.9\n11.8\n69.7\n\n\n\n\n\n\n\nAverage inflow [m3/s]: 72.62307692307692\nMaximum inflow [m3/s]: 221.5\n\n\n\n\n2.1.4 Basin node (confluence)\nTo schematize the confluence from the tributary we will use the Basin node. The node by itself portrays as water storage with a certain volume of water and can be used for different purposes, such as a reservoir, river reach, lake or in this case a confluence. Figure 2 visualizes a cross section of the confluence point in our model.\n\n\n\n\n\n\nFigure 2: Basin node concept for the confluence\n\n\n\nTable 1 shows the input data for the Basin node profile.\n\n\n\nTable 1: Profile data for the basin node\n\n\n\n\n\nArea [\\(\\text{m}^2\\)]\nLevel [\\(\\text{m}\\)]\n\n\n\n\n\\(672000.0\\)\n\\(0.0\\)\n\n\n\\(5600000.0\\)\n\\(6.0\\)\n\n\n\n\n\n\nWhilst in this case the level starts at \\(0.0\\) and therefore happens to be the same as the depth, it should never be interpreted as a depth. All water levels in Ribasim are assumed to be with respect to a shared reference datum, like mean sea level (MSL). The first water level in the profile is the height of the Basin bottom above this reference datum.\nTo specify the Basin profile, the following code is used:\n\nconfluence = model.basin.add(\n    Node(3, Point(-1.5, -1), name=\"confluence\"),\n    [\n        basin.Profile(area=[672000, 5600000], level=[0, 6]),\n        basin.State(level=[4]),\n        basin.Time(time=[starttime, endtime]),\n    ],\n)\n\n\n\n2.1.5 TabulatedRatingCurve\nIn the previous step we implemented a Basin node that functions as a confluence. Conceptually, the Basin acts as a store of water, accumulating inflows and then releasing them. A Basin cannot directly connect to another Basin, because the rules for water exchange between them need to be defined. Connector nodes take care of this. The first such node we introduce is the TabulatedRatingCurve. It defines a relation between the water level (\\(h\\)) in the Basin and the outflow (\\(Q\\)) from the Basin. This setup mimics the behavior of a gate or spillway, allowing us to model how varying water levels influence flow rates at the confluence.\nAs the two inflows come together at the confluence, we expect, as mentioned above, a discharge average of \\(44.45 \\text{ m}^3/\\text{s}\\). It is therefore expected that the confluence Basin goes towards a level where the outflow is equal to the inflow via the rating curve. Only then is the confluence Basin in equilibrium. The maximum depth of the river is \\(6 \\text{ m}\\), and the maximum inflow is \\(221.5 \\text{ m}^3/\\text{s}\\) The \\(Q(h)\\) relationship in Table 2 allows such inflows with reasonable water levels.\n\n\n\nTable 2: Input data for the Tabulated Rating Curve\n\n\n\n\n\n\n\n\n\nWater Level (\\(h\\)) [\\(\\text{m}\\)]\nOutflow (\\(Q\\)) [\\(\\text{m}^3/\\text{s}\\)]\n\n\n\n\n\\(0.0\\)\n\\(0.0\\)\n\n\n\\(2.0\\)\n\\(50.0\\)\n\n\n\\(5.0\\)\n\\(200.0\\)\n\n\n\n\n\n\nIn Ribasim, the \\(Q(h)\\) relation is a piecewise linear function, so the points in between will be linearly interpolated. Figure 3 illustrates the visual process and shows a progressive increase in discharge with rising water levels. In this case this means:\n\nAt level \\(0.0\\): No discharge occurs. This represents a condition where the water level is too low for any flow to be discharged.\nAt level \\(2.0\\): Discharge is \\(50.0 \\text{ m}^3/\\text{s}\\). This is a bit above the average discharge rate, corresponding to the water level where normal flow conditions are established.\nAt level \\(5.0\\): Discharge rate reaches \\(200.0 \\text{ m}^3/\\text{s}\\). This discharge rate occurs at the water level during wet periods, indicating higher flow capacity.\n\n\n\n\n\n\n\nFigure 3: Discharge at corresponding water levels\n\n\n\nTaking this into account, add the TabulatedRatingCurve as follows:\n\nweir = model.tabulated_rating_curve.add(\n    Node(4, Point(-1.5, -1.5), name=\"weir\"),\n    [\n        tabulated_rating_curve.Static(\n            level=[0.0, 2, 5],\n            flow_rate=[0.0, 50, 200],\n        )\n    ],\n)\n\n\n\n2.1.6 Terminal node\nFinally all the water will discharge into the sea. We schematize this with the Terminal node, as it portrays the end point of the model, that can receive but not give water. Besides the node number/name and location, no further input is needed.\n\nsea = model.terminal.add(Node(5, Point(-1.5, -3.0), name=\"sea\"))\n\n\n\n2.1.7 Defining links\nImplement the connections (links) between the nodes.\n\nmodel.link.add(main, confluence, name=\"main\")\nmodel.link.add(minor, confluence, name=\"minor\")\nmodel.link.add(confluence, weir)\nmodel.link.add(weir, sea, name=\"sea\")\n\n\n\n2.1.8 Visualization and model execution\nPlot the schematization.\n\nmodel.plot();\n\n\n\n\n\n\n\n\nWrite the model configuration to the TOML file. Name the output file Crystal-1/ribasim.toml:\n\ntoml_path = base_dir / \"Crystal-1/ribasim.toml\"\nmodel.write(toml_path)\n\nPosixPath('crystal-basin/Crystal-1/ribasim.toml')\n\n\nAfter running model.write a subfolder Crystal-1 is created, which contains the model input data and configuration:\n\nribasim.toml: The model configuration\ndatabase.gpkg: A GeoPackage containing the network geometry and input data of the nodes used.\n\nNow run the model. You can open a terminal and run it from there. For example:\nribasim Crystal-1/ribasim.toml\nFrom Python you can run it with:\n\nrun_ribasim(toml_path)\n\n┌ Info: Starting a Ribasim simulation at 2026-01-23T16:43:19.040.\n│   toml_path = \"crystal-basin/Crystal-1/ribasim.toml\"\n│   cli.ribasim_version = \"2026.1.0-rc1\"\n│   starttime = 2022-01-01T00:00:00\n│   endtime = 2023-01-01T00:00:00\n└   threads = 1\nSimulating   0%|                                        |  ETA: N/A\nSimulating   1%|▋                                       |  ETA: 0:56:07\nSimulating   9%|███▌                                    |  ETA: 0:08:24\nSimulating  16%|██████▌                                 |  ETA: 0:04:15\nSimulating  25%|█████████▉                              |  ETA: 0:02:30\nSimulating  26%|██████████▎                             |  ETA: 0:02:23\nSimulating  33%|█████████████▏                          |  ETA: 0:01:41\nSimulating  35%|██████████████                          |  ETA: 0:01:31\nSimulating  42%|████████████████▉                       |  ETA: 0:01:08\nSimulating  50%|███████████████████▉                    |  ETA: 0:00:50\nSimulating  53%|█████████████████████▏                  |  ETA: 0:00:44\nSimulating  59%|███████████████████████▊                |  ETA: 0:00:34\nSimulating  67%|██████████████████████████▉             |  ETA: 0:00:24\nSimulating  76%|██████████████████████████████▎         |  ETA: 0:00:16\nSimulating  84%|█████████████████████████████████▍      |  ETA: 0:00:10\nSimulating  91%|████████████████████████████████████▍   |  ETA: 0:00:05\nSimulating  95%|█████████████████████████████████████▉  |  ETA: 0:00:03\nSimulating 100%|████████████████████████████████████████| Time: 0:00:49\n[ Info: Computation time: 24 seconds, 32 milliseconds\n[ Info: The model finished successfully at 2026-01-23T16:45:52.159.\n\n\nBy default it will search for ribasim in the PATH, but you can supply the ribasim_exe keyword argument which points to the ribasim executable: run_ribasim(toml_path, ribasim_exe=\"bin/ribasim/ribasim.exe\"). Use run_ribasim(version=True) to check the version.\n\n\n2.1.9 Post-processing results\nRead the Arrow files and plot the simulated flows from different links and the levels and storages at our confluence point:\n\ndf_basin = pd.read_feather(base_dir / \"Crystal-1/results/basin.arrow\")\n\n# Create pivot tables and plot for Basin data\ndf_basin_wide = df_basin.pivot_table(\n    index=\"time\", columns=\"node_id\", values=[\"storage\", \"level\"]\n)\n\n# Plot level and storage on the same graph with dual y-axes\nfig, ax1 = plt.subplots(figsize=(12, 6))\n\n# Plot level on the primary y-axis\ncolor = \"b\"\nax1.set_xlabel(\"Time\")\nax1.set_ylabel(\"Level [m]\", color=color)\nax1.plot(df_basin_wide.index, df_basin_wide[\"level\"], color=color)\nax1.tick_params(axis=\"y\", labelcolor=color)\n\n# Create a secondary y-axis for storage\nax2 = ax1.twinx()\ncolor = \"r\"\nax2.set_ylabel(\"Storage [m³]\", color=\"r\")\nax2.plot(df_basin_wide.index, df_basin_wide[\"storage\"], linestyle=\"--\", color=color)\nax2.tick_params(axis=\"y\", labelcolor=color)\n\nfig.tight_layout()  # Adjust layout to fit labels\nplt.title(\"Basin level and storage\")\nplt.show()\n\n\n\n\n\n\n\n\nThe figure above shows the storage and levels in the Basin node.\nTo accurately represent the relationship between water levels and discharge rates at this confluence, a TabulatedRatingCurve is used. This setup mimics the behavior of a gate or spillway, allowing us to model how varying water levels influence flow rates at the confluence. Since the basin node is functioning as a confluence rather than a storage reservoir, the simulated water levels and storage trends will closely follow the inflow patterns. This is because there is no net change in storage; all incoming water is balanced by outgoing flow.\n\n# Plot flow data\n# Read the flow results\ndf_flow = pd.read_feather(base_dir / \"Crystal-1/results/flow.arrow\")\n# Add the link names and then remove unnamed links\ndf_flow[\"name\"] = model.link.df[\"name\"].loc[df_flow[\"link_id\"]].to_numpy()\ndf_flow = df_flow[df_flow[\"name\"].astype(bool)]\n\n# Create a pivot table\npivot_flow = df_flow.pivot_table(index=\"time\", columns=\"name\", values=\"flow_rate\")\n\nline_styles = [\"-\", \"--\", \"-\", \"-.\"]\nnum_styles = len(line_styles)\n\nfig, ax = plt.subplots(figsize=(12, 6))\nfor i, column in enumerate(pivot_flow.columns):\n    pivot_flow[column].plot(\n        ax=ax, linestyle=line_styles[i % num_styles], linewidth=1.5, alpha=0.8\n    )\n\n# Set labels and title\nax.set_xlabel(\"Time\")\nax.set_ylabel(\"Flow [m³/s]\")\nax.legend(bbox_to_anchor=(1.15, 1), title=\"Link\")\nplt.title(\"Flow\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nThe figure above shows the discharges in \\(\\text{m}^3/\\text{s}\\) on each link.\nLink (3,4) represents the flow from the confluence to the TabulatedRatingCurve and link (4,5) represents the flow from the TabulatedRatingCurve to the Terminal. Both show the same discharge over time. Which is expected in a natural flow environment, as what is coming into the confluence must come out.",
    "crumbs": [
      "Getting started",
      "Tutorials",
      "Natural flow"
    ]
  },
  {
    "objectID": "getting-started/tutorial/reservoir.html",
    "href": "getting-started/tutorial/reservoir.html",
    "title": "Reservoir",
    "section": "",
    "text": "from ribasim import run_ribasim\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport plotly.express as px\nfrom ribasim import Model, Node\nfrom ribasim.nodes import (\n    basin,\n    flow_boundary,\n    tabulated_rating_curve,\n    user_demand,\n)\nfrom shapely.geometry import Point\nbase_dir = Path(\"crystal-basin\")\n\nstarttime = \"2022-01-01\"\nendtime = \"2023-01-01\"\nmodel = Model(\n    starttime=starttime,\n    endtime=endtime,\n    crs=\"EPSG:4326\",\n)\nThese nodes are identical to the previous tutorial:\n# FlowBoundary\ndata = pd.DataFrame({\n    \"time\": pd.date_range(start=\"2022-01-01\", end=\"2023-01-01\", freq=\"MS\"),\n    \"main\": [74.7, 57.9, 63.2, 183.9, 91.8, 47.5, 32.6, 27.6, 26.5, 25.1, 39.3, 37.8, 57.9],\n    \"minor\": [16.3, 3.8, 3.0, 37.6, 18.2, 11.1, 12.9, 12.2, 11.2, 10.8, 15.1, 14.3, 11.8]\n})  # fmt: skip\ndata[\"total\"] = data[\"minor\"] + data[\"main\"]\nmain = model.flow_boundary.add(\n    Node(1, Point(0.0, 0.0), name=\"main\"),\n    [\n        flow_boundary.Time(\n            time=data.time,\n            flow_rate=data.main,\n        )\n    ],\n)\nminor = model.flow_boundary.add(\n    Node(2, Point(-3.0, 0.0), name=\"minor\"),\n    [\n        flow_boundary.Time(\n            time=data.time,\n            flow_rate=data.minor,\n        )\n    ],\n)\n\n# Basin\nconfluence = model.basin.add(\n    Node(3, Point(-1.5, -1), name=\"confluence\"),\n    [\n        basin.Profile(area=[672000, 5600000], level=[0, 6]),\n        basin.State(level=[4]),\n        basin.Time(time=[starttime, endtime]),\n    ],\n)\n\n# TabulatedRatingCurve\nweir = model.tabulated_rating_curve.add(\n    Node(4, Point(-1.5, -1.5), name=\"weir\"),\n    [\n        tabulated_rating_curve.Static(\n            level=[0.0, 2, 5],\n            flow_rate=[0.0, 50, 200],\n        )\n    ],\n)\ndiversion_weir = model.tabulated_rating_curve.add(\n    Node(8, Point(-1.125, -0.75), name=\"diversion_weir\"),\n    [\n        tabulated_rating_curve.Static(\n            level=[0.0, 1.5, 5],\n            flow_rate=[0.0, 45, 200],\n        )\n    ],\n)\n\n# UserDemand\nirrigation = model.user_demand.add(\n    Node(7, Point(-1.5, 0.5), name=\"irrigation\"),\n    [\n        user_demand.Time(\n            demand=[0.0, 0.0, 10, 12, 12, 0.0],\n            return_factor=0,\n            min_level=0,\n            demand_priority=1,\n            time=[\n                starttime,\n                \"2022-03-31\",\n                \"2022-04-01\",\n                \"2022-07-01\",\n                \"2022-09-30\",\n                \"2022-10-01\",\n            ],\n        )\n    ],\n)\n\n# Terminal\nsea = model.terminal.add(Node(5, Point(-1.5, -3.0), name=\"sea\"))\nDue to the increase of population and climate change Crystal city has implemented a reservoir upstream to store water for domestic use (See Figure 1). The reservoir is to help ensure a reliable supply during dry periods. In this module, the user will update the model to incorporate the reservoir’s impact on the whole Crystal basin.",
    "crumbs": [
      "Getting started",
      "Tutorials",
      "Reservoir"
    ]
  },
  {
    "objectID": "getting-started/tutorial/reservoir.html#reservoir",
    "href": "getting-started/tutorial/reservoir.html#reservoir",
    "title": "Reservoir",
    "section": "1 Reservoir",
    "text": "1 Reservoir\n\n1.1 Add a Basin\nThe diversion_basin from the previous tutorial is not used, but replaced by a larger reservoir Basin. Its water will play an important role for the users (the city and the irrigation district). The reservoir has a maximum area of \\(32.3 \\text{ km}^2\\) and a maximum depth of \\(7 \\text{ m}\\).\n\nreservoir = model.basin.add(\n    Node(6, Point(-0.75, -0.5), name=\"reservoir\"),\n    [\n        basin.Profile(area=[20000000, 32300000], level=[0, 7]),\n        basin.State(level=[3.5]),\n        basin.Time(time=[starttime, endtime]),\n    ],\n)\n\n\n\n1.2 Add a demand node\n\\(50.000\\) people live in Crystal City. To represents the total flow rate or abstraction rate required to meet the water demand of \\(50.000\\) people, another demand node needs to be added assuming a return flow of \\(60\\%\\).\n\ncity = model.user_demand.add(\n    Node(9, Point(0, -1), name=\"city\"),\n    [\n        user_demand.Time(\n            # Total demand in m³/s\n            demand=[0.07, 0.08, 0.09, 0.10, 0.12, 0.14, 0.15, 0.14, 0.12, 0.10, 0.09, 0.08],\n            return_factor=0.6,\n            min_level=0,\n            demand_priority=1,\n            time=pd.date_range(start=\"2022-01-01\", periods=12, freq=\"MS\"),\n        )\n    ],\n)  # fmt: skip\n\n\nmodel.link.add(main, reservoir, name=\"main\")\nmodel.link.add(minor, confluence, name=\"minor\")\nmodel.link.add(reservoir, irrigation, name=\"irrigation\")\nmodel.link.add(irrigation, confluence)\nmodel.link.add(reservoir, city, name=\"city\")\nmodel.link.add(city, confluence, name=\"city returnflow\")\nmodel.link.add(reservoir, diversion_weir, name=\"not diverted\")\nmodel.link.add(diversion_weir, confluence)\nmodel.link.add(confluence, weir)\nmodel.link.add(weir, sea, name=\"sea\")\n\n\nmodel.plot();\n\n\n\n\n\n\n\n\n\ntoml_path = base_dir / \"Crystal-3/ribasim.toml\"\nmodel.write(toml_path)\n\nPosixPath('crystal-basin/Crystal-3/ribasim.toml')\n\n\n\n\n1.3 Adjust the code\nAdjust the naming of the Basin in the dictionary mapping and the saving file should be Crystal-3.\n\nrun_ribasim(toml_path)\n\n┌ Info: Starting a Ribasim simulation at 2026-01-23T16:36:26.805.\n│   toml_path = \"crystal-basin/Crystal-3/ribasim.toml\"\n│   cli.ribasim_version = \"2026.1.0-rc1\"\n│   starttime = 2022-01-01T00:00:00\n│   endtime = 2023-01-01T00:00:00\n└   threads = 1\nSimulating   0%|                                        |  ETA: N/A\nSimulating   0%|                                        |  ETA: 1 days, 2:26:24\nSimulating   4%|█▋                                      |  ETA: 0:19:32\nSimulating   8%|███▍                                    |  ETA: 0:08:54\nSimulating  13%|█████▎                                  |  ETA: 0:05:32\nSimulating  17%|██████▊                                 |  ETA: 0:04:02\nSimulating  25%|█████████▉                              |  ETA: 0:02:32\nSimulating  25%|█████████▉                              |  ETA: 0:02:32\nSimulating  25%|█████████▉                              |  ETA: 0:02:32\nSimulating  26%|██████████▎                             |  ETA: 0:02:24\nSimulating  30%|████████████                            |  ETA: 0:01:56\nSimulating  33%|█████████████▎                          |  ETA: 0:01:41\nSimulating  37%|██████████████▉                         |  ETA: 0:01:23\nSimulating  41%|████████████████▌                       |  ETA: 0:01:10\nSimulating  46%|██████████████████▌                     |  ETA: 0:00:58\nSimulating  50%|███████████████████▉                    |  ETA: 0:00:51\nSimulating  51%|████████████████████▎                   |  ETA: 0:00:49\nSimulating  58%|███████████████████████▎                |  ETA: 0:00:36\nSimulating  63%|█████████████████████████▏              |  ETA: 0:00:30\nSimulating  68%|███████████████████████████             |  ETA: 0:00:24\nSimulating  75%|█████████████████████████████▉          |  ETA: 0:00:17\nSimulating  78%|███████████████████████████████         |  ETA: 0:00:14\nSimulating  83%|█████████████████████████████████▍      |  ETA: 0:00:10\nSimulating  87%|███████████████████████████████████     |  ETA: 0:00:07\nSimulating  92%|████████████████████████████████████▋   |  ETA: 0:00:05\nSimulating 100%|████████████████████████████████████████| Time: 0:00:49\n[ Info: Computation time: 24 seconds, 279 milliseconds\n[ Info: The model finished successfully at 2026-01-23T16:39:03.282.",
    "crumbs": [
      "Getting started",
      "Tutorials",
      "Reservoir"
    ]
  },
  {
    "objectID": "getting-started/tutorial/reservoir.html#plot-reservoir-storage-and-level",
    "href": "getting-started/tutorial/reservoir.html#plot-reservoir-storage-and-level",
    "title": "Reservoir",
    "section": "2 Plot reservoir storage and level",
    "text": "2 Plot reservoir storage and level\n\ndf_basin = pd.read_feather(base_dir / \"Crystal-3/results/basin.arrow\")\n\n# Create pivot tables and plot for Basin data\ndf_basin_wide = df_basin.pivot_table(\n    index=\"time\", columns=\"node_id\", values=[\"storage\", \"level\"]\n)\ndf_basin_wide = df_basin_wide.loc[:, pd.IndexSlice[:, reservoir.node_id]]\n\n# Plot level and storage on the same graph with dual y-axes\nfig, ax1 = plt.subplots(figsize=(12, 6))\n\n# Plot level on the primary y-axis\ncolor = \"b\"\nax1.set_xlabel(\"Time\")\nax1.set_ylabel(\"Level [m]\", color=color)\nax1.plot(df_basin_wide.index, df_basin_wide[\"level\"], color=color)\nax1.tick_params(axis=\"y\", labelcolor=color)\n\n# Create a secondary y-axis for storage\nax2 = ax1.twinx()\ncolor = \"r\"\nax2.set_ylabel(\"Storage [m³]\", color=\"r\")\nax2.plot(df_basin_wide.index, df_basin_wide[\"storage\"], linestyle=\"--\", color=color)\nax2.tick_params(axis=\"y\", labelcolor=color)\n\nfig.tight_layout()  # Adjust layout to fit labels\nplt.title(\"Basin level and storage\")\nplt.show()\n\n\n\n\n\n\n\n\nThe figure above illustrates the storage and water level at the reservoir. As expected, after increasing the profile of the Basin, its storage capacity increased as well.",
    "crumbs": [
      "Getting started",
      "Tutorials",
      "Reservoir"
    ]
  },
  {
    "objectID": "getting-started/tutorial/reservoir.html#plot-flows",
    "href": "getting-started/tutorial/reservoir.html#plot-flows",
    "title": "Reservoir",
    "section": "3 Plot flows",
    "text": "3 Plot flows\n\ndf_flow = pd.read_feather(base_dir / \"Crystal-3/results/flow.arrow\")\n# Add the link names and then remove unnamed links\ndf_flow[\"name\"] = model.link.df[\"name\"].loc[df_flow[\"link_id\"]].to_numpy()\ndf_flow = df_flow[df_flow[\"name\"].astype(bool)]\n\n# Plot the flow data, interactive plot with Plotly\npivot_flow = df_flow.pivot_table(\n    index=\"time\", columns=\"name\", values=\"flow_rate\"\n).reset_index()\nfig = px.line(pivot_flow, x=\"time\", y=pivot_flow.columns[1:], title=\"Flow [m3/s]\")\n\nfig.update_layout(legend_title_text=\"Link\")\nfig.show()",
    "crumbs": [
      "Getting started",
      "Tutorials",
      "Reservoir"
    ]
  },
  {
    "objectID": "getting-started/install.html",
    "href": "getting-started/install.html",
    "title": "Installation",
    "section": "",
    "text": "In this document, we describe how to install the different components of Ribasim. First the components and their relation are introduced, then installation instructions per component follow.",
    "crumbs": [
      "Getting started",
      "Installation"
    ]
  },
  {
    "objectID": "getting-started/install.html#windows-installation-script-recommended",
    "href": "getting-started/install.html#windows-installation-script-recommended",
    "title": "Installation",
    "section": "2.1 Windows installation script (recommended)",
    "text": "2.1 Windows installation script (recommended)\nThe easiest way to install Ribasim on Windows is to use the installation script. Open a terminal and run:\npowershell -ExecutionPolicy ByPass -c \"irm https://ribasim.org/install.ps1 | iex\"\nThis will download and install the latest version of Ribasim to %USERPROFILE%\\.ribasim and automatically add it to your PATH. After installation, you can run ribasim --help from any directory.\nYou can set the RIBASIM_HOME environment variable if you wish to install it in a different directory. Use the manual installation to install older versions of Ribasim, or if you don’t want to add it to your PATH.",
    "crumbs": [
      "Getting started",
      "Installation"
    ]
  },
  {
    "objectID": "getting-started/install.html#manual-installation",
    "href": "getting-started/install.html#manual-installation",
    "title": "Installation",
    "section": "2.2 Manual installation",
    "text": "2.2 Manual installation\nTo download the Ribasim core manually, download the appropriate zip file for your operating system:\n\nRibasim executable - Windows: ribasim_windows.zip\nRibasim executable - Linux: ribasim_linux.zip\n\nNote that we currently only support and provide binaries for Windows and Linux, for the x86_64 architecture.\nTo check whether the installation was performed successfully, open a terminal and go to the path where the executable is for example C:\\bin\\ribasim\\. If you are using cmd.exe type ribasim --help, or for PowerShell ./ribasim.\nThis will give the following message if it is installed correctly:\nUsage: ribasim [OPTIONS] &lt;TOML_PATH&gt;\n\nArguments:\n  &lt;TOML_PATH&gt;  Path to the TOML file\n\nOptions:\n  -h, --help                Print help\n  -V, --version             Print version",
    "crumbs": [
      "Getting started",
      "Installation"
    ]
  },
  {
    "objectID": "getting-started/install.html#adding-ribasim-to-path-on-windows",
    "href": "getting-started/install.html#adding-ribasim-to-path-on-windows",
    "title": "Installation",
    "section": "2.3 Adding Ribasim to Path on Windows",
    "text": "2.3 Adding Ribasim to Path on Windows\nIf you used the installation script, Ribasim is already on your PATH. For manual installations, you can add the Ribasim executable directory to your Windows Path environment variable.\nThe Path environment variable tells Windows where to look for programs when you type their name in a terminal. By adding Ribasim to your Path, you can type ribasim from any folder instead of having to navigate to the Ribasim folder first or typing the full path like C:\\bin\\ribasim\\ribasim.exe.\n\nSearch “Environment Variables” in the Windows search bar\nClick “Edit the system environment variables”\nClick on the “Advanced” tab\nClick the “Environment Variables…” button at the bottom\nIn the top section “User variables”, scroll down and find “Path”, then click “Edit…”\nClick “New” and enter the full path to your Ribasim directory (e.g., C:\\bin\\ribasim, not C:\\bin\\ribasim\\ribasim.exe)\nClick “OK” three times to close all dialogs\nClose any open terminals/command prompts and open a new one",
    "crumbs": [
      "Getting started",
      "Installation"
    ]
  },
  {
    "objectID": "getting-started/install.html#install-from-qgis-plugin-repository-recommended",
    "href": "getting-started/install.html#install-from-qgis-plugin-repository-recommended",
    "title": "Installation",
    "section": "4.1 Install from QGIS Plugin Repository (recommended)",
    "text": "4.1 Install from QGIS Plugin Repository (recommended)\nThe easiest way to install the Ribasim QGIS plugin is through the QGIS Plugin Repository.\nIn QGIS, go to Plugins menu &gt; Manage and Install Plugins…\n\n\n\n\n\nSelect “All” and search for “Ribasim”:\n\nType “Ribasim” in the search bar\nSelect the “Ribasim” plugin from the results\nClick “Install Plugin”\n\nFor more information on installing plugins in QGIS, see the QGIS documentation on installing plugins.\nAfter installation the Ribasim icon should appear on the QGIS toolbar:\n\n\n\n\n\nSee the Ribasim QGIS guide for how to use the plugin.",
    "crumbs": [
      "Getting started",
      "Installation"
    ]
  },
  {
    "objectID": "getting-started/install.html#alternative-install-from-zip-file",
    "href": "getting-started/install.html#alternative-install-from-zip-file",
    "title": "Installation",
    "section": "4.2 Alternative: Install from ZIP file",
    "text": "4.2 Alternative: Install from ZIP file\nIf the plugin repository method doesn’t work or you need a specific version, you can manually install the plugin from a ZIP file.\nDownload ribasim_qgis.zip:\n\nQGIS plugin: ribasim_qgis.zip.\n\nIn QGIS, go to Plugins menu &gt; Manage and Install Plugins…\nSelect “Install from ZIP”:\n\nBrowse to the ribasim_qgis.zip file containing the plugin that was downloaded earlier\nClick “Install Plugin”",
    "crumbs": [
      "Getting started",
      "Installation"
    ]
  },
  {
    "objectID": "getting-started/install.html#install-imod-plugin",
    "href": "getting-started/install.html#install-imod-plugin",
    "title": "Installation",
    "section": "4.3 Install iMOD plugin",
    "text": "4.3 Install iMOD plugin\nIn QGIS, navigate to “Plugins &gt; Manage and Install Plugins &gt; All”. In the search bar, type: “iMOD”. Select the iMOD plugin, and click “Install”.\nAt least version 0.5.3 of the iMOD plugin is required.\nThe Time Series widget from the iMOD plugin is used for visualizing Ribasim results, which is described in the results section. Documentation on the Time Series widget can be found in the iMOD documentation.",
    "crumbs": [
      "Getting started",
      "Installation"
    ]
  },
  {
    "objectID": "dev/addnode.html",
    "href": "dev/addnode.html",
    "title": "Adding node types",
    "section": "",
    "text": "Several parts of the code have to be made aware of the new node type. In the rest of this page we shall call our new node type NewNodeType.",
    "crumbs": [
      "Contributing",
      "Adding node types"
    ]
  },
  {
    "objectID": "dev/addnode.html#parameters",
    "href": "dev/addnode.html#parameters",
    "title": "Adding node types",
    "section": "1.1 Parameters",
    "text": "1.1 Parameters\nThe parameters object (defined in parameter.jl) passed to the ODE solver must be made aware of the new node type. Therefore define a struct in parameter.jl which holds the data for each node of the new node type:\nstruct NewNodeType &lt;: AbstractParameterNode\n    node_id::Vector{NodeID}\n    # Other fields\nend\nAnother abstract type which subtypes from AbstractParameterNode is called AbstractDemandNode. For creating new node type used in allocation, define a struct:\nstruct NewNodeType &lt;: AbstractDemandNode\n    node_id::Vector{NodeID}\n    # Other fields\nend\nThese fields do not have to correspond 1:1 with the input tables (see below). The vector with all node IDs that are of the new type in a given model is a mandatory field. Now you can:\n\nAdd new_node_type::NewNodeType to the Parameters object;\nAdd new_node_type = NewNodeType(db,config) to the function Parameters in read.jl and add new_node_type at the proper location in the Parameters constructor call.",
    "crumbs": [
      "Contributing",
      "Adding node types"
    ]
  },
  {
    "objectID": "dev/addnode.html#reading-from-configuration",
    "href": "dev/addnode.html#reading-from-configuration",
    "title": "Adding node types",
    "section": "1.2 Reading from configuration",
    "text": "1.2 Reading from configuration\nThere can be several schemas associated with a single node type. To define a schema for the new node type, add the following to schema.jl:\n@schema \"ribasim.newnodetype.static\" NewNodeTypeStatic\n\n\"\"\"\nnode_id: node ID of the NewNodeType node\n\"\"\"\n@version NewNodeTypeStaticV1 begin\n    node_id::Int32\n    # Other fields\nend\nHere static refers to data that does not change over time. For naming conventions of these schemas see Node usage. If a new schema contains a demand_priority column for allocation, it must also be added to the list of all such schemas in the function get_all_priorities in util.jl.\nvalidation.jl deals with checking and applying a specific sorting order for the tabular data (default is sorting by node ID only), see sort_by_function and sorted_table!.\nNow we define the function that is called in the second bullet above, in read.jl:\nfunction NewNodeType(db::DB, config::Config)::NewNodeType\n    static = load_structvector(db, config, NewNodeTypeStaticV1)\n    defaults = (; foo = 1, bar = false)\n    # Process potential control states in the static data\n    parsed_parameters, valid = parse_static_and_time(db, config, \"NewNodeType\"; static, defaults)\n\n    if !valid\n        error(\"Errors occurred when parsing NewNodeType data.\")\n    end\n\n    # Unpack the fields of static as inputs for the NewNodeType constructor\n    return NewNodeType(\n        NodeID.(NodeType.NewNodeType, parsed_parameters.node_id),\n        parsed_parameters.some_property,\n        parsed_parameters.control_mapping)\nend",
    "crumbs": [
      "Contributing",
      "Adding node types"
    ]
  },
  {
    "objectID": "dev/addnode.html#node-behavior",
    "href": "dev/addnode.html#node-behavior",
    "title": "Adding node types",
    "section": "1.3 Node behavior",
    "text": "1.3 Node behavior\nIn general if the new node type dictates flow, the behavior of the new node in the Ribasim core is defined in a method of the formulate_flow! function, which is called within the water_balance! (both in solve.jl) function being the right hand side of the system of differential equations solved by Ribasim. Here the details depend highly on the specifics of the node type. An example structure of a formulate_flow! method is given below.\nfunction formulate_flow!(new_node_type::NewNodeType, p::Parameters)::Nothing\n    # Retrieve relevant parameters\n    (; graph) = p\n    (; node_id, param_1, param_2) = new_node_type\n\n    # Loop over nodes of NewNodeType\n    for (i, id) in enumerate(node_id)\n        # compute e.g. flow based on param_1[i], param_2[i]\n    end\n\n    return nothing\nend\nIf the new node type is non-conservative, meaning it either adds or removes water from the model, these boundary flows also need to be recorded. This is done by storing it on the diagonal of the flow[from, to] matrix, e.g. flow[id, id] = q, where q is positive for water added to the model.",
    "crumbs": [
      "Contributing",
      "Adding node types"
    ]
  },
  {
    "objectID": "dev/addnode.html#the-jacobian",
    "href": "dev/addnode.html#the-jacobian",
    "title": "Adding node types",
    "section": "1.4 The Jacobian",
    "text": "1.4 The Jacobian\nSee Equations for a mathematical description of the Jacobian.\nBefore the Julia core runs its simulation, the sparsity structure jac_prototype of \\(J\\) is determined with get_jac_prototype in sparsity.jl. This function runs through all node types and looks for nodes that create dependencies between states. It creates a sparse matrix of zeros and ones, where the ones denote locations of possible non-zeros in \\(J\\). Note that only nodes that set flows in the physical layer (or have their own state like PidControl) affect the sparsity structure.\nWe divide the various node types in groups based on what type of state dependencies they yield, and these groups are discussed below. Each group has its own method update_jac_prototype! in utils.jl for the sparsity structure induced by nodes of that group. NewNodeType should be added to the signature of one these methods, or to the list of node types that do not contribute to the Jacobian in the method of update_jac_prototype! whose signature contains node::AbstractParameterNode. Of course it is also possible that a new method of update_jac_prototype! has to be introduced.\nThe current dependency groups are:\n\nOut-neighbor dependencies: examples are TabulatedRatingCurve, Pump (the latter only in the reduction factor regime and not PID controlled). If the in-neighbor of a node of this group is a basin, then the storage of this basin affects itself and the storage of the outneighbor if that is also a basin;\nEither-neighbor dependencies: examples are LinearResistance, ManningResistance. If either the in-neighbor or out-neighbor of a node of this group is a basin, the storage of this basin depends on itself. If both the in-neighbor and the out-neighbor are basins, their storages also depend on eachother.\nThe PidControl node is a special case which is discussed in the PID equations.\n\nUsing jac_prototype the Jacobian of water_balance! is computed automatically using ForwardDiff.jl with memory management provided by PreallocationTools.jl. These computations make use of DiffCache and dual numbers.",
    "crumbs": [
      "Contributing",
      "Adding node types"
    ]
  },
  {
    "objectID": "dev/addnode.html#python-class",
    "href": "dev/addnode.html#python-class",
    "title": "Adding node types",
    "section": "2.1 Python class",
    "text": "2.1 Python class\nIn python/ribasim/ribasim/config.py add\n\nthe above defined schemas to the imports from ribasim.schemas. This requires code generation to work, see Finishing up;\na class of the following form with all schemas associated with the node type:\n\nclass NewNodeType(MultiNodeModel):\n    static: TableModel[NewNodeTypeStaticSchema] = Field(\n        default_factory=TableModel[NewNodeTypeStaticSchema],\n        json_schema_extra={\"sort_keys\": [\"node_id\"]},\n    )\nIn python/ribasim/ribasim/nodes/__init__.py add\n\nNewNodeType to the imports from ribasim.nodes;\n\"NewNodeType\" to __all__.\n\nIn python/ribasim/ribasim/model.py, add\n\nNewNodeType to the imports from ribasim.config;\nnew_node_type as a parameter of the Model class.\n\nIn python/ribasim/ribasim/geometry/node.py add a color and shape description in the MARKERS and COLORS dictionaries.",
    "crumbs": [
      "Contributing",
      "Adding node types"
    ]
  },
  {
    "objectID": "dev/bmi.html",
    "href": "dev/bmi.html",
    "title": "1 Basic Model Interface (BMI)",
    "section": "",
    "text": "For runtime data exchange and coupling with other kernels, the Julia kernel is wrapped in a Python API (ribasim_api) which implements the Basic Model Interface BMI.\n\n\nThe following functions are available to interact with the Ribasim model”\n\n\n\n\n\n\n\nsignature\ndescription\n\n\n\n\ninitialize(config_path)\nInitialize a model from the path to the TOML configuration file\n\n\nfinalize()\nWrite all results to the configured files\n\n\nget_current_time()\nGet the current time of the Ribasim simulation\n\n\nget_end_time()\nGet the final time of the Ribasim simulation in seconds\n\n\nget_start_time()\nGet the start time of the Ribasim simulation (0.0)\n\n\nget_time_step()\nGet the proposed next internal Ribasim timestep\n\n\nget_time_units()\nGet the time unit (s)\n\n\nget_value_ptr(string)\nGet the pointer to a Ribasim internal array (see below)\n\n\nupdate()\nPerform a Ribasim internal time step\n\n\nupdate_until(time)\nSet Ribasim internal timesteps until the specified time\n\n\n\nDepending on what is specified in the Ribasim TOML configuration file, Ribasim can internally have adaptive (non-constant) timesteps. update_until will always try to progress the Ribasim simulation to exactly the time specified. This however can fail for algorithms that only support a fixed timestep if that timestep does not fit into the interval until the specified time an integer amount of times.\n\n\n\nThe following pointers to memory containing Ribasim internal arrays are given via the BMI using get_value_ptr(string):\n\n\n\n\n\n\n\n\n\n\n\n\nstring\nmeaning\ntype\nunit\ntemporal type\nwritable\nsorted by\n\n\n\n\nbasin.storage\nstorage per basin\nFloat64\n\\(\\text{m}^3\\)\ninstantaneous\nno\nbasin node ID\n\n\nbasin.level\nlevel per basin\nFloat64\n\\(\\text{m}\\)\ninstantaneous\nno\nbasin node ID\n\n\nbasin.infiltration\ninfiltration flux per basin\nFloat64\n\\(\\text{m}^3 \\text{s}^{-1}\\)\nforward fill\nyes\nbasin node ID\n\n\nbasin.drainage\ndrainage flux per basin\nFloat64\n\\(\\text{m}^3 \\text{s}^{-1}\\)\nforward fill\nyes\nbasin node ID\n\n\nbasin.infiltration_integrated\ncumulative infiltration per basin\nFloat64\n\\(\\text{m}^3\\)\nintegrated from start\nyes\nbasin node ID\n\n\nbasin.drainage_integrated\ncumulative drainage per basin\nFloat64\n\\(\\text{m}^3\\)\nintegrated from start\nyes\nbasin node ID\n\n\nbasin.subgrid_level\nsubgrid level\nFloat64\n\\(\\text{m}\\)\ninstantaneous\nno\nsubgrid ID\n\n\nuser_demand.demand\ndemand per node ID per priority\nFloat64\n\\(\\text{m}^3 \\text{s}^{-1}\\)\nforward fill\nyes\nuser_demand node ID, priority index\n\n\nuser_demand.realized\ncumulative intake flow per user\nFloat64\n\\(\\text{m}^3\\)\nintegrated from start\nyes\nuser_demand node ID\n\n\n\nAdditional notes:\n\nuser_demand.demand yields the only 2D array, the other arrays are 1D. This array is indexed as (node_idx, priority_idx) in Julia, which stores arrays column-major\nThe index of e.g. basins and user demand nodes needs to be inferred from the Ribasim input. The same holds for priority_idx, which is global over all subnetworks\nThe data being writable means that Ribasim takes into account the possibility that the data is updated outiside the Ribasim core\nAlthough the *_integrated and *_realized data is writable, this doesn’t affect the Ribasim simulation. This integrated data is only computed for the BMI, and can be set to \\(0\\) via the BMI to avoid accuracy problems when the values get too large.\nDifferent from what is exposed via the BMI, the basin forcings and realized user demands are averaged over the allocation timestep and saveat interval respectively.",
    "crumbs": [
      "Contributing",
      "Basic Model Interface (BMI)"
    ]
  },
  {
    "objectID": "dev/bmi.html#functions",
    "href": "dev/bmi.html#functions",
    "title": "1 Basic Model Interface (BMI)",
    "section": "",
    "text": "The following functions are available to interact with the Ribasim model”\n\n\n\n\n\n\n\nsignature\ndescription\n\n\n\n\ninitialize(config_path)\nInitialize a model from the path to the TOML configuration file\n\n\nfinalize()\nWrite all results to the configured files\n\n\nget_current_time()\nGet the current time of the Ribasim simulation\n\n\nget_end_time()\nGet the final time of the Ribasim simulation in seconds\n\n\nget_start_time()\nGet the start time of the Ribasim simulation (0.0)\n\n\nget_time_step()\nGet the proposed next internal Ribasim timestep\n\n\nget_time_units()\nGet the time unit (s)\n\n\nget_value_ptr(string)\nGet the pointer to a Ribasim internal array (see below)\n\n\nupdate()\nPerform a Ribasim internal time step\n\n\nupdate_until(time)\nSet Ribasim internal timesteps until the specified time\n\n\n\nDepending on what is specified in the Ribasim TOML configuration file, Ribasim can internally have adaptive (non-constant) timesteps. update_until will always try to progress the Ribasim simulation to exactly the time specified. This however can fail for algorithms that only support a fixed timestep if that timestep does not fit into the interval until the specified time an integer amount of times.",
    "crumbs": [
      "Contributing",
      "Basic Model Interface (BMI)"
    ]
  },
  {
    "objectID": "dev/bmi.html#memory-pointers",
    "href": "dev/bmi.html#memory-pointers",
    "title": "1 Basic Model Interface (BMI)",
    "section": "",
    "text": "The following pointers to memory containing Ribasim internal arrays are given via the BMI using get_value_ptr(string):\n\n\n\n\n\n\n\n\n\n\n\n\nstring\nmeaning\ntype\nunit\ntemporal type\nwritable\nsorted by\n\n\n\n\nbasin.storage\nstorage per basin\nFloat64\n\\(\\text{m}^3\\)\ninstantaneous\nno\nbasin node ID\n\n\nbasin.level\nlevel per basin\nFloat64\n\\(\\text{m}\\)\ninstantaneous\nno\nbasin node ID\n\n\nbasin.infiltration\ninfiltration flux per basin\nFloat64\n\\(\\text{m}^3 \\text{s}^{-1}\\)\nforward fill\nyes\nbasin node ID\n\n\nbasin.drainage\ndrainage flux per basin\nFloat64\n\\(\\text{m}^3 \\text{s}^{-1}\\)\nforward fill\nyes\nbasin node ID\n\n\nbasin.infiltration_integrated\ncumulative infiltration per basin\nFloat64\n\\(\\text{m}^3\\)\nintegrated from start\nyes\nbasin node ID\n\n\nbasin.drainage_integrated\ncumulative drainage per basin\nFloat64\n\\(\\text{m}^3\\)\nintegrated from start\nyes\nbasin node ID\n\n\nbasin.subgrid_level\nsubgrid level\nFloat64\n\\(\\text{m}\\)\ninstantaneous\nno\nsubgrid ID\n\n\nuser_demand.demand\ndemand per node ID per priority\nFloat64\n\\(\\text{m}^3 \\text{s}^{-1}\\)\nforward fill\nyes\nuser_demand node ID, priority index\n\n\nuser_demand.realized\ncumulative intake flow per user\nFloat64\n\\(\\text{m}^3\\)\nintegrated from start\nyes\nuser_demand node ID\n\n\n\nAdditional notes:\n\nuser_demand.demand yields the only 2D array, the other arrays are 1D. This array is indexed as (node_idx, priority_idx) in Julia, which stores arrays column-major\nThe index of e.g. basins and user demand nodes needs to be inferred from the Ribasim input. The same holds for priority_idx, which is global over all subnetworks\nThe data being writable means that Ribasim takes into account the possibility that the data is updated outiside the Ribasim core\nAlthough the *_integrated and *_realized data is writable, this doesn’t affect the Ribasim simulation. This integrated data is only computed for the BMI, and can be set to \\(0\\) via the BMI to avoid accuracy problems when the values get too large.\nDifferent from what is exposed via the BMI, the basin forcings and realized user demands are averaged over the allocation timestep and saveat interval respectively.",
    "crumbs": [
      "Contributing",
      "Basic Model Interface (BMI)"
    ]
  },
  {
    "objectID": "dev/benchmark.html",
    "href": "dev/benchmark.html",
    "title": "Benchmark",
    "section": "",
    "text": "This document describes how the benchmarking and performance testing of Ribasim is handled. In Ribasim, the benchmarking includes and regression tests on the test models and regressive performance tests on the production models.\nThe idea of regression tests on the test models is to run models with various solvers, run models with a sparse Jacobian and a dense one and compare the outputs. It will possibly involve production models in the future. And runtime performance test is lined up for the next step (in issue #1698).\nThe idea of regressive performance tests on the production models is to test the performance of running the production models. It will report if the new changes in the code decrease the model’s performance or result in failed runs.",
    "crumbs": [
      "Contributing",
      "Benchmark"
    ]
  },
  {
    "objectID": "dev/benchmark.html#benchmark-the-ode-solvers",
    "href": "dev/benchmark.html#benchmark-the-ode-solvers",
    "title": "Benchmark",
    "section": "1.1 Benchmark the ODE solvers",
    "text": "1.1 Benchmark the ODE solvers\nThe benchmarking of the ODE solvers is done by running the test models with different ODE solvers and solver settings and comparing the output with the benchmark.\nThe settings include toggling the sparse and autodiff solver settings. Currently, 4 models are chosen to undergo the regression tests. They are trivial, basic, pid_control and subnetwork_with_sources.\nThe benchmark reference are the output files of a run of the test models with default solver settings. The output files basin.arrow and flow.arrow are used for comparison. Different margins are set for the comparison of the outputs, and the benchmark is considered passed if the output is within the margin. Since we are still in the process of evaluating the performance of different solvers, the margin is subject to change.\nThe regression tests are run on a weekly basis.",
    "crumbs": [
      "Contributing",
      "Benchmark"
    ]
  },
  {
    "objectID": "dev/copilot.html",
    "href": "dev/copilot.html",
    "title": "Copilot instructions",
    "section": "",
    "text": "The developers sometimes use GitHub Copilot to assist in their work. To make this more effective, we supply custom instructions for this repository, as documented here. These instructions are automatically used by Copilot.",
    "crumbs": [
      "Contributing",
      "Copilot instructions"
    ]
  },
  {
    "objectID": "dev/copilot.html#project-overview",
    "href": "dev/copilot.html#project-overview",
    "title": "Copilot instructions",
    "section": "2.1 Project Overview",
    "text": "2.1 Project Overview\nRibasim is a water resources modeling system. It’s a multi-language project with components in Julia (core), Python (utilities/API), and QGIS integration.\n\nPrimary Language: Julia (core simulation engine)\nSecondary Languages: Python (model building, QGIS plugin)\nDomain: Water resources modeling, hydrology, scientific computing\nArchitecture: Modular system with CLI, Python API, and QGIS plugin",
    "crumbs": [
      "Contributing",
      "Copilot instructions"
    ]
  },
  {
    "objectID": "dev/copilot.html#repository-structure",
    "href": "dev/copilot.html#repository-structure",
    "title": "Copilot instructions",
    "section": "2.2 Repository Structure",
    "text": "2.2 Repository Structure\n├── core/                   # Julia core engine (main simulation code)\n│   ├── src/                # Core Julia source code\n│   ├── test/               # Julia unit tests\n│   └── Project.toml        # Julia package configuration\n├── python/                 # Python components\n│   ├── ribasim/            # Main Python package (model building)\n│   ├── ribasim_api/        # Python API for model interaction\n│   └── ribasim_testmodels/ # Test model generation\n├── ribasim_qgis/           # QGIS plugin for model visualization\n├── docs/                   # Documentation (Quarto-based)\n├── build/                  # Build scripts for CLI\n├── generated_testmodels/   # Generated test models\n├── models/                 # Working directory for models, ignored by git\n└── utils/                  # Utility scripts",
    "crumbs": [
      "Contributing",
      "Copilot instructions"
    ]
  },
  {
    "objectID": "dev/copilot.html#key-technologies-dependencies",
    "href": "dev/copilot.html#key-technologies-dependencies",
    "title": "Copilot instructions",
    "section": "2.3 Key Technologies & Dependencies",
    "text": "2.3 Key Technologies & Dependencies\n\n2.3.1 Julia Stack (Core)\n\nOrdinaryDiffEq.jl: Differential equation solving (primary solver)\nJuMP.jl: Mathematical optimization modeling\nHiGHS.jl: Linear/mixed-integer programming solver\nArrow.jl: Columnar data format for I/O\nSQLite.jl: Database operations\nMetaGraphsNext.jl: Graph data structures for network topology\nSciML ecosystem: Scientific machine learning tools\n\n\n\n2.3.2 Python Stack\n\nPandas/GeoPandas: Data manipulation and geospatial processing\nPyArrow: Arrow format integration with Julia\nPydantic/Pandera: Data modeling and validation\nMatplotlib: Visualization and plotting\n\n\n\n2.3.3 Build & Development\n\nPixi: Primary package/environment manager, also used to run e.g. tests via tasks. (see pixi.toml)\nJulia Package Manager: For Julia dependencies. Project.toml has all dev dependencies and core/Project.toml the Ribasim core dependencies.\nPre-commit: Code quality hooks\nPytest: Python testing\nQuarto: Documentation generation",
    "crumbs": [
      "Contributing",
      "Copilot instructions"
    ]
  },
  {
    "objectID": "dev/copilot.html#development-workflow",
    "href": "dev/copilot.html#development-workflow",
    "title": "Copilot instructions",
    "section": "2.4 Development Workflow",
    "text": "2.4 Development Workflow\n\n2.4.1 Environment Setup\n# Use Pixi for environment management\npixi run install            # Install and configure all dependencies\n\n\n2.4.2 Key Commands\n# Testing\npixi run test-ribasim-python     # Python tests\npixi run test-ribasim-core       # Julia tests\n\n# Documentation\npixi run quarto-preview          # Preview docs locally\n\n# Model Generation\npixi run generate-testmodels     # Generate test models",
    "crumbs": [
      "Contributing",
      "Copilot instructions"
    ]
  },
  {
    "objectID": "dev/copilot.html#code-architecture-patterns",
    "href": "dev/copilot.html#code-architecture-patterns",
    "title": "Copilot instructions",
    "section": "2.5 Code Architecture Patterns",
    "text": "2.5 Code Architecture Patterns\n\n2.5.1 Julia Core (core/src/)\n\nSolver integration: Built around OrdinaryDiffEq.jl patterns with callbacks\nGraph representation: Network topology using MetaGraphsNext.jl\n\n\n\n2.5.2 Python Components\n\nPydantic (pandera) models: Data validation and serialization\nPandas workflows: Data processing pipelines\nGeospatial integration: Heavy use of GeoPandas for spatial operations\nArrow: Seamless data exchange with Julia core",
    "crumbs": [
      "Contributing",
      "Copilot instructions"
    ]
  },
  {
    "objectID": "dev/copilot.html#common-patterns-conventions",
    "href": "dev/copilot.html#common-patterns-conventions",
    "title": "Copilot instructions",
    "section": "2.6 Common Patterns & Conventions",
    "text": "2.6 Common Patterns & Conventions\nWe use the GitHub repository https://github.com/Deltares/Ribasim for issues and PRs.\n\n2.6.1 Julia Code Style\n\nFollow Julia community conventions\nUse multiple dispatch extensively\nPrefer immutable structs where possible\nUse @kwdef for struct definitions with defaults\n\n\n\n2.6.2 Python Code Style\n\nFollow PEP 8\nUse ruff\nUse type hints extensively\nPydantic models for data structures\nPandas-style method chaining where appropriate\n\n\n\n2.6.3 File Naming\n\nJulia: snake_case.jl\nPython: snake_case.py\nTests: test_*.py (Python), *_test.jl (Julia)",
    "crumbs": [
      "Contributing",
      "Copilot instructions"
    ]
  },
  {
    "objectID": "dev/copilot.html#data-flow-formats",
    "href": "dev/copilot.html#data-flow-formats",
    "title": "Copilot instructions",
    "section": "2.7 Data Flow & Formats",
    "text": "2.7 Data Flow & Formats\n\n2.7.1 Primary Data Formats\n\nSQLite/GeoPackage: Model database storage\nArrow: Results or tables too large for SQLite\nTOML: Configuration file\nNetCDF: Conversion to NetCDF for interop\n\n\n\n2.7.2 Key Data Structures\n\nNetwork Graph: Node-link representation of water system\nTimeSeries: Time-dependent boundary conditions\nSpatial Geometries: Basin area polygons, link linestrings\nControl Logic: Rules for pumps, gates, etc.",
    "crumbs": [
      "Contributing",
      "Copilot instructions"
    ]
  },
  {
    "objectID": "dev/copilot.html#common-tasks-helpers",
    "href": "dev/copilot.html#common-tasks-helpers",
    "title": "Copilot instructions",
    "section": "2.8 Common Tasks & Helpers",
    "text": "2.8 Common Tasks & Helpers\n\n2.8.1 When Adding New Node Types:\n\nDefine Julia struct in core/src/\nAdd Python Pydantic model in python/ribasim/\nUpdate schema validation\nAdd to network topology handling\nUpdate documentation and tests\n\n\n\n2.8.2 When Modifying Solvers:\n\nCore solver logic in core/src/solve.jl\nIntegration tests in core/integration_test/\nRegression tests for numerical stability\n\n\n\n2.8.3 When Adding New Python Features:\n\nFollow the pattern in python/ribasim/\nAdd comprehensive docstrings (used by quartodoc)\nInclude examples in docstrings\nAdd tests in python/ribasim/tests/",
    "crumbs": [
      "Contributing",
      "Copilot instructions"
    ]
  },
  {
    "objectID": "dev/copilot.html#testing-strategy",
    "href": "dev/copilot.html#testing-strategy",
    "title": "Copilot instructions",
    "section": "2.9 Testing Strategy",
    "text": "2.9 Testing Strategy\n\n2.9.1 Julia Tests\n\nUnit tests in core/test/\nIntegration tests in core/integration_test/\nRegression tests in core/regression_test/\n\n\n\n2.9.2 Python Tests\n\nUnit tests in python/*/tests/\nMark regression tests with @pytest.mark.regression",
    "crumbs": [
      "Contributing",
      "Copilot instructions"
    ]
  },
  {
    "objectID": "dev/copilot.html#performance-considerations",
    "href": "dev/copilot.html#performance-considerations",
    "title": "Copilot instructions",
    "section": "2.10 Performance Considerations",
    "text": "2.10 Performance Considerations\n\n2.10.1 Julia Core\n\nAvoid allocations during simulation\nAim towards making it statically compilable\nProfile with @profile and @benchmark\nPrecompileTools.jl for reducing startup time\nAvoid type instabilities (use @code_warntype)\n\n\n\n2.10.2 Python Components\n\nUse vectorized pandas operations",
    "crumbs": [
      "Contributing",
      "Copilot instructions"
    ]
  },
  {
    "objectID": "dev/copilot.html#debugging-tips",
    "href": "dev/copilot.html#debugging-tips",
    "title": "Copilot instructions",
    "section": "2.11 Debugging Tips",
    "text": "2.11 Debugging Tips\n\n2.11.1 Julia\n\n@show for quick variable inspection\nJulia debugger for step-through debugging\n\n\n\n2.11.2 Python\n\nStandard Python debugging tools work\nUse breakpoint() for PDB\nRich error messages from Pydantic validation",
    "crumbs": [
      "Contributing",
      "Copilot instructions"
    ]
  },
  {
    "objectID": "dev/copilot.html#integration-points",
    "href": "dev/copilot.html#integration-points",
    "title": "Copilot instructions",
    "section": "2.12 Integration Points",
    "text": "2.12 Integration Points\n\n2.12.1 Julia ↔︎ Python\n\nSQLite database and Arrow files for model storage\nArrow format for data exchange\nSubprocess calls from Python to Julia CLI\n\n\n\n2.12.2 QGIS Plugin\n\nReads/writes same formats as Python components\nProvides GUI for model visualization\nGenerates compatible model files",
    "crumbs": [
      "Contributing",
      "Copilot instructions"
    ]
  },
  {
    "objectID": "dev/copilot.html#documentation",
    "href": "dev/copilot.html#documentation",
    "title": "Copilot instructions",
    "section": "2.13 Documentation",
    "text": "2.13 Documentation\n\nUser docs: docs/ (Quarto-based, published to ribasim.org)\nAPI docs: Auto-generated from docstrings\nCode comments: Focus on why, not what\nExamples: Include runnable examples in docstrings",
    "crumbs": [
      "Contributing",
      "Copilot instructions"
    ]
  },
  {
    "objectID": "dev/copilot.html#common-gotchas",
    "href": "dev/copilot.html#common-gotchas",
    "title": "Copilot instructions",
    "section": "2.14 Common Gotchas",
    "text": "2.14 Common Gotchas\n\nJulia compilation: First run is slow due to compilation\nTable schema: Ensure compatibility between Julia and Python table schemas\nCoordinate systems: Be explicit about CRS in geospatial operations\nNumerical precision: Water balance calculations require careful numerical handling",
    "crumbs": [
      "Contributing",
      "Copilot instructions"
    ]
  },
  {
    "objectID": "dev/copilot.html#getting-help",
    "href": "dev/copilot.html#getting-help",
    "title": "Copilot instructions",
    "section": "2.15 Getting Help",
    "text": "2.15 Getting Help\n\nDocumentation: https://ribasim.org/\nIssues: GitHub issues for bugs and feature requests\nCode patterns: Look at existing similar components for patterns\nTests: Existing tests show expected usage patterns",
    "crumbs": [
      "Contributing",
      "Copilot instructions"
    ]
  },
  {
    "objectID": "dev/copilot.html#key-files-to-understand",
    "href": "dev/copilot.html#key-files-to-understand",
    "title": "Copilot instructions",
    "section": "2.16 Key Files to Understand",
    "text": "2.16 Key Files to Understand\n\ncore/src/Ribasim.jl: Main Julia module entry point\npython/ribasim/ribasim/model.py: Core Python model class\npixi.toml: Development environment and task definitions\nProject.toml: Julia development dependencies\ncore/Project.toml: Julia package dependencies\npython/ribasim/pyproject.toml: Python package configuration",
    "crumbs": [
      "Contributing",
      "Copilot instructions"
    ]
  },
  {
    "objectID": "dev/release.html",
    "href": "dev/release.html",
    "title": "Release process",
    "section": "",
    "text": "The Ribasim repository contains several components, e.g., the Julia core, the Python tooling and QGIS plugin. The components are currently only guaranteed to work together if they have the same version number. Therefore we release Ribasim as a collection of all the components at once, all carrying the same version number. For maximum interoperability it is suggested to only release all components together, and not individually.",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/release.html#pre-release-checks",
    "href": "dev/release.html#pre-release-checks",
    "title": "Release process",
    "section": "2.1 Pre release checks",
    "text": "2.1 Pre release checks\nBefore starting the release process, ensure that all tests are passing and that all features intended for the release are complete and merged into the main branch.",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/release.html#qgis-manual-testing",
    "href": "dev/release.html#qgis-manual-testing",
    "title": "Release process",
    "section": "2.2 QGIS manual testing",
    "text": "2.2 QGIS manual testing\nOur continuous integration (CI) should have caught most issues. A current weak spot in our testing is the QGIS plugin, so a manual test plan is in place. Start with running the automated task to see if it can be correctly installed.\n# This test might give a fatal error on the first run, this is most likely a timing issue.\n# Try to run it again when that happens.\npixi run test-ribasim-qgis-ui\nThen follow the instructions as described in the QGIS manual test plan.",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/release.html#update-version-numbers-of-the-components",
    "href": "dev/release.html#update-version-numbers-of-the-components",
    "title": "Release process",
    "section": "2.3 Update version numbers of the components",
    "text": "2.3 Update version numbers of the components\nDetermine the new version like 2023.1.0, filling in the current year, a bumped MINOR number for normal releases (starting at 1) and a bumped MICRO number for non-breaking, hotfix releases (starting at 0). This follows YYYY.MINOR.MICRO from calver.\nFor pre-releases, add -rcN to the end of the version, which stands for release candidate. Here N represents an integer, starting at 1, so we can have, in chronological order:\n2023.1.0-rc1 as the first release candidate pre-release of 2023.1.0\n2023.1.0-rc2 as the second release candidate pre-release of 2023.1.0\n2023.1.0 as the release\nUpdate the version numbers in the repository to the new version number. See also the latest Ribasim release. Use find and replace to update all locations. Only update the lines in pixi.lock that refer to Ribasim packages, to avoid accidentally changing the version number of dependencies that happen to have the same version number. Don’t change the old version numbers in changelog.qmd.",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/release.html#update-the-changelog",
    "href": "dev/release.html#update-the-changelog",
    "title": "Release process",
    "section": "2.4 Update the changelog",
    "text": "2.4 Update the changelog\nThe docs/changelog.qmd file, hosted on ribasim.org/changelog, records the most important changes for users. Review the commits since the latest Ribasim release to make sure these are listed. Change the “Unreleased” section to the new version number and date, and create a new empty “Unreleased” section at the top.",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/release.html#submit-a-pull-request",
    "href": "dev/release.html#submit-a-pull-request",
    "title": "Release process",
    "section": "2.5 Submit a pull request",
    "text": "2.5 Submit a pull request\nNow submit a pull request with the updated the version numbers and changelog.",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/release.html#create-a-new-release",
    "href": "dev/release.html#create-a-new-release",
    "title": "Release process",
    "section": "2.6 Create a new release",
    "text": "2.6 Create a new release\nWhen the pull request is merged to main, checkout the commit that updates the version numbers.\nCreate a new tag, which is the letter v followed by the version, like, v2023.8.0.\nThis can be done by executing:\ngit tag &lt;tagname&gt;\nThen push the tags:\ngit push --tags\nThis will trigger a workflow on TeamCity that will publish a new release on GitHub as soon as it is finished. You can follow the progress here. It also auto-generates a changelog. You need to edit that by moving the auto-generated contents, except the “Full Changelog” link, in a collapsed details block as shown below.\n&lt;details&gt;\n&lt;summary&gt;\nAll changes\n&lt;/summary&gt;\n\n# Put GitHub flavored markdown here\n\n&lt;/details&gt;\n\nNow copy the manually edited changelog entry from changelog.qmd above the details, such that the edited changelog can be seen both from our documentation as well as GitHub releases.",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/release.html#release-the-ribasim-python-packages-to-pypi",
    "href": "dev/release.html#release-the-ribasim-python-packages-to-pypi",
    "title": "Release process",
    "section": "2.7 Release the Ribasim Python packages to PyPI",
    "text": "2.7 Release the Ribasim Python packages to PyPI\nTo be able to install packages with pip, they need to be released on the Python Package Index (PyPI). In order to publish Ribasim Python or Ribasim API follow the following steps:\n\nOpen a terminal and run pixi run publish-ribasim-python\nOpen a terminal and run pixi run publish-ribasim-api",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/release.html#announce-release",
    "href": "dev/release.html#announce-release",
    "title": "Release process",
    "section": "2.8 Announce release",
    "text": "2.8 Announce release\nAnnounce the release in appropriate channels. Include a link to the release notes and assets, which is whatever this resolves to at that time. Also include a link to the documentation.",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/release.html#create-a-release-branch",
    "href": "dev/release.html#create-a-release-branch",
    "title": "Release process",
    "section": "2.9 Create a release branch",
    "text": "2.9 Create a release branch\nIf it is a new stable non-hotfix release (MICRO is equal to 0, and not a pre-release), we need to create and push a release branch. For example, if the release is v2023.1.0, follow these steps:\ngit checkout v2023.1.0\ngit switch -c release/v2023.1\ngit push\nThe release branch will be the target for (backport of) bugfixes.",
    "crumbs": [
      "Contributing",
      "Release process"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html",
    "href": "dev/qgis_test_plan.html",
    "title": "QGIS plugin manual test plan",
    "section": "",
    "text": "This document describes how to perform a full manual test on the Ribasim QGIS plugin. Known shortcomings and issues can be documented here. Bugs can be reported on GitHub.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#enable-and-disable",
    "href": "dev/qgis_test_plan.html#enable-and-disable",
    "title": "QGIS plugin manual test plan",
    "section": "1.1 Enable and disable",
    "text": "1.1 Enable and disable\n\nOpen QGIS and navigate to “Plugins &gt; Manage and Install Plugins…”: The plugin management window opens.\nNavigate to “Installed”: Ribasim plugin is in the list (enabled).\nDisable the Ribasim plugin: Ribasim plugin panel hides if it was open, Ribasim button hides from navigation toolbar.\nEnable the Ribasim plugin: Ribasim button shows on the navigation toolbar.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#open-model-twice",
    "href": "dev/qgis_test_plan.html#open-model-twice",
    "title": "QGIS plugin manual test plan",
    "section": "2.1 Open model twice",
    "text": "2.1 Open model twice\n\nOpen QGIS and ensure that the Ribasim plugin is installed and enabled.\nClick the Ribasim button on the QGIS toolbar: file navigation window pops up.\nChoose an existing model from the generated_testmodels folder.\nPress OK: The model layers appear in the layer panel and on the map.\nClick the Ribasim button on the QGIS toolbar: file navigation window pops up.\nOpen the same model again: A new layer group is added to the layers panel.\n\nIntended behavior: The same model is loaded twice, but there is only a connection on the last loaded model when interacting with the plugin.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#node-selection-on-map-triggers-table-selection",
    "href": "dev/qgis_test_plan.html#node-selection-on-map-triggers-table-selection",
    "title": "QGIS plugin manual test plan",
    "section": "3.1 Node selection on map triggers table selection",
    "text": "3.1 Node selection on map triggers table selection\n\nOpen QGIS and ensure that the Ribasim plugin is installed and enabled.\nChoose an existing model from the generated_testmodels folder in the file explorer.\nDrag the TOML file onto QGIS: The model layers appear in the layer panel and on the map.\nSelect the node layer, and make a subselection of nodes on the map: Nodes are highlighted in yellow, including their links.\nOpen the Link attribute table: The highlighted rows are those with a from/to node_id that was selected.\nOpen any non-spatial attribute table: The highlighted rows are those with a node_id that was selected.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#run-a-model-and-check-the-time-series",
    "href": "dev/qgis_test_plan.html#run-a-model-and-check-the-time-series",
    "title": "QGIS plugin manual test plan",
    "section": "4.1 Run a model and check the time series",
    "text": "4.1 Run a model and check the time series\nTODO",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "dev/qgis_test_plan.html#perform-tutorial-in-documentation",
    "href": "dev/qgis_test_plan.html#perform-tutorial-in-documentation",
    "title": "QGIS plugin manual test plan",
    "section": "5.1 Perform tutorial in documentation",
    "text": "5.1 Perform tutorial in documentation\nGo through the tutorial as described in the How-to guide.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin manual test plan"
    ]
  },
  {
    "objectID": "guide/modeling-process.html",
    "href": "guide/modeling-process.html",
    "title": "Modeling process",
    "section": "",
    "text": "In general, it is recommended to follow an incremental approach when building a Ribasim model. This approach could be organized in the following phases:",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#goal",
    "href": "guide/modeling-process.html#goal",
    "title": "Modeling process",
    "section": "1.1 Goal",
    "text": "1.1 Goal\nCreate a valid network representation of the water system that runs and can be discussed with stakeholders.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#steps",
    "href": "guide/modeling-process.html#steps",
    "title": "Modeling process",
    "section": "1.2 Steps",
    "text": "1.2 Steps\n\nDiscuss with stakeholders the purpose of the model and what system components and behavior they want to see reflected in the model.\nDecide what procedure to follow to separate Basins and position control nodes in between.\nScript this approach to build the network topology of nodes and links.\nAdd user demand nodes as appropriate and link them to the supplying Basin.\nParameterize Basins with default or made up profiles.\nParameterize TabulatedRatingCurves with some default settings.\nParameterize Pumps and outlets with sufficiently large default or made up capacities.\nPut static forcing on the boundaries nodes.\nTry to run the model and fix any topological issues.\nDiscuss the network/water system representation with the stakeholders to confirm that the relevant elements are included. Prioritize next steps.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#keep-in-mind",
    "href": "guide/modeling-process.html#keep-in-mind",
    "title": "Modeling process",
    "section": "1.3 Keep in mind",
    "text": "1.3 Keep in mind\n\nFor better understanding and plotting of the model layout, use of proper GIS-coordinates are highly recommended. Water system components that are modelled with multiple nodes in Ribasim (e.g. reservoirs) may share similar coordinates for the storage component (the Basin-node) and the control structures (e.g. Outlet nodes). For clarity, it is recommended to apply small coordinate offsets to enable visualization of topological connections between these co-located nodes.\nWhen preparing input data for Ribasim, all quantities must follow SI units unless explicitly stated otherwise in the documentation.\n\nVolume: cubic meters (m³)\nFlow: cubic meters per second (m³/s)\nWater level / elevation: meters (m) above reference datum\nArea: square meters (m²)",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#necessary-input-data",
    "href": "guide/modeling-process.html#necessary-input-data",
    "title": "Modeling process",
    "section": "1.4 Necessary input data",
    "text": "1.4 Necessary input data\n\nGIS-data layers with accurate geographic information (coordinates) for proper water system representation:\n\nreservoirs\ncontrol structures (weirs, intakes, outlets, pump stations)\ngauges\nriver reaches, canal sections\nwater demand areas (irrigation systems, domestic/industrial abstractions)\n\nIf the above is not available, at minimum map-based sketch with the layout of the water system, paying extra attention to positioning of waterways and connections. Try to assign proper coordinates.\nSome default (static) values (e.g. flow rates, river cross sections) to use that are in line with the typical parameter ranges of the system.\nKeep in mind that values are specified in SI units.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#output",
    "href": "guide/modeling-process.html#output",
    "title": "Modeling process",
    "section": "1.5 Output",
    "text": "1.5 Output\n\nA valid network topology with sufficient basic information for execution by the Ribasim kernel.\nA model schematization that can be discussed with stakeholders.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#goal-1",
    "href": "guide/modeling-process.html#goal-1",
    "title": "Modeling process",
    "section": "2.1 Goal",
    "text": "2.1 Goal\nImprove the model’s realism by incorporating better physical parameters and semi-static boundary conditions to test the model under different flow scenarios.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#steps-1",
    "href": "guide/modeling-process.html#steps-1",
    "title": "Modeling process",
    "section": "2.2 Steps",
    "text": "2.2 Steps\n\nWhere available, use actual Basin profile information (e.g. volume-level relations) for better volume representation. If needed, make estimates of river/canal width and depth in combination with length of river reaches and canal sections to make a reasonable volume estimate.\nImprove Tabulated Rating Curves parameterization where possible.\nAdd local water level controls to the pumps and outlets to be maintained.\nAdd proper capacities to outlets and pumps.\nTry to run the model with semi-static flow boundaries/demands (high and low flow rates).\nAssess whether water flows in a proper direction, where basins drain properly and receive water as needed.\nAssess computational run time and improve the model (network topology and/or model parameterization) to address the nodes that most impact performance.\nDiscuss the model with the stakeholders to confirm that the relevant elements are included. Prioritize next steps.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#necessary-input-data-1",
    "href": "guide/modeling-process.html#necessary-input-data-1",
    "title": "Modeling process",
    "section": "2.3 Necessary input data",
    "text": "2.3 Necessary input data\n\nVolume-level relations for reservoirs and river reaches and canal sections.\nTabulated rating curves.\nWater system control information such as controlled water levels, actual flow rates or maximum flow capacities.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#output-1",
    "href": "guide/modeling-process.html#output-1",
    "title": "Modeling process",
    "section": "2.4 Output",
    "text": "2.4 Output\n\nA valid and running Ribasim model with improved system representation.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#goal-2",
    "href": "guide/modeling-process.html#goal-2",
    "title": "Modeling process",
    "section": "3.1 Goal",
    "text": "3.1 Goal\nTransition from static/semi-static conditions to realistic time-varying boundary conditions and control strategies.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#steps-2",
    "href": "guide/modeling-process.html#steps-2",
    "title": "Modeling process",
    "section": "3.2 Steps",
    "text": "3.2 Steps\n\nCollect and add realistic dynamic forcing (e.g. flow boundaries, Basin fluxes, user demands).\nWhere needed add control nodes to properly represent more complicated control practices of joint system operation.\nRun the model for a limited time period (e.g. 1 year) and assess model behavior (outcome and computational performance).\nImprove the model (network topology and/or model parameterization) to address the nodes that most impact performance.\nDiscuss the model and the underlying assumptions with the stakeholders to confirm that the relevant elements are properly included. Prioritize next steps.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#necessary-input-data-2",
    "href": "guide/modeling-process.html#necessary-input-data-2",
    "title": "Modeling process",
    "section": "3.3 Necessary input data",
    "text": "3.3 Necessary input data\n\nWater system control information e.g. on joint operation of reservoirs.\nproper forcing on the boundaries.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#output-2",
    "href": "guide/modeling-process.html#output-2",
    "title": "Modeling process",
    "section": "3.4 Output",
    "text": "3.4 Output\n\nA better model, both in outcome produced and runtime needed.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#goal-3",
    "href": "guide/modeling-process.html#goal-3",
    "title": "Modeling process",
    "section": "4.1 Goal",
    "text": "4.1 Goal\nImplement water allocation to represent water distribution policies and priority-based water management decisions.\nWhen the analysis situation needs global allocation decisions, the input for the allocation algorithm needs to be specified.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#steps-3",
    "href": "guide/modeling-process.html#steps-3",
    "title": "Modeling process",
    "section": "4.2 Steps",
    "text": "4.2 Steps\n\nExtend/add UserDemand nodes and associated abstraction series (m³/s) and link them to Basin (abstraction and return flow links).\nAdd LevelDemand nodes and link them to Basins.\nAdd FlowDemand nodes and link them to Outlets or Pumps.\nAssign demand priorities, using separate priorities for each demand-type.\nAssign allocation sub-networks.\nWhen relevant, specify which discrete control nodes need to be controlled by allocation.\nRun the model with allocation for a limited time period (e.g. 1 year) and assess model behavior (outcome and computational performance).\nImprove the model (e.g prioritization) to address outstanding issues.\nReview the model implementation and underlying assumptions with the stakeholders to confirm that the underlying (policy) information is properly represented in the model.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#necessary-input-data-3",
    "href": "guide/modeling-process.html#necessary-input-data-3",
    "title": "Modeling process",
    "section": "4.3 Necessary input data",
    "text": "4.3 Necessary input data\n\nReservoir operation and allocation policy information (demands, allocation and route priorities, reservoir rules etc).",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#output-3",
    "href": "guide/modeling-process.html#output-3",
    "title": "Modeling process",
    "section": "4.4 Output",
    "text": "4.4 Output\n\nAn improved water systems model taking allocation policies into account.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#goal-4",
    "href": "guide/modeling-process.html#goal-4",
    "title": "Modeling process",
    "section": "5.1 Goal",
    "text": "5.1 Goal\nVerify that the model adequately represents the real-world water system by comparing simulated results with observed data.\nAs the model is nearly finished, a validation against observations is advised to accommodate acceptance.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#steps-4",
    "href": "guide/modeling-process.html#steps-4",
    "title": "Modeling process",
    "section": "5.2 Steps",
    "text": "5.2 Steps\n\nDiscuss with stakeholders what they consider relevant to accept the model.\nDecide on key performance indicators (e.g. water levels or flows at critical locations) and acceptance criteria to validate model behavior.\nDecide on the period to run and validate the model.\nCollect observations that support the validation.\nCollect forcing data for the associated validation period.\nRun the model for the analysis period.\nAssess model behavior (outcome and computational performance).\nDiscuss the model results with the stakeholders and if needed prioritize improvements.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#necessary-input-data-4",
    "href": "guide/modeling-process.html#necessary-input-data-4",
    "title": "Modeling process",
    "section": "5.3 Necessary input data",
    "text": "5.3 Necessary input data\n\nObservations that can be associated with objects in the network.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#output-4",
    "href": "guide/modeling-process.html#output-4",
    "title": "Modeling process",
    "section": "5.4 Output",
    "text": "5.4 Output\n\nA validated model with documented performance against observations.\nAssessment of model accuracy and limitations for intended applications.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#goal-5",
    "href": "guide/modeling-process.html#goal-5",
    "title": "Modeling process",
    "section": "6.1 Goal",
    "text": "6.1 Goal\nDeploy the validated model for its intended purpose, whether for operational water management, scenario analysis, or decision support.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#steps-5",
    "href": "guide/modeling-process.html#steps-5",
    "title": "Modeling process",
    "section": "6.2 Steps",
    "text": "6.2 Steps\n\nConduct scenario analysis or operational runs as required by the project.\nDocument model assumptions, limitations, and recommended usage.\nProvide training or handover materials to end users.\nEstablish procedures for model updates and maintenance as needed.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/modeling-process.html#output-5",
    "href": "guide/modeling-process.html#output-5",
    "title": "Modeling process",
    "section": "6.3 Output",
    "text": "6.3 Output\n\nA fully operational model ready for its intended application.\nDocumentation supporting model use and interpretation.",
    "crumbs": [
      "How-to guides",
      "Modeling process"
    ]
  },
  {
    "objectID": "guide/qgis.html",
    "href": "guide/qgis.html",
    "title": "QGIS plugin",
    "section": "",
    "text": "1 Opening a model\nThis guide assumes you have already installed the Ribasim core, test models and QGIS plugin as described in the install page. As an example of an existing model, you can use the “basic” model from generated_testmodels.zip.\n\n\n2 Running a model\n\nInstall the Ribasim core application as described in the install section\nOpen a terminal like Powershell or Cmd and navigate to the model directory.\nCall Ribasim with the .toml file as input. E.g. &lt;path_to_ribasim&gt;/ribasim my_model.toml.\nIn your model directory there is now a results/ folder with basin.arrow and flow.arrow output files.\n\n\n\n3 Inspect a (large) model\nFor larger models the node tables can grow quite large. To facilitate inspection, the tables are linked via the node_id field to the Node table, and react to the selection of the Node layer. That is, on selection of certain nodes—either via the map or the attribute table—the selection is also made in all related tables. This is also the case for the Link layer. It helps to set the attribute table of a table of interest to show selected features only (using the dropdown button on the bottom left).\n\n\n\n4 Inspecting results\nBefore inspecting the results, verify that the run was successful and the output files are there.\nClick the “Time Series” button of the iMOD plugin.\n\n\n\n\n\nSelect the layer that you wish to plot. From the “Node” layer you can plot level or storage on Basin nodes. From the “Link” layer you can plot flow over flow links. Note that before switching between these, you typically have to click “Clear” to clear the selection. If you run a simulation with the model open in QGIS, you have to close and re-open the “iMOD Time Series Plot” panel for the new results to be loaded.\nSelect the variables that you want to plot.\n\n\n\n\n\nClick “Select points” and select a node by dragging a rectangle around it on the map. Hold the Ctrl key to select multiple nodes.\n\n\n\n\n\nThe associated time series are shown in the graph.\n\n\n\n\n\nOnly the basin.arrow and flow.arrow can be inspected with the “iMOD Time Series Plot” panel. All Arrow files can be loaded as a layer by dragging the files onto QGIS. Right click the layer and select “Open Attribute Table” to view the contents.\n\n\n5 Reloading models\nIf you made changes to your model outside of QGIS, and want to see the new version in QGIS, the quickest way is to click “Reload Ribasim model” in the model group’s context menu, as shown below:\n\n\n\n\n\nThis avoids the need to remove the group and open the same model again via the plugin. It can be convenient when iteratively building your model via Python, or running new simulations.",
    "crumbs": [
      "How-to guides",
      "QGIS plugin"
    ]
  },
  {
    "objectID": "guide/delwaq.html",
    "href": "guide/delwaq.html",
    "title": "Ribasim Delwaq coupling",
    "section": "",
    "text": "from ribasim import run_ribasim\nIn order to generate the Delwaq input files, we need a completed Ribasim simulation (typically one with a results folder) that ideally also includes some substances and initial concentrations. Let’s take the basic test model for example, which already has set some initial concentrations.\nAll testmodels can be downloaded from here.",
    "crumbs": [
      "How-to guides",
      "Coupling guides",
      "Ribasim Delwaq coupling"
    ]
  },
  {
    "objectID": "guide/delwaq.html#generating-delwaq-input",
    "href": "guide/delwaq.html#generating-delwaq-input",
    "title": "Ribasim Delwaq coupling",
    "section": "1 Generating Delwaq input",
    "text": "1 Generating Delwaq input\n\nfrom pathlib import Path\n\ntoml_path = Path(\"../../generated_testmodels/basic/ribasim.toml\")\n\nassert toml_path.is_file()\n\nThis Ribasim model already has substance concentrations for Cl and Tracer in the input tables, and we will use these to generate the Delwaq input files.\n\nfrom ribasim import Model\n\nmodel = Model.read(toml_path)\n\ndisplay(model.basin.concentration_state)  # basin initial state\ndisplay(model.basin.concentration)  # basin boundaries\ndisplay(model.flow_boundary.concentration)  # flow boundaries\ndisplay(model.level_boundary.concentration)  # level boundaries\nmodel.plot();  # for later comparison\n\nBasin / concentration_state\n\n\n\n\n\n\nnode_id\nsubstance\nconcentration\n\n\nfid\n\n\n\n\n\n\n\n0\n1\nCl\n0.0\n\n\n1\n3\nCl\n0.0\n\n\n2\n6\nCl\n0.0\n\n\n3\n9\nCl\n0.0\n\n\n\n\n\n\n\nBasin / concentration\n\n\n\n\n\n\nnode_id\ntime\nsubstance\ndrainage\nprecipitation\nsurface_runoff\n\n\nfid\n\n\n\n\n\n\n\n\n\n\n0\n1\n2020-01-01\nCl\n0.0\n0.0\n0.0\n\n\n1\n1\n2020-01-02\nCl\n1.0\n1.0\n1.0\n\n\n2\n1\n2020-01-01\nTracer\n1.0\n1.0\n1.0\n\n\n3\n3\n2020-01-01\nCl\n0.0\n0.0\n0.0\n\n\n4\n3\n2020-01-02\nCl\n1.0\n1.0\n1.0\n\n\n5\n3\n2020-01-01\nTracer\n1.0\n1.0\n1.0\n\n\n6\n6\n2020-01-01\nCl\n0.0\n0.0\n0.0\n\n\n7\n6\n2020-01-02\nCl\n1.0\n1.0\n1.0\n\n\n8\n6\n2020-01-01\nTracer\n1.0\n1.0\n1.0\n\n\n9\n9\n2020-01-01\nCl\n0.0\n0.0\n0.0\n\n\n10\n9\n2020-01-02\nCl\n1.0\n1.0\n1.0\n\n\n11\n9\n2020-01-01\nTracer\n1.0\n1.0\n1.0\n\n\n\n\n\n\n\nFlowBoundary / concentration\n\n\n\n\n\n\nnode_id\ntime\nsubstance\nconcentration\n\n\nfid\n\n\n\n\n\n\n\n\n0\n15\n2020-01-01\nCl\n0.0\n\n\n1\n15\n2020-01-01\nTracer\n1.0\n\n\n2\n16\n2020-01-01\nCl\n0.0\n\n\n3\n16\n2020-01-01\nTracer\n1.0\n\n\n\n\n\n\n\nLevelBoundary / concentration\n\n\n\n\n\n\nnode_id\ntime\nsubstance\nconcentration\n\n\nfid\n\n\n\n\n\n\n\n\n0\n11\n2020-01-01\nCl\n34.0\n\n\n1\n17\n2020-01-01\nCl\n34.0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmodel.basin.profile\n\nBasin / profile\n\n\n\n\n\n\nnode_id\narea\nlevel\nstorage\n\n\nfid\n\n\n\n\n\n\n\n\n0\n1\n0.01\n0.0\nNaN\n\n\n1\n1\n1000.00\n1.0\nNaN\n\n\n2\n3\n0.01\n0.0\nNaN\n\n\n3\n3\n1000.00\n1.0\nNaN\n\n\n4\n6\n0.01\n0.0\nNaN\n\n\n5\n6\n1000.00\n1.0\nNaN\n\n\n6\n9\n0.01\n0.0\nNaN\n\n\n7\n9\n1000.00\n1.0\nNaN\n\n\n\n\n\n\n\nLet’s add another tracer to the model, to setup a fraction calculation.\n\nfrom ribasim.delwaq import add_tracer\n\nadd_tracer(model, 11, \"Foo\")\nadd_tracer(model, 15, \"Bar\")\ndisplay(model.flow_boundary.concentration)  # flow boundaries\ndisplay(model.level_boundary.concentration)  # flow boundaries\n\nmodel.write(toml_path)\n\nFlowBoundary / concentration\n\n\n\n\n\n\nnode_id\ntime\nsubstance\nconcentration\n\n\nfid\n\n\n\n\n\n\n\n\n0\n15\n2020-01-01\nCl\n0.0\n\n\n1\n15\n2020-01-01\nTracer\n1.0\n\n\n2\n16\n2020-01-01\nCl\n0.0\n\n\n3\n16\n2020-01-01\nTracer\n1.0\n\n\n4\n15\n2020-01-01\nBar\n1.0\n\n\n\n\n\n\n\nLevelBoundary / concentration\n\n\n\n\n\n\nnode_id\ntime\nsubstance\nconcentration\n\n\nfid\n\n\n\n\n\n\n\n\n0\n11\n2020-01-01\nCl\n34.0\n\n\n1\n17\n2020-01-01\nCl\n34.0\n\n\n2\n11\n2020-01-01\nFoo\n1.0\n\n\n\n\n\n\n\nPosixPath('../../generated_testmodels/basic/ribasim.toml')\n\n\n\nrun_ribasim(toml_path)\n\n┌ Info: Starting a Ribasim simulation at 2026-01-23T16:28:13.863.\n│   toml_path = \"../../generated_testmodels/basic/ribasim.toml\"\n│   cli.ribasim_version = \"2026.1.0-rc1\"\n│   starttime = 2020-01-01T00:00:00\n│   endtime = 2021-01-01T00:00:00\n└   threads = 1\n┌ Warning: The following experimental features are enabled: concentration\n└ @ Ribasim /home/runner/work/Ribasim/Ribasim/core/src/logging.jl:51\nSimulating   0%|                                        |  ETA: N/A\nSimulating   6%|██▎                                     |  ETA: 0:13:40\nSimulating  33%|█████████████▎                          |  ETA: 0:01:41\nSimulating  60%|████████████████████████▏               |  ETA: 0:00:33\nSimulating  88%|███████████████████████████████████▏    |  ETA: 0:00:07\nSimulating 100%|████████████████████████████████████████| Time: 0:00:49\n[ Info: Computation time: 24 seconds, 352 milliseconds\n[ Info: The model finished successfully at 2026-01-23T16:31:05.330.\n\n\nGiven the path to a completed Ribasim simulation, we can call ribasim.delwaq.generate for generating the required input files for Delwaq from scratch. ribasim.delwaq.generate either takes a Model instance, or the path to a toml file, as well as an output_path keyword, where the input for Delwaq will be written. By default it is set to the delwaq folder next to the toml.\n\nfrom ribasim.delwaq import generate\n\n# The default path is the delwaq folder next to the toml\noutput_path = Path(\"../../generated_testmodels/basic/delwaq\")\n\ngraph, substances = generate(model, output_path)\n\n/home/runner/work/Ribasim/Ribasim/python/ribasim/ribasim/delwaq/generate.py:503: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n\n\nThis call produces a handful of files in the user defined folder. Let’s take a look at them:\n\nlist(output_path.iterdir())\n\n[PosixPath('../../generated_testmodels/basic/delwaq/B5_bounddata.inc'),\n PosixPath('../../generated_testmodels/basic/delwaq/ribasim.atr'),\n PosixPath('../../generated_testmodels/basic/delwaq/ribasim.vel'),\n PosixPath('../../generated_testmodels/basic/delwaq/ribasim.vol'),\n PosixPath('../../generated_testmodels/basic/delwaq/delwaq.inp'),\n PosixPath('../../generated_testmodels/basic/delwaq/bndlist.csv'),\n PosixPath('../../generated_testmodels/basic/delwaq/B6_wasteloads.inc'),\n PosixPath('../../generated_testmodels/basic/delwaq/ribasim.are'),\n PosixPath('../../generated_testmodels/basic/delwaq/ribasim.nc'),\n PosixPath('../../generated_testmodels/basic/delwaq/ribasim.poi'),\n PosixPath('../../generated_testmodels/basic/delwaq/B8_initials.inc'),\n PosixPath('../../generated_testmodels/basic/delwaq/dimr_config.xml'),\n PosixPath('../../generated_testmodels/basic/delwaq/ribasim_bndlist.inc'),\n PosixPath('../../generated_testmodels/basic/delwaq/ribasim.len'),\n PosixPath('../../generated_testmodels/basic/delwaq/ribasim.flo'),\n PosixPath('../../generated_testmodels/basic/delwaq/network.csv')]\n\n\nThese files form a complete Delwaq simulation, and can be run by either pointing DIMR to the dimr_config.xml file or pointing Delwaq to the delwaq.inp file.\nNote that the call to generate produces two output variables; graph and substances that are required for parsing the results of the Delwaq model later on. Nonetheless, we can also inspect them here, and inspect the created Delwaq network.\n\nsubstances  # list of substances, as will be present in the Delwaq netcdf output\n\n{'Bar',\n 'Cl',\n 'Continuity',\n 'Drainage',\n 'FlowBoundary',\n 'Foo',\n 'Initial',\n 'LevelBoundary',\n 'Precipitation',\n 'SurfaceRunoff',\n 'Tracer',\n 'UserDemand'}\n\n\nAs you can see, the complete substances list is a combination of user input (Cl and Tracer in the input tables), a Continuity tracer, and tracers for all nodetypes in the Ribasim model. The latter tracers allow for deeper inspection of the Ribasim model, such as debugging the mass balance by plotting fraction graphs. Let’s inspect the graph next, which is the Delwaq network that was created from the Ribasim model:\n\nimport matplotlib.pyplot as plt\nimport networkx as nx\n\n# Let's draw the graph\nfig, ax = plt.subplots(1, 2, figsize=(10, 5))\nnx.draw(\n    graph,\n    pos={k: v[\"pos\"] for k, v in graph.nodes(data=True)},\n    with_labels=True,\n    labels={k: k for k, v in graph.nodes(data=True)},\n    ax=ax[0],\n)\nax[0].set_title(\"Delwaq node IDs\")\nnx.draw(\n    graph,\n    pos={k: v[\"pos\"] for k, v in graph.nodes(data=True)},\n    with_labels=True,\n    labels={k: v[\"id\"] for k, v in graph.nodes(data=True)},\n    ax=ax[1],\n)\nax[1].set_title(\"Ribasim node IDs\")\nfig.suptitle(\"Delwaq network\");\n\n\n\n\n\n\n\n\nHere we plotted the Delwaq network twice, with the node IDs as used by Delwaq on the left hand side, and the corresponding Ribasim node IDs on the right hand side. As you can see, the Delwaq network is very similar to the Ribasim network, with some notable changes:\n\nAll non-Basin or non-boundary types are removed (e.g. no more Pumps or TabulatedRatingCurves)\nBasin boundaries are split into separate nodes and links (drainage, precipitation, and evaporation, as indicated by the duplicated Basin IDs on the right hand side)\nAll node IDs have been renumbered, with boundaries being negative, and Basins being positive.",
    "crumbs": [
      "How-to guides",
      "Coupling guides",
      "Ribasim Delwaq coupling"
    ]
  },
  {
    "objectID": "guide/delwaq.html#parsing-the-results",
    "href": "guide/delwaq.html#parsing-the-results",
    "title": "Ribasim Delwaq coupling",
    "section": "2 Parsing the results",
    "text": "2 Parsing the results\nWith Delwaq having run, we can now parse the results using ribasim.delwaq.parse. This function requires either a path to a toml file, or a Model instance, as well as the graph and substances variables that were output by ribasim.delwaq.generate. You can optionally set the path to the results folder of the Delwaq simulation, if you overrode the default during ribasim.delwaq.generate.\n\nfrom ribasim.delwaq import parse\n\nnmodel = parse(model, graph, substances)\n\nThe parsed model is identical to the Ribasim model, with the exception of the added concentration_external table that contains all tracer results from Delwaq.\n\ndisplay(nmodel.basin.concentration_external)\nprint(substances)\nt = nmodel.basin.concentration_external.df\nt[t.time == t.time.unique()[2]]\n\nBasin / concentration_external\n\n\n\n\n\n\ntime\nnode_id\nconcentration\nsubstance\n\n\nfid\n\n\n\n\n\n\n\n\n0\n2020-01-01\n1\n0.000000\nFlowBoundary\n\n\n1464\n2020-01-01\n1\n0.000000\nTracer\n\n\n2928\n2020-01-01\n1\n0.000000\nLevelBoundary\n\n\n4392\n2020-01-01\n1\n1.000000\nInitial\n\n\n5856\n2020-01-01\n1\n0.000000\nUserDemand\n\n\n...\n...\n...\n...\n...\n\n\n11711\n2020-12-31\n9\n0.000000\nDrainage\n\n\n13175\n2020-12-31\n9\n0.009059\nFoo\n\n\n14639\n2020-12-31\n9\n0.657780\nCl\n\n\n16103\n2020-12-31\n9\n0.499193\nBar\n\n\n17567\n2020-12-31\n9\n0.167443\nSurfaceRunoff\n\n\n\n\n17568 rows × 4 columns\n\n\n\n{'FlowBoundary', 'Tracer', 'LevelBoundary', 'Initial', 'UserDemand', 'Continuity', 'Precipitation', 'Drainage', 'Foo', 'Cl', 'Bar', 'SurfaceRunoff'}\n\n\n\n\n\n\n\n\n\ntime\nnode_id\nconcentration\nsubstance\n\n\nfid\n\n\n\n\n\n\n\n\n8\n2020-01-03\n1\n0.618847\nFlowBoundary\n\n\n1472\n2020-01-03\n1\n0.785120\nTracer\n\n\n2936\n2020-01-03\n1\n0.170560\nLevelBoundary\n\n\n4400\n2020-01-03\n1\n0.044320\nInitial\n\n\n5864\n2020-01-03\n1\n0.000000\nUserDemand\n\n\n7328\n2020-01-03\n1\n1.000000\nContinuity\n\n\n8792\n2020-01-03\n1\n0.083136\nPrecipitation\n\n\n10256\n2020-01-03\n1\n0.000000\nDrainage\n\n\n11720\n2020-01-03\n1\n0.170560\nFoo\n\n\n13184\n2020-01-03\n1\n5.799030\nCl\n\n\n14648\n2020-01-03\n1\n0.000000\nBar\n\n\n16112\n2020-01-03\n1\n0.083136\nSurfaceRunoff\n\n\n9\n2020-01-03\n3\n0.000000\nFlowBoundary\n\n\n1473\n2020-01-03\n3\n0.118851\nTracer\n\n\n2937\n2020-01-03\n3\n0.854525\nLevelBoundary\n\n\n4401\n2020-01-03\n3\n0.026624\nInitial\n\n\n5865\n2020-01-03\n3\n0.000000\nUserDemand\n\n\n7329\n2020-01-03\n3\n1.000000\nContinuity\n\n\n8793\n2020-01-03\n3\n0.059426\nPrecipitation\n\n\n10257\n2020-01-03\n3\n0.000000\nDrainage\n\n\n11721\n2020-01-03\n3\n0.854525\nFoo\n\n\n13185\n2020-01-03\n3\n29.053844\nCl\n\n\n14649\n2020-01-03\n3\n0.000000\nBar\n\n\n16113\n2020-01-03\n3\n0.059426\nSurfaceRunoff\n\n\n10\n2020-01-03\n6\n0.782940\nFlowBoundary\n\n\n1474\n2020-01-03\n6\n0.965784\nTracer\n\n\n2938\n2020-01-03\n6\n0.011620\nLevelBoundary\n\n\n4402\n2020-01-03\n6\n0.022596\nInitial\n\n\n5866\n2020-01-03\n6\n0.000000\nUserDemand\n\n\n7330\n2020-01-03\n6\n1.000000\nContinuity\n\n\n8794\n2020-01-03\n6\n0.091422\nPrecipitation\n\n\n10258\n2020-01-03\n6\n0.000000\nDrainage\n\n\n11722\n2020-01-03\n6\n0.011620\nFoo\n\n\n13186\n2020-01-03\n6\n0.395092\nCl\n\n\n14650\n2020-01-03\n6\n0.782940\nBar\n\n\n16114\n2020-01-03\n6\n0.091422\nSurfaceRunoff\n\n\n11\n2020-01-03\n9\n0.061337\nFlowBoundary\n\n\n1475\n2020-01-03\n9\n0.093076\nTracer\n\n\n2939\n2020-01-03\n9\n0.898593\nLevelBoundary\n\n\n4403\n2020-01-03\n9\n0.008330\nInitial\n\n\n5867\n2020-01-03\n9\n0.000000\nUserDemand\n\n\n7331\n2020-01-03\n9\n1.000000\nContinuity\n\n\n8795\n2020-01-03\n9\n0.015869\nPrecipitation\n\n\n10259\n2020-01-03\n9\n0.000000\nDrainage\n\n\n11723\n2020-01-03\n9\n0.000696\nFoo\n\n\n13187\n2020-01-03\n9\n30.552170\nCl\n\n\n14651\n2020-01-03\n9\n0.061337\nBar\n\n\n16115\n2020-01-03\n9\n0.015869\nSurfaceRunoff\n\n\n\n\n\n\n\nWe can use this table to plot the results of the Delwaq model, both spatially as over time.\n\nfrom ribasim.delwaq import plot_fraction\n\nplot_fraction(nmodel, 1)  # default tracers, should add up to 1\nplot_fraction(nmodel, 9, [\"Foo\", \"Bar\"])  # custom tracers\nplot_fraction(nmodel, 9, [\"Continuity\"])  # mass balance check\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom ribasim.delwaq import plot_spatial\n\nplot_spatial(nmodel, \"Bar\")\nplot_spatial(nmodel, \"Foo\", versus=\"Bar\")",
    "crumbs": [
      "How-to guides",
      "Coupling guides",
      "Ribasim Delwaq coupling"
    ]
  },
  {
    "objectID": "reference/node/pump.html",
    "href": "reference/node/pump.html",
    "title": "Pump",
    "section": "",
    "text": "Pump water from a source node to a destination node. The set flow rate will be pumped unless the intake storage is less than \\(10~m^3\\), in which case the flow rate will be linearly reduced to \\(0~m^3/s\\). The intake must be either a Basin or LevelBoundary. When PID controlled, the pump must point away from the controlled basin in terms of links.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Pump"
    ]
  },
  {
    "objectID": "reference/node/pump.html#static",
    "href": "reference/node/pump.html#static",
    "title": "Pump",
    "section": "1.1 Static",
    "text": "1.1 Static\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\nflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative\n\n\nmin_flow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n(optional, default 0.0)\n\n\nmax_flow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n(optional)\n\n\nmin_upstream_level\nFloat64\n\\(\\text{m}\\)\n(optional)\n\n\nmax_downstream_level\nFloat64\n\\(\\text{m}\\)\n(optional)\n\n\ncontrol_state\nString\n-\n(optional)",
    "crumbs": [
      "Reference",
      "Nodes",
      "Pump"
    ]
  },
  {
    "objectID": "reference/node/pump.html#time",
    "href": "reference/node/pump.html#time",
    "title": "Pump",
    "section": "1.2 Time",
    "text": "1.2 Time\nThis table is the transient form of the Pump table. With this all parameters can be updated over time. In between the given times the flow_rate is interpolated linearly, and outside the flow rate is constant given by the nearest time value. Note that a node_id can be either in this table or in the static one, but not both.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ntime\nDateTime\n-\n\n\n\nflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative\n\n\nmin_flow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n(optional, default 0.0)\n\n\nmax_flow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n(optional)\n\n\nmin_upstream_level\nFloat64\n\\(\\text{m}\\)\n(optional)\n\n\nmax_downstream_level\nFloat64\n\\(\\text{m}\\)\n(optional)",
    "crumbs": [
      "Reference",
      "Nodes",
      "Pump"
    ]
  },
  {
    "objectID": "reference/node/continuous-control.html",
    "href": "reference/node/continuous-control.html",
    "title": "ContinuousControl",
    "section": "",
    "text": "The ContinuousControl node allows for fine control of a controllable property of a connector node, which is updated at each time step. This control can be set up as follows:",
    "crumbs": [
      "Reference",
      "Nodes",
      "ContinuousControl"
    ]
  },
  {
    "objectID": "reference/node/continuous-control.html#variable",
    "href": "reference/node/continuous-control.html#variable",
    "title": "ContinuousControl",
    "section": "1.1 Variable",
    "text": "1.1 Variable\nThe compound variable schema defines linear combinations of variables which can be used as an input for continuous functions described below. This means that this schema defines new variables that look like \\[\n    \\text{weight}_1 * \\text{variable}_1 + \\text{weight}_2 * \\text{variable}_2 + \\ldots,\n\\]\nwhich can be for instance an average or a difference of variables. If a variable comes from a timeseries, a look ahead \\(\\Delta t\\) can be supplied. There is only one compound variable per ContinuousControl node.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\nlisten_node_id\nInt32\n-\ncannot be a Junction\n\n\nvariable\nString\n-\nmust be “level” or “flow_rate”\n\n\nweight\nFloat64\n-\n(optional, default 1.0)\n\n\nlook_ahead\nFloat64\n\\(\\text{s}\\)\nOnly on transient boundary conditions, non-negative (optional, default 0.0).",
    "crumbs": [
      "Reference",
      "Nodes",
      "ContinuousControl"
    ]
  },
  {
    "objectID": "reference/node/continuous-control.html#function",
    "href": "reference/node/continuous-control.html#function",
    "title": "ContinuousControl",
    "section": "1.2 Function",
    "text": "1.2 Function\nThe function table defines a smooth function \\(f\\) interpolating between (input, output) datapoints for each ContinuousControl. The interpolation type is PCHIP, for more information see here. The total computation thus looks like\n\\[\n    f(\\text{weight}_1 * \\text{variable}_1 + \\text{weight}_2 * \\text{variable}_2 + \\ldots).\n\\]\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ninput\nFloat64\n-\n\n\n\noutput\nFloat64\n-\n-\n\n\ncontrolled_variable\nString\n-\nmust be “level” or “flow_rate”",
    "crumbs": [
      "Reference",
      "Nodes",
      "ContinuousControl"
    ]
  },
  {
    "objectID": "reference/node/outlet.html",
    "href": "reference/node/outlet.html",
    "title": "Outlet",
    "section": "",
    "text": "The Outlet lets water flow downstream with a prescribed flow rate. It is similar to the Pump, except that water only flows down, by gravity.\nWhen PID controlled, the Outlet must point towards the controlled Basin in terms of links.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Outlet"
    ]
  },
  {
    "objectID": "reference/node/outlet.html#static",
    "href": "reference/node/outlet.html#static",
    "title": "Outlet",
    "section": "1.1 Static",
    "text": "1.1 Static\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\nflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative\n\n\nmin_flow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n(optional, default 0.0)\n\n\nmax_flow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n(optional)\n\n\nmin_upstream_level\nFloat64\n\\(\\text{m}\\)\n(optional)\n\n\nmax_downstream_level\nFloat64\n\\(\\text{m}\\)\n(optional)\n\n\ncontrol_state\nString\n-\n(optional)",
    "crumbs": [
      "Reference",
      "Nodes",
      "Outlet"
    ]
  },
  {
    "objectID": "reference/node/outlet.html#time",
    "href": "reference/node/outlet.html#time",
    "title": "Outlet",
    "section": "1.2 Time",
    "text": "1.2 Time\nThis table is the transient form of the Outlet table. With this all parameters can be updated over time. In between the given times the flow_rate is interpolated linearly, and outside the flow rate is constant given by the nearest time value. Note that a node_id can be either in this table or in the static one, but not both.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ntime\nDateTime\n-\n\n\n\nflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative\n\n\nmin_flow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n(optional, default 0.0)\n\n\nmax_flow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n(optional)\n\n\nmin_upstream_level\nFloat64\n\\(\\text{m}\\)\n(optional)\n\n\nmax_downstream_level\nFloat64\n\\(\\text{m}\\)\n(optional)",
    "crumbs": [
      "Reference",
      "Nodes",
      "Outlet"
    ]
  },
  {
    "objectID": "reference/node/discrete-control.html",
    "href": "reference/node/discrete-control.html",
    "title": "DiscreteControl",
    "section": "",
    "text": "Set parameters of other nodes based on model state conditions (e.g. Basin level). The table below shows which parameters are controllable for a given node type.\nCode\nusing Ribasim\nusing DataFrames: DataFrame\nusing MarkdownTables\n\nnode_names = Symbol[]\ncontrollable_parameters = String[]\n\nfor node_type in fieldtypes(Ribasim.ParametersIndependent)\n    if node_type &lt;: Ribasim.AbstractParameterNode\n        node_name = nameof(node_type)\n        controllable_fields = Ribasim.controllablefields(node_name)\n        controllable_fields = sort!(string.(controllable_fields))\n        if node_name == :TabulatedRatingCurve\n            controllable_fields = map(\n                s -&gt; replace(s, \"table\" =&gt; \"q(h) relationship (given by level, flow_rate)\"),\n                controllable_fields,\n            )\n        end\n        if !isempty(controllable_fields)\n            push!(node_names, Ribasim.snake_case(node_name))\n            push!(controllable_parameters, join(controllable_fields, \", \"))\n        end\n    end\nend\n\ndf = DataFrame(:node =&gt; node_names, :controllable_parameters =&gt; controllable_parameters)\n\nmarkdown_table(df)\n\n\n\n\n\n\n\n\n\nnode\ncontrollable_parameters\n\n\n\n\nlinear_resistance\nresistance\n\n\nmanning_resistance\nmanning_n\n\n\ntabulated_rating_curve\nq(h) relationship (given by level, flow_rate)\n\n\npump\nflow_rate\n\n\noutlet\nflow_rate\n\n\npid_control\nderivative, integral, proportional, target",
    "crumbs": [
      "Reference",
      "Nodes",
      "DiscreteControl"
    ]
  },
  {
    "objectID": "reference/node/discrete-control.html#variable",
    "href": "reference/node/discrete-control.html#variable",
    "title": "DiscreteControl",
    "section": "1.1 Variable",
    "text": "1.1 Variable\nThe compound variable schema defines linear combinations of variables which can be used in conditions. This means that this schema defines new variables with the given compound_variable_id that look like \\[\n\\text{weight}_1 * \\text{variable}_1 + \\text{weight}_2 * \\text{variable}_2 + \\ldots,\n\\]\nwhich can be for instance an average or a difference of variables. If a variable comes from a time-series, a look ahead \\(\\Delta t\\) can be supplied.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ncompound_variable_id\nInt32\n-\n\n\n\nlisten_node_id\nInt32\n-\ncannot be a Junction\n\n\nvariable\nString\n-\nmust be “level”, “storage” or “flow_rate”\n\n\nweight\nFloat64\n-\n(optional, default 1.0)\n\n\nlook_ahead\nFloat64\n\\(\\text{s}\\)\nOnly on transient boundary conditions, non-negative (optional, default 0.0).\n\n\n\nThese variables can be listened to:\n\nThe storage of a Basin\nThe level of a Basin\nThe level of a LevelBoundary (supports look ahead)\nThe flow rate through one of these node types: Pump, Outlet, TabulatedRatingCurve, LinearResistance, ManningResistance\nThe flow rate of a FlowBoundary (supports look ahead)",
    "crumbs": [
      "Reference",
      "Nodes",
      "DiscreteControl"
    ]
  },
  {
    "objectID": "reference/node/discrete-control.html#condition",
    "href": "reference/node/discrete-control.html#condition",
    "title": "DiscreteControl",
    "section": "1.2 Condition",
    "text": "1.2 Condition\nThe condition schema defines conditions of the form the discrete_control node with this node_id listens to whether the variable given by the node_id and compound_variable_id is greater than threshold_high (at time \\(t\\)) when the condition was false previously, or threshold_low when true previously. Using threshold_low is optional and defaults to threshold_high. When set to a different value—smaller than or equal to threshold_high—it defines a deadband and thus enables hysteresis. In equation form:\n\\[\ncondition=\\begin{cases}\n    \\text{weight}_1 * \\text{variable}_1 + \\text{weight}_2 * \\text{variable}_2 + \\ldots &gt; \\text{greater\\_than}(t), !condition\\_{prev} \\\\\n    \\text{weight}_1 * \\text{variable}_1 + \\text{weight}_2 * \\text{variable}_2 + \\ldots &gt;= \\text{less\\_than}(t), condition\\_{prev}\n\\end{cases}\n\\]\nMultiple conditions with different threshold_high and/or threshold_low values can be defined on the same compound_variable, each with their own unique condition_id.\nNote the strict inequality ‘\\(&gt;\\)’ in the equation above. This means for instance that if a simulation starts with a compound variable exactly at the threshold_high value, the condition is false. The same holds for the threshold_low value, using ‘\\(&gt;=\\)’, so the deadband is inclusive of the thresholds.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n-\n\n\ncompound_variable_id\nInt32\n-\n-\n\n\ncondition_id\nInt32\n-\n-\n\n\nthreshold_high\nFloat64\nvarious\n-\n\n\nthreshold_low\nFloat64\nvarious\n(optional), &lt;= threshold_high\n\n\ntime\nDateTime\n-\n(optional)\n\n\n\nWhen no (or only a single) time is supplied for a given condition_id, the threshold_high value of this condition is unchanging over time.",
    "crumbs": [
      "Reference",
      "Nodes",
      "DiscreteControl"
    ]
  },
  {
    "objectID": "reference/node/discrete-control.html#logic",
    "href": "reference/node/discrete-control.html#logic",
    "title": "DiscreteControl",
    "section": "1.3 Logic",
    "text": "1.3 Logic\nThe logic schema defines which control states are triggered based on the truth of the conditions a DiscreteControl node listens to. DiscreteControl is applied in the Julia core as follows:\n\nDuring the simulation it is checked whether the truth of any of the conditions changes.\nWhen a condition changes, the corresponding DiscreteControl node ID is retrieved (node_id in the condition schema above).\nThe truth value of all the conditions this DiscreteControl node listens to are retrieved, in the order of the condition IDs. This is then converted into a string of “T” for true and “F” for false. This string we call the truth state.\nThe table below determines for the given DiscreteControl node ID and truth state what the corresponding control state is.\nFor all the nodes this DiscreteControl node affects (as given by the “control” links in Links / static), their parameters are set to those parameters in NodeType / static corresponding to the determined control state.\n\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ntruth_state\nString\n-\nConsists of the characters “T” (true), “F” (false) and “*” (any)\n\n\ncontrol_state\nString\n-\n-",
    "crumbs": [
      "Reference",
      "Nodes",
      "DiscreteControl"
    ]
  },
  {
    "objectID": "reference/node/terminal.html",
    "href": "reference/node/terminal.html",
    "title": "Terminal",
    "section": "",
    "text": "A Terminal is a water sink without state or properties. Any water that flows into a Terminal node is removed from the model. No water can come into the model from a Terminal node. For example, Terminal nodes can be used as a downstream boundary.\n\n1 Tables\nNo tables are required for Terminal nodes.\n\n\n2 Equations\nThe incoming node determines the flow into the Terminal node.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Terminal"
    ]
  },
  {
    "objectID": "reference/node/linear-resistance.html",
    "href": "reference/node/linear-resistance.html",
    "title": "LinearResistance",
    "section": "",
    "text": "Bidirectional flow proportional to the level difference between the connected basins.",
    "crumbs": [
      "Reference",
      "Nodes",
      "LinearResistance"
    ]
  },
  {
    "objectID": "reference/node/linear-resistance.html#static",
    "href": "reference/node/linear-resistance.html#static",
    "title": "LinearResistance",
    "section": "1.1 Static",
    "text": "1.1 Static\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\nresistance\nFloat64\n\\(\\text{s}/\\text{m}^2\\)\n-\n\n\nmax_flow_rate\nFloat64\n\\(\\text{m}^3/s\\)\nnon-negative\n\n\ncontrol_state\nString\n-\n(optional)",
    "crumbs": [
      "Reference",
      "Nodes",
      "LinearResistance"
    ]
  },
  {
    "objectID": "reference/node/basin.html",
    "href": "reference/node/basin.html",
    "title": "Basin",
    "section": "",
    "text": "The Basin node represents a flexible, generalized control volume that can be used to model various water bodies and systems. It can exchange water with all other connected nodes, but it has no flow behavior of its own. The connected nodes determine how water is exchanged with the Basin, depending on their specific characteristics and the flow dynamics between them.\nWhile the term “Basin” may traditionally suggest a watershed, in this context, it serves as a wide range of water bodies and control volumes, including those that may not conform to the typical geographical definition of a basin.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#static",
    "href": "reference/node/basin.html#static",
    "title": "Basin",
    "section": "3.1 Static",
    "text": "3.1 Static\nThe Basin / static table can be used to set the static value of variables. The time table has a similar schema, with the time column added. A static value for a variable is only used if there is no dynamic forcing data for that variable. Specifically, if there is either no time table, it is empty, or all timestamps of that variable are missing.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ndrainage\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative\n\n\npotential_evaporation\nFloat64\n\\(\\text{m}/\\text{s}\\)\nnon-negative\n\n\ninfiltration\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative\n\n\nprecipitation\nFloat64\n\\(\\text{m}/\\text{s}\\)\nnon-negative\n\n\nsurface_runoff\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative\n\n\n\nNote that if variables are not set in the static table, default values are used when possible. These are generally zero, e.g. no precipitation, no inflow. If it is not possible to have a reasonable and safe default, a value must be provided in the static table.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#time",
    "href": "reference/node/basin.html#time",
    "title": "Basin",
    "section": "3.2 Time",
    "text": "3.2 Time\nThis table is the transient form of the Basin table. The only difference is that a time column is added.\n\n3.2.1 Interpolation\nAt the given timestamps the values are set in the simulation, such that the timeseries can be seen as forward filled.\n\n\nCode\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom IPython.display import display, Markdown\n\nnp.random.seed(1)\nfig, ax = plt.subplots()\nfontsize = 15\n\nN = 5\ny = np.random.rand(N)\nx = np.cumsum(np.random.rand(N))\n\ndef forward_fill(x_):\n    i = min(max(0, np.searchsorted(x, x_)-1), len(x)-1)\n    return y[i]\n\ndef plot_forward_fill(i):\n    ax.plot([x[i], x[i+1]], [y[i], y[i]], color = \"C0\", label = \"interpolation\" if i == 0 else None)\n\nax.scatter(x[:-1],y[:-1], label = \"forcing at data points\")\nfor i in range(N-1):\n    plot_forward_fill(i)\n\nx_missing_data = np.sort(x[0] + (x[-1] - x[0]) * np.random.rand(5))\ny_missing_data = [forward_fill(x_) for x_ in x_missing_data]\nax.scatter(x_missing_data, y_missing_data, color = \"C0\", marker = \"x\", label = \"missing data\")\nax.set_xticks([])\nax.set_yticks([])\nax.set_xlabel(\"time\", fontsize = fontsize)\nax.set_ylabel(\"forcing\", fontsize = fontsize)\nxlim = ax.get_xlim()\nax.set_xlim(xlim[0], (x[-2] + x[-1])/2)\nax.legend()\n\nmarkdown_table = pd.DataFrame(\n        data = {\n            \"time\" : x,\n            \"forcing\" : y\n        }\n    ).to_markdown(index = False)\n\ndisplay(Markdown(markdown_table))\n\n\n\n\n\ntime\nforcing\n\n\n\n\n0.0923386\n0.417022\n\n\n0.278599\n0.720324\n\n\n0.62416\n0.000114375\n\n\n1.02093\n0.302333\n\n\n1.55974\n0.146756\n\n\n\n\n\n\n\n\n\n\n\n\nAs shown this interpolation type supports missing data, and just maintains the last available value. Because of this for instance precipitation can be updated while evaporation stays the same.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#sec-state",
    "href": "reference/node/basin.html#sec-state",
    "title": "Basin",
    "section": "3.3 State",
    "text": "3.3 State\nThe state table gives the initial water levels of all Basins.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\nlevel\nFloat64\n\\(\\text{m}\\)\n\\(\\ge\\) basin bottom\n\n\n\nEach Basin ID needs to be in the table. To use the final state of an earlier simulation as an initial condition, copy results/basin_state.arrow over to the input_dir, and point the TOML to it:\n[basin]\nstate = \"basin_state.arrow\"\nThis will start of the simulation with the same water levels as the end of the earlier simulation. Since there is no time information in this state, the user is responsible to ensure that the earlier endtime matches the current starttime. This only applies when the user wishes to continue an existing simulation as if it was one continuous simulation.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#profile",
    "href": "reference/node/basin.html#profile",
    "title": "Basin",
    "section": "3.4 Profile",
    "text": "3.4 Profile\nThe profile table defines the physical dimensions of the storage reservoir of each basin. Either storage or area is required.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\nstorage\nFloat64\n\\(\\text{m}^3\\)\nnon-negative and non-decreasing (optional if area is defined)\n\n\narea\nFloat64\n\\(\\text{m}^2\\)\nnon-negative, per node_id: start positive (optional if storage is defined)\n\n\nlevel\nFloat64\n\\(\\text{m}\\)\nincreasing\n\n\n\nThe level is the level at the basin outlet. All levels are defined in meters above a datum that is the same for the entire model. An example of the first 4 rows of such a table is given below. The first 3 rows define the profile of ID 2. The number of rows can vary per ID, and must be at least 2. Using a very large number of rows may impact performance.\n\n\n\nnode_id\narea\nlevel\nstorage\n\n\n\n\n2\n3.14\n0.0\n0.0\n\n\n2\n6.28\n1.0\n4.71\n\n\n2\n9.42\n2.0\n12.56\n\n\n3\n12.56\n3.0\n23.56\n\n\n\nWe use the symbol \\(A\\) for area, \\(h\\) for level and \\(S\\) for storage. The profile provides a function \\(A(h)\\) for each basin. Internally this get converted to two functions, \\(A(h)\\) and \\(h(S)\\). When \\(A\\) is missing, we take the derivative of \\(S\\) with respect to \\(h\\). When \\(S\\) is missing, we integrate \\(A(h)\\) with respect to \\(h\\). The area at the top level is used to convert precipitation flux to an inflow.\n\n3.4.1 Interpolation\n\n3.4.1.1 Level to area\nThe level to area relationship is defined with the Basin / profile data using linear interpolation. An example of such a relationship is shown below.\n\n\nCode\nfig, ax = plt.subplots()\n\n# Data\nN = 3\narea = 25 * np.cumsum(np.random.rand(N))\nlevel = np.cumsum(np.random.rand(N))\n\n# Interpolation\nax.scatter(level,area, label = \"data\")\nax.plot(level,area, label = \"interpolation\")\nax.set_xticks([level[0], level[-1]])\nax.set_xticklabels([\"bottom\", \"last supplied level\"])\nax.set_xlabel(\"level\", fontsize = fontsize)\nax.set_ylabel(\"area\", fontsize = fontsize)\nax.set_yticks([0])\n\n# Extrapolation\nlevel_extrap = 2 * level[-1] - level[-2]\narea_extrap = area[-1]\nax.plot([level[-1], level_extrap], [area[-1], area_extrap], color = \"C0\", ls = \"dashed\", label = \"extrapolation\")\nxlim = ax.get_xlim()\nax.set_xlim(xlim[0], (level[-1] + level_extrap)/2)\n\nax.legend()\nfig.tight_layout()\n\nmarkdown_table = pd.DataFrame(\n        data = {\n            \"level\" : level,\n            \"area\" : area\n        }\n    ).to_markdown(index = False)\n\ndisplay(Markdown(markdown_table))\n\n\n\n\n\nlevel\narea\n\n\n\n\n0.140387\n16.7617\n\n\n0.338488\n27.1943\n\n\n1.13923\n41.1616\n\n\n\n\n\n\n\n\n\n\n\n\nFor this interpolation it is validated that:\n\nThe areas are positive\nThere are at least 2 data points\n\nThis interpolation is used in each evaluation of the right hand side function of the ODE.\n\n\n3.4.1.2 Level to storage\nThe level to storage relationship gives the volume of water in the basin at a given level, which is given by the integral over the level to area relationship from the basin bottom to the given level:\n\\[\n    S(h) = \\int_{h_0}^h A(h')\\text{d}h'.\n\\]\n\n\nCode\nstorage = np.diff(level) * area[:-1] + 0.5 * np.diff(area) * np.diff(level)\nstorage = np.cumsum(storage)\nstorage = np.insert(storage, 0, 0.0)\ndef S(h):\n    i = min(max(0, np.searchsorted(level, h)-1), len(level)-2)\n    return storage[i] + area[i] * (h - level[i]) + 0.5 * (area[i+1] - area[i]) / (level[i+1] - level[i]) * (h - level[i])**2\n\nS = np.vectorize(S)\n\n# Interpolation\nfig, ax = plt.subplots()\nlevel_eval = np.linspace(level[0], level[-1], 100)\nstorage_eval = S(np.linspace(level[0], level[-1], 100))\nax.scatter(level, storage, label = \"storage at datapoints\")\nax.plot(level_eval, storage_eval, label = \"interpolation\")\nax.set_xticks([level[0], level[-1]])\nax.set_xticklabels([\"bottom\", \"last supplied level\"])\nax.set_yticks([0])\nax.set_xlabel(\"level\", fontsize = fontsize)\nax.set_ylabel(\"storage\", fontsize = fontsize)\n\n# Extrapolation\nlevel_eval_extrap = [level[-1], level_extrap]\nstorage_extrap = storage_eval[-1] + area[-1]*level_extrap\nstorage_eval_extrap = [storage_eval[-1], storage_extrap]\n\nax.plot(level_eval_extrap, storage_eval_extrap, color = \"C0\", linestyle = \"dashed\", label = \"extrapolation\")\nxlim = ax.get_xlim()\nax.set_xlim(xlim[0], (level[-1] + level_extrap)/2)\nax.legend()\n\n\n\n\n\n\n\n\n\nfor converting the initial state in terms of levels to an initial state in terms of storages used in the core.\n\n\n3.4.1.3 Interactive Basin example\nThe profile data is not detailed enough to create a full 3D picture of the basin. However, if we assume the profile data is for a stretch of canal of given length, the following plot shows a cross section of the basin.\n\n\nCode\nimport plotly.graph_objects as go\nimport numpy as np\n\ndef linear_interpolation(X, Y, x, maximum):\n    i = min(max(0, np.searchsorted(X, x) - 1), len(X) - 2)\n    return min(Y[i] + (Y[i + 1] - Y[i]) / (X[i + 1] - X[i]) * (x - X[i]), maximum)\n\n\ndef A(h):\n    return linear_interpolation(level, area, h, maximum=area[-1])\n\nfig = go.Figure()\n\nx = area/2\nx = np.concat([-x[::-1], x])\ny = np.concat([level[::-1], level])\n\n# Basin profile\nfig.add_trace(\n    go.Scatter(\n        x = x,\n        y = y,\n        line = dict(color = \"green\"),\n        name = \"Basin profile\"\n    )\n)\n\n# Basin profile extrapolation\ny_extrap = np.array([level[-1], level_extrap])\nx_extrap = np.array([area[-1]/2, area_extrap/2])\nfig.add_trace(\n    go.Scatter(\n        x = x_extrap,\n        y = y_extrap,\n        line = dict(color = \"green\", dash = \"dash\"),\n        name = \"Basin extrapolation\"\n    )\n)\nfig.add_trace(\n    go.Scatter(\n        x = -x_extrap,\n        y = y_extrap,\n        line = dict(color = \"green\", dash = \"dash\"),\n        showlegend = False\n    )\n)\n\n# Water level\nfig.add_trace(\n    go.Scatter(x = [-area[0]/2, area[0]/2],\n               y = [level[0], level[0]],\n               line = dict(color = \"blue\"),\n               name= \"Water level\")\n)\n\n# Fill area\nfig.add_trace(\n    go.Scatter(\n        x = [],\n        y = [],\n        fill = 'tonexty',\n        fillcolor = 'rgba(0, 0, 255, 0.2)',\n        line = dict(color = 'rgba(255, 255, 255, 0)'),\n        name = \"Filled area\"\n    )\n)\n\n# Create slider steps\nsteps = []\nfor h in np.linspace(level[0], level_extrap, 100):\n    a = A(h)\n    s = S(h).item()\n\n\n    i = min(max(0, np.searchsorted(level, h)-1), len(level)-2)\n    if h &gt; level[-1]:\n        i = i + 1\n    fill_area = np.append(area[:i+1], a)\n    fill_level = np.append(level[:i+1], h)\n    fill_x = np.concat([-fill_area[::-1]/2, fill_area/2])\n    fill_y = np.concat([fill_level[::-1], fill_level])\n\n    step = dict(\n        method = \"update\",\n        args=[\n            {\n                \"x\": [x, x_extrap, -x_extrap, [-a/2, a/2], fill_x],\n                \"y\": [y, y_extrap, y_extrap, [h, h], fill_y]\n            },\n            {\"title\": f\"Interactive water level &lt;br&gt; Area: {a:.2f}, Storage: {s:.2f}\"}\n        ],\n        label=str(round(h, 2))\n    )\n    steps.append(step)\n\n# Create slider\nsliders = [dict(\n    active=0,\n    currentvalue={\"prefix\": \"Level: \"},\n    pad={\"t\": 25},\n    steps=steps\n)]\n\nfig.update_layout(\n    title = {\n        \"text\": f\"Interactive water level &lt;br&gt; Area: {area[0]:.2f}, Storage: 0.0\",\n    },\n    yaxis_title = \"level\",\n    sliders = sliders,\n    margin = {\"t\": 100, \"b\": 100}\n)\n\nfig.show()\n\n\n                            \n                                            \n\n\n\n\n3.4.1.4 Storage to level\nThe level is computed from the storage by inverting the level to storage relationship shown above. See here for more details.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#area",
    "href": "reference/node/basin.html#area",
    "title": "Basin",
    "section": "3.5 Area",
    "text": "3.5 Area\nThe optional area table is not used during computation, but provides a place to associate areas in the form of polygons to Basins. Using this makes it easier to recognize which water or land surfaces are represented by Basins.\n\n\n\ncolumn\ntype\nrestriction\n\n\n\n\nnode_id\nInt32\n\n\n\ngeom\nPolygon or MultiPolygon\n(optional)",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#subgrid",
    "href": "reference/node/basin.html#subgrid",
    "title": "Basin",
    "section": "3.6 Subgrid",
    "text": "3.6 Subgrid\nThe subgrid table defines a piecewise linear interpolation from a basin water level to a subgrid element water level. Many subgrid elements may be associated with a single basin, each with distinct interpolation functions. This functionality can be used to translate a single lumped basin level to a more spatially detailed representation (e.g comparable to the output of a hydrodynamic simulation).\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nsubgrid_id\nInt32\n-\n\n\n\nnode_id\nInt32\n-\nconstant per subgrid_id\n\n\nbasin_level\nFloat64\n\\(\\text{m}\\)\n\n\n\nsubgrid_level\nFloat64\n\\(\\text{m}\\)\n\n\n\n\nThe table below shows example input for two subgrid elements:\n\n\n\nsubgrid_id\nnode_id\nbasin_level\nsubgrid_level\n\n\n\n\n1\n9\n0.0\n0.0\n\n\n1\n9\n1.0\n1.0\n\n\n1\n9\n2.0\n2.0\n\n\n2\n9\n0.0\n0.5\n\n\n2\n9\n1.0\n1.5\n\n\n2\n9\n2.0\n2.5\n\n\n\nBoth subgrid elements use the water level of the basin with node_id 9 to interpolate to their respective water levels. The first element has a one to one connection with the water level; the second also has a one to one connection, but is offset by half a meter. A basin water level of 0.3 would be translated to a water level of 0.3 for the first subgrid element, and 0.8 for the second. Water levels beyond the last basin_level are linearly extrapolated.\nNote that the interpolation to subgrid water level is not constrained by any water balance within Ribasim. Generally, to create physically meaningful subgrid water levels, the subgrid table must be parametrized properly such that the spatially integrated water volume of the subgrid elements agrees with the total storage volume of the basin.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#subgrid-time",
    "href": "reference/node/basin.html#subgrid-time",
    "title": "Basin",
    "section": "3.7 Subgrid time",
    "text": "3.7 Subgrid time\nThis table is the transient form of the Subgrid table. The only difference is that a time column is added. With this the subgrid relations can be updated over time. Note that a node_id can be either in this table or in the static one, but not both. That means for each Basin all subgrid relations are either static or dynamic.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#sec-basin-conc",
    "href": "reference/node/basin.html#sec-basin-conc",
    "title": "Basin",
    "section": "3.8 Concentration",
    "text": "3.8 Concentration\nThis table defines the concentration of substances for the inflow boundaries of a Basin node.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ntime\nDateTime\n-\n\n\n\nsubstance\nString\n\ncan correspond to known Delwaq substances\n\n\ndrainage\nFloat64\n\\(\\text{g}/\\text{m}^3\\)\n(optional)\n\n\nprecipitation\nFloat64\n\\(\\text{g}/\\text{m}^3\\)\n(optional)\n\n\nsurface_runoff\nFloat64\n\\(\\text{g}/\\text{m}^3\\)\n(optional)",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#sec-basin-conc-state",
    "href": "reference/node/basin.html#sec-basin-conc-state",
    "title": "Basin",
    "section": "3.9 Concentration state",
    "text": "3.9 Concentration state\nThis table defines the concentration of substances in the Basin at the start of the simulation.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\nsubstance\nString\n-\ncan correspond to known Delwaq substances\n\n\nconcentration\nFloat64\n\\(\\text{g}/\\text{m}^3\\)",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#concentration-external",
    "href": "reference/node/basin.html#concentration-external",
    "title": "Basin",
    "section": "3.10 Concentration external",
    "text": "3.10 Concentration external\nThis table is used for (external) concentrations, that can be used for Control lookups.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ntime\nDateTime\n-\n\n\n\nsubstance\nString\n-\ncan correspond to known Delwaq substances\n\n\nconcentration\nFloat64\n\\(\\text{g}/\\text{m}^3\\)",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#sec-reduction-factor",
    "href": "reference/node/basin.html#sec-reduction-factor",
    "title": "Basin",
    "section": "4.1 The reduction factor",
    "text": "4.1 The reduction factor\nAt several points in the equations below a reduction factor is used. This is a term that makes certain transitions more smooth, for instance when a pump stops providing water when its source basin dries up. The reduction factor is given by\n\\[\\begin{align}\n    \\phi(x; p) =\n    \\begin{cases}\n    0 &\\text{if}\\quad x &lt; 0 \\\\\n        -2 \\left(\\frac{x}{p}\\right)^3 + 3\\left(\\frac{x}{p}\\right)^2 &\\text{if}\\quad 0 \\le x \\le p \\\\\n        1 &\\text{if}\\quad x &gt; p\n    \\end{cases}\n\\end{align}\\]\nHere \\(p &gt; 0\\) is the threshold value which determines the interval \\([0,p]\\) of the smooth transition between \\(0\\) and \\(1\\), see the plot below.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x, p = 3):\n    x_scaled = x / p\n    phi = (-2 * x_scaled + 3) * x_scaled**2\n    phi = np.where(x &lt; 0, 0, phi)\n    phi = np.where(x &gt; p, 1, phi)\n\n    return phi\n\nfontsize = 15\np = 3\nN = 100\nx_min = -1\nx_max = 4\nx = np.linspace(x_min,x_max,N)\nphi = f(x,p)\n\nfig,ax = plt.subplots(dpi=80)\nax.plot(x,phi)\n\ny_lim = ax.get_ylim()\n\nax.set_xticks([0,p], [0,\"$p$\"], fontsize=fontsize)\nax.set_yticks([0,1], [0,1], fontsize=fontsize)\nax.hlines([0,1],x_min,x_max, color = \"k\", ls = \":\", zorder=-1)\nax.vlines([0,p], *y_lim, color = \"k\", ls = \":\")\nax.set_xlim(x_min,x_max)\nax.set_xlabel(\"$x$\", fontsize=fontsize)\nax.set_ylabel(r\"$\\phi(x;p)$\", fontsize=fontsize)\nax.set_ylim(y_lim)\n\nfig.tight_layout()\nplt.show()",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#precipitation",
    "href": "reference/node/basin.html#precipitation",
    "title": "Basin",
    "section": "4.2 Precipitation",
    "text": "4.2 Precipitation\nThe precipitation term is given by\n\\[\n    Q_P = P \\cdot A.\n\\tag{1}\\]\nHere \\(P = P(t)\\) is the precipitation rate and \\(A\\) is the area given at the highest level in the Basin / profile table. Precipitation in the Basin area is assumed to be directly added to the Basin storage. The modeler needs to ensure all precipitation enters the model, and there is no overlap in the maximum profile areas, otherwise extra water is created. If a part of the catchment is not in any Basin profile, the modeler has to verify that water source is not forgotten. It can for instance be converted to a flow rate and added to a Basin as a FlowBoundary.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#evaporation",
    "href": "reference/node/basin.html#evaporation",
    "title": "Basin",
    "section": "4.3 Evaporation",
    "text": "4.3 Evaporation\nThe evaporation term is given by\n\\[\n    Q_E = E_\\text{pot} \\cdot A(u) \\cdot \\phi(d;0.1).\n\\tag{2}\\]\nHere \\(E_\\text{pot} = E_\\text{pot}(t)\\) is the potential evaporation rate and \\(A\\) is the wetted area. \\(\\phi\\) is the reduction factor which depends on the depth \\(d\\). It provides a smooth gradient as \\(u \\rightarrow 0\\).\nA straightforward formulation \\(Q_E = \\mathrm{max}(E_\\text{pot} A(u), 0)\\) is unsuitable, as \\(\\frac{\\mathrm{d}Q_E}{\\mathrm{d}u}(u=0)\\) is not well-defined.\nA non-smooth derivative results in extremely small timesteps and long computation time. In a physical interpretation, evaporation is switched on or off per individual droplet of water. In general, the effect of the reduction term is negligible, or not even necessary. As a surface water dries, its wetted area decreases and so does the evaporative flux. However, for (simplified) cases with constant wetted surface (a rectangular profile), evaporation only stops at \\(u = 0\\).",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/basin.html#infiltration-surface-runoff-and-drainage",
    "href": "reference/node/basin.html#infiltration-surface-runoff-and-drainage",
    "title": "Basin",
    "section": "4.4 Infiltration, Surface Runoff and Drainage",
    "text": "4.4 Infiltration, Surface Runoff and Drainage\nInfiltration and surface runoff is provided as a lump sum for the Basin. If Ribasim is coupled with MODFLOW 6, the infiltration is computed as the sum of all positive flows of the MODFLOW 6 boundary conditions in the Basin:\n\\[\n    Q_\\text{inf} = \\sum_{i=1}^{n} \\sum_{j=1}^{m} \\max(Q_{\\mathrm{mf6}_{i,j}}, 0.0)\n\\tag{3}\\]\nWhere \\(i\\) is the index of the boundary condition, \\(j\\) the MODFLOW 6 cell index, \\(n\\) the number of boundary conditions, and \\(\\text{m}\\) the number of MODFLOW 6 cells in the Basin. \\(Q_{\\mathrm{mf6}_{i,j}}\\) is the flow computed by MODFLOW 6 for cell \\(j\\) for boundary condition \\(i\\).\nDrainage is a lump sum for the Basin, and consists of the sum of the absolute value of all negative flows of the MODFLOW 6 boundary conditions in the Basin.\n\\[\n    Q_\\text{drn} = \\sum_{i=1}^{n} \\sum_{j=1}^{m} \\left| \\min(Q_{\\mathrm{mf6}_{i,j}}, 0.0) \\right|\n\\tag{4}\\]\nThe interaction with MODFLOW 6 boundary conditions is explained in greater detail in the the iMOD Coupler docs.",
    "crumbs": [
      "Reference",
      "Nodes",
      "Basin"
    ]
  },
  {
    "objectID": "reference/node/user-demand.html",
    "href": "reference/node/user-demand.html",
    "title": "UserDemand",
    "section": "",
    "text": "A UserDemand takes water from the Basin that supplies it.\nWhen allocation is not used, a UserDemand node attempts to extract the full demand from the connected Basin. When allocation is used, the amount a UserDemand node is allowed to abstract is determined by the allocation algorithm. This algorithm first tries to allocate from the directly connected basin, and then from other sources whose flow can reach the UserDemand node. Note that demand_priority is used to determine the order in which the UserDemands are allocated water. This parameter is only used when allocation is active and is optional when allocation is not active.\nWhen the connected Basin is almost empty or reaches the minimum level at which the UserDemand can extract water (min_level), it will stop extraction.\nUserDemands need an outgoing flow link along which they can send their return flow, this can also be to the same Basin from which it extracts water. The amount of return flow is always a fraction of the inflow into the UserDemand. The difference is consumed by the UserDemand.",
    "crumbs": [
      "Reference",
      "Nodes",
      "UserDemand"
    ]
  },
  {
    "objectID": "reference/node/user-demand.html#static",
    "href": "reference/node/user-demand.html#static",
    "title": "UserDemand",
    "section": "1.1 Static",
    "text": "1.1 Static\nThis table contains the static form of the UserDemand node.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ndemand\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative\n\n\nreturn_factor\nFloat64\n-\nbetween [0 - 1]\n\n\nmin_level\nFloat64\n\\(\\text{m}\\)\n-\n\n\ndemand_priority\nInt32\n-\npositive",
    "crumbs": [
      "Reference",
      "Nodes",
      "UserDemand"
    ]
  },
  {
    "objectID": "reference/node/user-demand.html#time",
    "href": "reference/node/user-demand.html#time",
    "title": "UserDemand",
    "section": "1.2 Time",
    "text": "1.2 Time\nThis table is the transient form of the UserDemand table. The only difference is that a time column is added. With this the demand and return factor can be updated over time. In between the given times the values are block interpolated (forward fill), and outside the demand is constant given by the nearest time value. The allocation algorithm evaluates the interpolation at the start of the allocation time step. The demand_priority is not allowed to change over time. Note that a node_id can be either in this table or in the static one, but not both.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ntime\nDateTime\n-\n\n\n\ndemand\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative\n\n\nreturn_factor\nFloat64\n-\nbetween [0 - 1]\n\n\nmin_level\nFloat64\n\\(\\text{m}\\)\n-\n\n\ndemand_priority\nInt32\n-\npositive\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAlthough it may seem that way, this table does not describe demands that change demand_priority over time. Rather, this table defines a demand(time) relationship for every occurring demand_priority in the table for a certain node_id.",
    "crumbs": [
      "Reference",
      "Nodes",
      "UserDemand"
    ]
  },
  {
    "objectID": "reference/node/user-demand.html#concentration",
    "href": "reference/node/user-demand.html#concentration",
    "title": "UserDemand",
    "section": "1.3 Concentration",
    "text": "1.3 Concentration\nThis table defines the concentration of substances for the flow from the UserDemand.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ntime\nDateTime\n-\n\n\n\nsubstance\nString\n-\ncan correspond to known Delwaq substances\n\n\nconcentration\nFloat64\n\\(\\text{g}/\\text{m}^3\\)",
    "crumbs": [
      "Reference",
      "Nodes",
      "UserDemand"
    ]
  },
  {
    "objectID": "reference/validation.html",
    "href": "reference/validation.html",
    "title": "Validation",
    "section": "",
    "text": "The tables below show the validation rules applied to the input to the Julia core before running the model.\n\n1 Connectivity\nIn the table below, each column shows which node types are allowed to be downstream (or ‘down-control’) of the node type at the top of the column.\n\n\nCode\nusing Ribasim\nusing DataFrames: DataFrame\nusing MarkdownTables\n\nnode_names_snake_case = Symbol[]\nnode_names_camel_case = Symbol[]\nfor (node_name, node_type) in\n    zip(fieldnames(Ribasim.ParametersIndependent), fieldtypes(Ribasim.ParametersIndependent))\n    if node_type &lt;: Ribasim.AbstractParameterNode\n        push!(node_names_snake_case, node_name)\n        push!(node_names_camel_case, nameof(node_type))\n    end\nend\n\nfunction to_symbol(b::Bool)::String\n    return b ? \"✓\" : \"x\"\nend\n\ndf = DataFrame()\ndf[!, :downstream] = node_names_snake_case\n\nfor node_name in node_names_snake_case\n    df[!, node_name] = [\n        (to_symbol(node_name_ in Ribasim.neighbortypes(node_name))) for\n        node_name_ in node_names_snake_case\n    ]\nend\n\nmarkdown_table(df)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndownstream\nbasin\nlinear_resistance\nmanning_resistance\ntabulated_rating_curve\nlevel_boundary\nflow_boundary\npump\noutlet\nterminal\njunction\ndiscrete_control\ncontinuous_control\npid_control\nuser_demand\nlevel_demand\nflow_demand\n\n\n\n\nbasin\nx\n✓\n✓\n✓\nx\n✓\n✓\n✓\nx\n✓\nx\nx\nx\n✓\n✓\nx\n\n\nlinear_resistance\n✓\nx\nx\nx\n✓\nx\nx\nx\nx\n✓\n✓\nx\nx\nx\nx\n✓\n\n\nmanning_resistance\n✓\nx\nx\nx\nx\nx\nx\nx\nx\n✓\n✓\nx\nx\nx\nx\n✓\n\n\ntabulated_rating_curve\n✓\nx\nx\nx\n✓\nx\nx\nx\nx\n✓\n✓\nx\nx\nx\nx\n✓\n\n\nlevel_boundary\nx\n✓\nx\n✓\nx\n✓\n✓\n✓\nx\nx\nx\nx\nx\n✓\nx\nx\n\n\nflow_boundary\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\n\n\npump\n✓\nx\nx\nx\n✓\nx\nx\nx\nx\n✓\n✓\n✓\n✓\nx\nx\n✓\n\n\noutlet\n✓\nx\nx\nx\n✓\nx\nx\nx\nx\n✓\n✓\n✓\n✓\nx\nx\n✓\n\n\nterminal\nx\nx\nx\n✓\nx\n✓\n✓\n✓\nx\n✓\nx\nx\nx\n✓\nx\nx\n\n\njunction\n✓\n✓\n✓\n✓\nx\n✓\n✓\n✓\nx\n✓\nx\nx\nx\n✓\nx\nx\n\n\ndiscrete_control\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\n\n\ncontinuous_control\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\n\n\npid_control\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\n✓\nx\nx\nx\nx\nx\n\n\nuser_demand\n✓\nx\nx\nx\nx\nx\nx\nx\nx\n✓\nx\nx\nx\nx\nx\nx\n\n\nlevel_demand\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\n\n\nflow_demand\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\nx\n\n\n\n\n\n\n\n2 Neighbor amounts\nThe table below shows for each node type between which bounds the amount of in- and outneighbors must be, for both flow and control links.\n\n\nCode\nflow_in_min = Vector{String}()\nflow_in_max = Vector{String}()\nflow_out_min = Vector{String}()\nflow_out_max = Vector{String}()\ncontrol_in_min = Vector{String}()\ncontrol_in_max = Vector{String}()\ncontrol_out_min = Vector{String}()\ncontrol_out_max = Vector{String}()\n\nfunction unbounded(i::Int)::String\n    return i == typemax(Int) ? \"∞\" : string(i)\nend\n\nfor node_name in node_names_camel_case\n    bounds_flow = Ribasim.n_neighbor_bounds_flow(node_name)\n    push!(flow_in_min, string(bounds_flow.in_min))\n    push!(flow_in_max, unbounded(bounds_flow.in_max))\n    push!(flow_out_min, string(bounds_flow.out_min))\n    push!(flow_out_max, unbounded(bounds_flow.out_max))\n\n    bounds_control = Ribasim.n_neighbor_bounds_control(node_name)\n    push!(control_in_min, string(bounds_control.in_min))\n    push!(control_in_max, unbounded(bounds_control.in_max))\n    push!(control_out_min, string(bounds_control.out_min))\n    push!(control_out_max, unbounded(bounds_control.out_max))\nend\n\ndf = DataFrame(;\n    node_type = node_names_snake_case,\n    flow_in_min,\n    flow_in_max,\n    flow_out_min,\n    flow_out_max,\n    control_in_min,\n    control_in_max,\n    control_out_min,\n    control_out_max,\n)\n\nmarkdown_table(df)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnode_type\nflow_in_min\nflow_in_max\nflow_out_min\nflow_out_max\ncontrol_in_min\ncontrol_in_max\ncontrol_out_min\ncontrol_out_max\n\n\n\n\nbasin\n0\n∞\n0\n∞\n0\n1\n0\n0\n\n\nlinear_resistance\n1\n1\n1\n1\n0\n1\n0\n0\n\n\nmanning_resistance\n1\n1\n1\n1\n0\n1\n0\n0\n\n\ntabulated_rating_curve\n1\n1\n1\n1\n0\n1\n0\n0\n\n\nlevel_boundary\n0\n∞\n0\n∞\n0\n0\n0\n0\n\n\nflow_boundary\n0\n0\n1\n1\n0\n0\n0\n0\n\n\npump\n1\n1\n1\n1\n0\n2\n0\n0\n\n\noutlet\n1\n1\n1\n1\n0\n2\n0\n0\n\n\nterminal\n1\n∞\n0\n0\n0\n0\n0\n0\n\n\njunction\n1\n∞\n1\n∞\n0\n0\n0\n0\n\n\ndiscrete_control\n0\n0\n0\n0\n0\n0\n1\n∞\n\n\ncontinuous_control\n0\n0\n0\n0\n0\n0\n1\n∞\n\n\npid_control\n0\n0\n0\n0\n0\n1\n1\n1\n\n\nuser_demand\n1\n1\n1\n1\n0\n0\n0\n0\n\n\nlevel_demand\n0\n0\n0\n0\n0\n0\n1\n∞\n\n\nflow_demand\n0\n0\n0\n0\n0\n0\n1\n1\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nPump and Outlet can receive two control links, in which case one must be from a FlowDemand, and the other from a control node.",
    "crumbs": [
      "Reference",
      "Validation"
    ]
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "Reference",
    "section": "",
    "text": "These pages contain the test models, node descriptions and Ribasim Python API documentation.",
    "crumbs": [
      "Reference"
    ]
  },
  {
    "objectID": "reference/python/Model.html",
    "href": "reference/python/Model.html",
    "title": "1 Model",
    "section": "",
    "text": "Model()\nA model of inland water resources systems.\n\n\n\n\n\nName\nDescription\n\n\n\n\nallocation\n\n\n\nbasin\n\n\n\ncontinuous_control\n\n\n\ncrs\n\n\n\ndiscrete_control\n\n\n\nendtime\n\n\n\nexperimental\n\n\n\nfilepath\n\n\n\nflow_boundary\n\n\n\nflow_demand\n\n\n\ninput_dir\n\n\n\ninterpolation\n\n\n\njunction\n\n\n\nlevel_boundary\n\n\n\nlevel_demand\n\n\n\nlinear_resistance\n\n\n\nlink\n\n\n\nlogging\n\n\n\nmanning_resistance\n\n\n\nmodel_config\n\n\n\noutlet\n\n\n\npid_control\n\n\n\npump\n\n\n\nresults\n\n\n\nresults_dir\n\n\n\nresults_path\nGet the path to the results directory if it exists.\n\n\nribasim_version\n\n\n\nsolver\n\n\n\nstarttime\n\n\n\ntabulated_rating_curve\n\n\n\nterminal\n\n\n\ntoml_path\nGet the path to the TOML file if it exists.\n\n\nuse_validation\n\n\n\nuser_demand\n\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ndiff\nCompare two instances of a BaseModel.\n\n\nmodel_dump\n\n\n\nmodel_post_init\n\n\n\nnode_table\nCompute the full sorted NodeTable from all node types.\n\n\nplot\nPlot the nodes, links and allocation networks of the model.\n\n\nplot_control_listen\nPlot the implicit listen links of the model.\n\n\nread\nRead a model from a TOML file.\n\n\nremove_link\nRemove a link from the model.\n\n\nremove_node\nRemove a node from the model, including connected links.\n\n\nset_crs\nSet the coordinate reference system of the data in the model.\n\n\nset_filepath\nSet the filepath of this instance.\n\n\nto_crs\n\n\n\nto_fews\nWrite the model network and results into files used by Delft-FEWS.\n\n\nto_xugrid\nConvert the network to a xugrid.UgridDataset.\n\n\nwrite\nWrite the contents of the model to disk and save it as a TOML configuration file.\n\n\n\n\n\nModel.diff(other, ignore_meta=False)\nCompare two instances of a BaseModel.\n** Warning: This method is experimental and is likely to change. **\nIf they are equal, return None. Otherwise, return a nested dictionary with the differences. When the differences are not a DataFrame (like the toml config), the dict has self and other as key. For DataFrames we return a dict with diff as key, and a datacompy Comparison object.\nWhen ignore_meta is set to True, the meta_* columns in the DataFrames are ignored. Note that in that case the key will still be returned and the value will be None.\n\n\n&gt;&gt;&gt; nbasic == basic\nFalse\n&gt;&gt;&gt; x = nbasic.diff(basic)\n{'basin': {'node': {'diff': &lt;datacompy.core.Compare object at 0x16e5a45c0&gt;},\n        'static': {'diff': &lt;datacompy.core.Compare object at 0x16eb90080&gt;}},\n'solver': {'saveat': {'other': 86400.0, 'self': 0.0}}}\n&gt;&gt;&gt; x[\"basin\"][\"static\"][\"diff\"].report()\nDataComPy Comparison\n--------------------\n...\n\n\n\n\nModel.model_dump(**kwargs)\n\n\n\nModel.model_post_init(__context)\n\n\n\nModel.node_table()\nCompute the full sorted NodeTable from all node types.\n\n\n\nModel.plot(ax=None, indicate_subnetworks=True, aspect_ratio_bound=0.33)\nPlot the nodes, links and allocation networks of the model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nax\nmatplotlib.pyplot.Artist\nAxes on which to draw the plot.\nNone\n\n\nindicate_subnetworks\nbool\nWhether to indicate subnetworks with a convex hull backdrop.\nTrue\n\n\naspect_ratio_bound\nfloat\nThe maximal aspect ratio in (0,1). The smaller this number, the further the figure shape is allowed to be from a square\n0.33\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nax\nmatplotlib.pyplot.Artist\nAxis on which the plot is drawn.\n\n\n\n\n\n\n\nModel.plot_control_listen(ax)\nPlot the implicit listen links of the model.\n\n\n\nModel.read(filepath)\nRead a model from a TOML file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilepath\nstr | PathLike[str]\nThe path to the TOML file.\nrequired\n\n\n\n\n\n\n\nModel.remove_link(link_id)\nRemove a link from the model.\n\n\n\nModel.remove_node(node_id)\nRemove a node from the model, including connected links.\n\n\n\nModel.set_crs(crs)\nSet the coordinate reference system of the data in the model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncrs\nstr\nCoordinate reference system, like “EPSG:4326” for WGS84 latitude longitude.\nrequired\n\n\n\n\n\n\n\nModel.set_filepath(filepath)\nSet the filepath of this instance.\nArgs: filepath (Path): The filepath to set.\n\n\n\nModel.to_crs(crs)\n\n\n\nModel.to_fews(region_home, add_network=True, add_results=True)\nWrite the model network and results into files used by Delft-FEWS.\n** Warning: This method is experimental and is likely to change. **\nTo run this method, the model needs to be written to disk, and have results. The Node, Link and Basin / area tables are written to shapefiles in the REGION_HOME/Config directory. The results are written to NetCDF files in the REGION_HOME/Modules directory. The netCDF files are NetCDF4 with CF-conventions.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nregion_home\nstr | PathLike[str]\nPath to the Delft-FEWS REGION_HOME directory.\nrequired\n\n\nadd_network\nbool\nWrite shapefiles representing the network, enabled by default.\nTrue\n\n\nadd_results\nbool\nWrite the results to NetCDF files, enabled by default.\nTrue\n\n\n\n\n\n\n\nModel.to_xugrid(add_flow=False, add_allocation=False)\nConvert the network to a xugrid.UgridDataset.\nEither the flow or the allocation data can be added, but not both simultaneously. This method will throw ImportError if the optional dependency xugrid isn’t installed.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nadd_flow\nbool\nadd flow results (Optional, defaults to False)\nFalse\n\n\nadd_allocation\nbool\nadd allocation results (Optional, defaults to False)\nFalse\n\n\n\n\n\n\n\nModel.write(filepath)\nWrite the contents of the model to disk and save it as a TOML configuration file.\nIf filepath.parent does not exist, it is created before writing.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilepath\nstr | PathLike[str]\nA file path with .toml extension.\nrequired"
  },
  {
    "objectID": "reference/python/Model.html#attributes",
    "href": "reference/python/Model.html#attributes",
    "title": "1 Model",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nallocation\n\n\n\nbasin\n\n\n\ncontinuous_control\n\n\n\ncrs\n\n\n\ndiscrete_control\n\n\n\nendtime\n\n\n\nexperimental\n\n\n\nfilepath\n\n\n\nflow_boundary\n\n\n\nflow_demand\n\n\n\ninput_dir\n\n\n\ninterpolation\n\n\n\njunction\n\n\n\nlevel_boundary\n\n\n\nlevel_demand\n\n\n\nlinear_resistance\n\n\n\nlink\n\n\n\nlogging\n\n\n\nmanning_resistance\n\n\n\nmodel_config\n\n\n\noutlet\n\n\n\npid_control\n\n\n\npump\n\n\n\nresults\n\n\n\nresults_dir\n\n\n\nresults_path\nGet the path to the results directory if it exists.\n\n\nribasim_version\n\n\n\nsolver\n\n\n\nstarttime\n\n\n\ntabulated_rating_curve\n\n\n\nterminal\n\n\n\ntoml_path\nGet the path to the TOML file if it exists.\n\n\nuse_validation\n\n\n\nuser_demand"
  },
  {
    "objectID": "reference/python/Model.html#methods",
    "href": "reference/python/Model.html#methods",
    "title": "1 Model",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndiff\nCompare two instances of a BaseModel.\n\n\nmodel_dump\n\n\n\nmodel_post_init\n\n\n\nnode_table\nCompute the full sorted NodeTable from all node types.\n\n\nplot\nPlot the nodes, links and allocation networks of the model.\n\n\nplot_control_listen\nPlot the implicit listen links of the model.\n\n\nread\nRead a model from a TOML file.\n\n\nremove_link\nRemove a link from the model.\n\n\nremove_node\nRemove a node from the model, including connected links.\n\n\nset_crs\nSet the coordinate reference system of the data in the model.\n\n\nset_filepath\nSet the filepath of this instance.\n\n\nto_crs\n\n\n\nto_fews\nWrite the model network and results into files used by Delft-FEWS.\n\n\nto_xugrid\nConvert the network to a xugrid.UgridDataset.\n\n\nwrite\nWrite the contents of the model to disk and save it as a TOML configuration file.\n\n\n\n\n\nModel.diff(other, ignore_meta=False)\nCompare two instances of a BaseModel.\n** Warning: This method is experimental and is likely to change. **\nIf they are equal, return None. Otherwise, return a nested dictionary with the differences. When the differences are not a DataFrame (like the toml config), the dict has self and other as key. For DataFrames we return a dict with diff as key, and a datacompy Comparison object.\nWhen ignore_meta is set to True, the meta_* columns in the DataFrames are ignored. Note that in that case the key will still be returned and the value will be None.\n\n\n&gt;&gt;&gt; nbasic == basic\nFalse\n&gt;&gt;&gt; x = nbasic.diff(basic)\n{'basin': {'node': {'diff': &lt;datacompy.core.Compare object at 0x16e5a45c0&gt;},\n        'static': {'diff': &lt;datacompy.core.Compare object at 0x16eb90080&gt;}},\n'solver': {'saveat': {'other': 86400.0, 'self': 0.0}}}\n&gt;&gt;&gt; x[\"basin\"][\"static\"][\"diff\"].report()\nDataComPy Comparison\n--------------------\n...\n\n\n\n\nModel.model_dump(**kwargs)\n\n\n\nModel.model_post_init(__context)\n\n\n\nModel.node_table()\nCompute the full sorted NodeTable from all node types.\n\n\n\nModel.plot(ax=None, indicate_subnetworks=True, aspect_ratio_bound=0.33)\nPlot the nodes, links and allocation networks of the model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nax\nmatplotlib.pyplot.Artist\nAxes on which to draw the plot.\nNone\n\n\nindicate_subnetworks\nbool\nWhether to indicate subnetworks with a convex hull backdrop.\nTrue\n\n\naspect_ratio_bound\nfloat\nThe maximal aspect ratio in (0,1). The smaller this number, the further the figure shape is allowed to be from a square\n0.33\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nax\nmatplotlib.pyplot.Artist\nAxis on which the plot is drawn.\n\n\n\n\n\n\n\nModel.plot_control_listen(ax)\nPlot the implicit listen links of the model.\n\n\n\nModel.read(filepath)\nRead a model from a TOML file.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilepath\nstr | PathLike[str]\nThe path to the TOML file.\nrequired\n\n\n\n\n\n\n\nModel.remove_link(link_id)\nRemove a link from the model.\n\n\n\nModel.remove_node(node_id)\nRemove a node from the model, including connected links.\n\n\n\nModel.set_crs(crs)\nSet the coordinate reference system of the data in the model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ncrs\nstr\nCoordinate reference system, like “EPSG:4326” for WGS84 latitude longitude.\nrequired\n\n\n\n\n\n\n\nModel.set_filepath(filepath)\nSet the filepath of this instance.\nArgs: filepath (Path): The filepath to set.\n\n\n\nModel.to_crs(crs)\n\n\n\nModel.to_fews(region_home, add_network=True, add_results=True)\nWrite the model network and results into files used by Delft-FEWS.\n** Warning: This method is experimental and is likely to change. **\nTo run this method, the model needs to be written to disk, and have results. The Node, Link and Basin / area tables are written to shapefiles in the REGION_HOME/Config directory. The results are written to NetCDF files in the REGION_HOME/Modules directory. The netCDF files are NetCDF4 with CF-conventions.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nregion_home\nstr | PathLike[str]\nPath to the Delft-FEWS REGION_HOME directory.\nrequired\n\n\nadd_network\nbool\nWrite shapefiles representing the network, enabled by default.\nTrue\n\n\nadd_results\nbool\nWrite the results to NetCDF files, enabled by default.\nTrue\n\n\n\n\n\n\n\nModel.to_xugrid(add_flow=False, add_allocation=False)\nConvert the network to a xugrid.UgridDataset.\nEither the flow or the allocation data can be added, but not both simultaneously. This method will throw ImportError if the optional dependency xugrid isn’t installed.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nadd_flow\nbool\nadd flow results (Optional, defaults to False)\nFalse\n\n\nadd_allocation\nbool\nadd allocation results (Optional, defaults to False)\nFalse\n\n\n\n\n\n\n\nModel.write(filepath)\nWrite the contents of the model to disk and save it as a TOML configuration file.\nIf filepath.parent does not exist, it is created before writing.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfilepath\nstr | PathLike[str]\nA file path with .toml extension.\nrequired"
  },
  {
    "objectID": "reference/python/Logging.html",
    "href": "reference/python/Logging.html",
    "title": "1 Logging",
    "section": "",
    "text": "Logging()\nDefines the logging behavior of the core.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nverbosity\nVerbosity\nThe verbosity of the logging: debug/info/warn/error (Optional, defaults to info)\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ndiff\nCompare two instances of a BaseModel.\n\n\nmodel_dump\n\n\n\n\n\n\nLogging.diff(other, ignore_meta=False)\nCompare two instances of a BaseModel.\n** Warning: This method is experimental and is likely to change. **\nIf they are equal, return None. Otherwise, return a nested dictionary with the differences. When the differences are not a DataFrame (like the toml config), the dict has self and other as key. For DataFrames we return a dict with diff as key, and a datacompy Comparison object.\nWhen ignore_meta is set to True, the meta_* columns in the DataFrames are ignored. Note that in that case the key will still be returned and the value will be None.\n\n\n&gt;&gt;&gt; nbasic == basic\nFalse\n&gt;&gt;&gt; x = nbasic.diff(basic)\n{'basin': {'node': {'diff': &lt;datacompy.core.Compare object at 0x16e5a45c0&gt;},\n        'static': {'diff': &lt;datacompy.core.Compare object at 0x16eb90080&gt;}},\n'solver': {'saveat': {'other': 86400.0, 'self': 0.0}}}\n&gt;&gt;&gt; x[\"basin\"][\"static\"][\"diff\"].report()\nDataComPy Comparison\n--------------------\n...\n\n\n\n\nLogging.model_dump(**kwargs)"
  },
  {
    "objectID": "reference/python/Logging.html#attributes",
    "href": "reference/python/Logging.html#attributes",
    "title": "1 Logging",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nverbosity\nVerbosity\nThe verbosity of the logging: debug/info/warn/error (Optional, defaults to info)"
  },
  {
    "objectID": "reference/python/Logging.html#methods",
    "href": "reference/python/Logging.html#methods",
    "title": "1 Logging",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndiff\nCompare two instances of a BaseModel.\n\n\nmodel_dump\n\n\n\n\n\n\nLogging.diff(other, ignore_meta=False)\nCompare two instances of a BaseModel.\n** Warning: This method is experimental and is likely to change. **\nIf they are equal, return None. Otherwise, return a nested dictionary with the differences. When the differences are not a DataFrame (like the toml config), the dict has self and other as key. For DataFrames we return a dict with diff as key, and a datacompy Comparison object.\nWhen ignore_meta is set to True, the meta_* columns in the DataFrames are ignored. Note that in that case the key will still be returned and the value will be None.\n\n\n&gt;&gt;&gt; nbasic == basic\nFalse\n&gt;&gt;&gt; x = nbasic.diff(basic)\n{'basin': {'node': {'diff': &lt;datacompy.core.Compare object at 0x16e5a45c0&gt;},\n        'static': {'diff': &lt;datacompy.core.Compare object at 0x16eb90080&gt;}},\n'solver': {'saveat': {'other': 86400.0, 'self': 0.0}}}\n&gt;&gt;&gt; x[\"basin\"][\"static\"][\"diff\"].report()\nDataComPy Comparison\n--------------------\n...\n\n\n\n\nLogging.model_dump(**kwargs)"
  },
  {
    "objectID": "reference/python/Node.html",
    "href": "reference/python/Node.html",
    "title": "1 Node",
    "section": "",
    "text": "Node(node_id=None, geometry=None, **kwargs)\nDefines a node for the model.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nnode_id\nNonNegativeInt | None\nInteger ID of the node. Must be unique for the model.\n\n\ngeometry\nshapely.geometry.Point\nThe coordinates of the node.\n\n\nname\nstr\nAn optional name of the node.\n\n\nsubnetwork_id\nint\nOptionally adds this node to a subnetwork, which is input for the allocation algorithm.\n\n\nroute_priority\nint\nOptionally overrides the route priority for this node, which is used in the allocation algorithm.\n\n\ncyclic_time\nbool\nOptionally extrapolate forcing timeseries periodically. Defaults to False.\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ninto_geodataframe\n\n\n\n\n\n\nNode.into_geodataframe(node_type, node_id)"
  },
  {
    "objectID": "reference/python/Node.html#attributes",
    "href": "reference/python/Node.html#attributes",
    "title": "1 Node",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nnode_id\nNonNegativeInt | None\nInteger ID of the node. Must be unique for the model.\n\n\ngeometry\nshapely.geometry.Point\nThe coordinates of the node.\n\n\nname\nstr\nAn optional name of the node.\n\n\nsubnetwork_id\nint\nOptionally adds this node to a subnetwork, which is input for the allocation algorithm.\n\n\nroute_priority\nint\nOptionally overrides the route priority for this node, which is used in the allocation algorithm.\n\n\ncyclic_time\nbool\nOptionally extrapolate forcing timeseries periodically. Defaults to False."
  },
  {
    "objectID": "reference/python/Node.html#methods",
    "href": "reference/python/Node.html#methods",
    "title": "1 Node",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ninto_geodataframe\n\n\n\n\n\n\nNode.into_geodataframe(node_type, node_id)"
  },
  {
    "objectID": "reference/python/Solver.html",
    "href": "reference/python/Solver.html",
    "title": "1 Solver",
    "section": "",
    "text": "Solver()\nDefines the numerical solver options.\nFor more details see https://docs.sciml.ai/DiffEqDocs/stable/basics/common_solver_opts/#solver_options.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\nalgorithm\nstr\nThe used numerical time integration algorithm (Optional, defaults to QNDF)\n\n\nsaveat\nfloat\nTime interval in seconds between saves of output data. 0 saves every timestep, inf only saves at start- and endtime. (Optional, defaults to 86400)\n\n\ndt\nfloat\nTimestep of the solver. (Optional, defaults to None which implies adaptive timestepping)\n\n\ndtmin\nfloat\nThe minimum allowed timestep of the solver (Optional, defaults to 0.0)\n\n\ndtmax\nfloat\nThe maximum allowed timestep size (Optional, defaults to 0.0 which implies the total length of the simulation)\n\n\nforce_dtmin\nbool\nIf a smaller dt than dtmin is needed to meet the set error tolerances, the simulation stops, unless force_dtmin = true (Optional, defaults to False)\n\n\nabstol\nfloat\nThe absolute tolerance for adaptive timestepping (Optional, defaults to 1e-7)\n\n\nreltol\nfloat\nThe relative tolerance for adaptive timestepping (Optional, defaults to 1e-7)\n\n\nmaxiters\nint\nThe total number of linear iterations over the whole simulation. (Defaults to 1e9, only needs to be increased for extremely long simulations)\n\n\nsparse\nbool\nWhether a sparse Jacobian matrix is used, which gives a significant speedup for models with &gt;~10 basins.\n\n\nautodiff\nbool\nWhether automatic differentiation instead of fine difference is used to compute the Jacobian. (Optional, defaults to true)\n\n\ndepth_threshold\nfloat\nUniversal depth at which the low storage factor kicks in\n\n\nlevel_difference_threshold\nfloat\nUniversal reduction factor threshold for the level difference of Pump/Outlet and TabulatedRatingCurve nodes\n\n\nevaporate_mass\nbool\nWhether mass is lost due to evaporation in water quality calculations. (Optional, defaults to true)\n\n\nspecialize\nbool\nTrades initialization speed for simulation speed, useful for long-running simulations. (Optional, defaults to false)\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ndiff\nCompare two instances of a BaseModel.\n\n\nmodel_dump\n\n\n\n\n\n\nSolver.diff(other, ignore_meta=False)\nCompare two instances of a BaseModel.\n** Warning: This method is experimental and is likely to change. **\nIf they are equal, return None. Otherwise, return a nested dictionary with the differences. When the differences are not a DataFrame (like the toml config), the dict has self and other as key. For DataFrames we return a dict with diff as key, and a datacompy Comparison object.\nWhen ignore_meta is set to True, the meta_* columns in the DataFrames are ignored. Note that in that case the key will still be returned and the value will be None.\n\n\n&gt;&gt;&gt; nbasic == basic\nFalse\n&gt;&gt;&gt; x = nbasic.diff(basic)\n{'basin': {'node': {'diff': &lt;datacompy.core.Compare object at 0x16e5a45c0&gt;},\n        'static': {'diff': &lt;datacompy.core.Compare object at 0x16eb90080&gt;}},\n'solver': {'saveat': {'other': 86400.0, 'self': 0.0}}}\n&gt;&gt;&gt; x[\"basin\"][\"static\"][\"diff\"].report()\nDataComPy Comparison\n--------------------\n...\n\n\n\n\nSolver.model_dump(**kwargs)"
  },
  {
    "objectID": "reference/python/Solver.html#attributes",
    "href": "reference/python/Solver.html#attributes",
    "title": "1 Solver",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\nalgorithm\nstr\nThe used numerical time integration algorithm (Optional, defaults to QNDF)\n\n\nsaveat\nfloat\nTime interval in seconds between saves of output data. 0 saves every timestep, inf only saves at start- and endtime. (Optional, defaults to 86400)\n\n\ndt\nfloat\nTimestep of the solver. (Optional, defaults to None which implies adaptive timestepping)\n\n\ndtmin\nfloat\nThe minimum allowed timestep of the solver (Optional, defaults to 0.0)\n\n\ndtmax\nfloat\nThe maximum allowed timestep size (Optional, defaults to 0.0 which implies the total length of the simulation)\n\n\nforce_dtmin\nbool\nIf a smaller dt than dtmin is needed to meet the set error tolerances, the simulation stops, unless force_dtmin = true (Optional, defaults to False)\n\n\nabstol\nfloat\nThe absolute tolerance for adaptive timestepping (Optional, defaults to 1e-7)\n\n\nreltol\nfloat\nThe relative tolerance for adaptive timestepping (Optional, defaults to 1e-7)\n\n\nmaxiters\nint\nThe total number of linear iterations over the whole simulation. (Defaults to 1e9, only needs to be increased for extremely long simulations)\n\n\nsparse\nbool\nWhether a sparse Jacobian matrix is used, which gives a significant speedup for models with &gt;~10 basins.\n\n\nautodiff\nbool\nWhether automatic differentiation instead of fine difference is used to compute the Jacobian. (Optional, defaults to true)\n\n\ndepth_threshold\nfloat\nUniversal depth at which the low storage factor kicks in\n\n\nlevel_difference_threshold\nfloat\nUniversal reduction factor threshold for the level difference of Pump/Outlet and TabulatedRatingCurve nodes\n\n\nevaporate_mass\nbool\nWhether mass is lost due to evaporation in water quality calculations. (Optional, defaults to true)\n\n\nspecialize\nbool\nTrades initialization speed for simulation speed, useful for long-running simulations. (Optional, defaults to false)"
  },
  {
    "objectID": "reference/python/Solver.html#methods",
    "href": "reference/python/Solver.html#methods",
    "title": "1 Solver",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndiff\nCompare two instances of a BaseModel.\n\n\nmodel_dump\n\n\n\n\n\n\nSolver.diff(other, ignore_meta=False)\nCompare two instances of a BaseModel.\n** Warning: This method is experimental and is likely to change. **\nIf they are equal, return None. Otherwise, return a nested dictionary with the differences. When the differences are not a DataFrame (like the toml config), the dict has self and other as key. For DataFrames we return a dict with diff as key, and a datacompy Comparison object.\nWhen ignore_meta is set to True, the meta_* columns in the DataFrames are ignored. Note that in that case the key will still be returned and the value will be None.\n\n\n&gt;&gt;&gt; nbasic == basic\nFalse\n&gt;&gt;&gt; x = nbasic.diff(basic)\n{'basin': {'node': {'diff': &lt;datacompy.core.Compare object at 0x16e5a45c0&gt;},\n        'static': {'diff': &lt;datacompy.core.Compare object at 0x16eb90080&gt;}},\n'solver': {'saveat': {'other': 86400.0, 'self': 0.0}}}\n&gt;&gt;&gt; x[\"basin\"][\"static\"][\"diff\"].report()\nDataComPy Comparison\n--------------------\n...\n\n\n\n\nSolver.model_dump(**kwargs)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ribasim",
    "section": "",
    "text": "Ribasim is a water resources model to simulate the physical behavior of a managed open water system based on a set of control rules and a prioritized water allocation strategy.\nRibasim is written in the Julia programming language and is built on top of the SciML: Open Source Software for Scientific Machine Learning libraries.\nThe initial version of Ribasim is developed by Deltares as part of a consortium for the Dutch watersystem. This activity is co-funded by TKI Deltatechnology, a Dutch public–private partnership innovation program from the Ministry of Economic Affairs. Ribasim will be used as the surface water module of the Netherlands Hydrologic Instrument (NHI).\n\nRibasim model of the main water distribution network in the Netherlands.",
    "crumbs": [
      "Overview",
      "Ribasim"
    ]
  },
  {
    "objectID": "concept/modelconcept.html",
    "href": "concept/modelconcept.html",
    "title": "Model concept",
    "section": "",
    "text": "A brief summary of the concept is given in the introduction. As indicated, the model concept is organized in three layers:",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Model concept"
    ]
  },
  {
    "objectID": "concept/modelconcept.html#water-balance-equations",
    "href": "concept/modelconcept.html#water-balance-equations",
    "title": "Model concept",
    "section": "1.1 Water balance equations",
    "text": "1.1 Water balance equations\nThe water balance equation for a drainage basin (Wikipedia contributors 2022) can be defined by a first-order ordinary differential equation (ODE), where the change of the storage \\(S\\) over time is determined by the inflow fluxes minus the outflow fluxes.\n\\[\n\\frac{\\mathrm{d}S}{\\mathrm{d}t} = Q_{in} - Q_{out}\n\\]\nWe can split out the fluxes into separate terms, such as precipitation \\(P\\) and evapotranspiration \\(ET\\). For now other fluxes are combined into \\(Q_{rest}\\). If we define all fluxes entering our reservoir as positive, and those leaving the system as negative, all fluxes can be summed up.\n\\[\n\\frac{\\mathrm{d}S}{\\mathrm{d}t} = P + ET + Q_{rest}\n\\]\nWe don’t use these equations directly. Rather, we use an equivalent formulation where we solve for the cumulative flows instead of the Basin storages. For more details on this see Equations.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Model concept"
    ]
  },
  {
    "objectID": "concept/modelconcept.html#time",
    "href": "concept/modelconcept.html#time",
    "title": "Model concept",
    "section": "1.2 Time",
    "text": "1.2 Time\nThe water balance equation can be applied on many timescales; years, weeks, days or hours. Depending on the application and available data any of these can be the best choice. In Ribasim, we make use of DifferentialEquations.jl and its ODE solvers. Many of these solvers are based on adaptive time stepping, which means the solver will decide how large the time steps can be depending on the state of the system.\nThe forcing, like precipitation, is generally provided as a time series. Ribasim is set up to support unevenly spaced timeseries. The solver will stop on timestamps where new forcing values are available, so they can be loaded as the new value.\nRibasim is essentially a continuous model, rather than daily or hourly. If you want to use hourly forcing, you only need to make sure that your forcing data contains hourly updates. The output frequency can be configured independently. To be able to write a closed water balance, we accumulate the fluxes. This way any variations in between timesteps are also included, and we can output in m³ rather than m³s⁻¹.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Model concept"
    ]
  },
  {
    "objectID": "concept/modelconcept.html#sec-space",
    "href": "concept/modelconcept.html#sec-space",
    "title": "Model concept",
    "section": "1.3 Space",
    "text": "1.3 Space\nThe water balance equation can be applied on different spatial scales. Besides modeling a single lumped watershed, it allows you to divide the area into a network of connected representative elementary watersheds (REWs) (Reggiani, Sivapalan, and Majid Hassanizadeh 1998). At this scale global water balance laws can be formulated by means of integration of point-scale conservation equations over control volumes. Such an approach makes Ribasim a semi-distributed model. In this document we typically use the term “basin” to refer to the REW. Each basin has an associated polygon, and the set of basins is connected to each other as described by a graph, which we call the network. Below is a representation of both on the map.\n\n\n\nMozart Local Surface Water polygons and their drainage.\n\n\nThe network is described as graph. Flow can be bi-directional, and the graph does not have to be acyclic.\n\n\n\n\n\ngraph LR;\n    A[\"basin A\"] --- B[\"basin B\"];\n    A --- C[\"basin C\"];\n    B --- D[\"basin D\"];\n    C --- D;\n\n\n\n\n\n\nInternally a directed graph is used. The direction is defined to be the positive flow direction, and is generally set in the dominant flow direction. The basins are the nodes of the network graph. Basin states and properties such storage volume and wetted area are associated with the nodes (A, B, C, D), as are most forcing data such as precipitation, evaporation, or water demand. Basin connection properties and interbasin flows are associated with the links (the lines between A, B, C, and D) instead.\nMultiple basins may exist within the same spatial polygon, representing different aspects of the surface water system (perennial ditches, ephemeral ditches, or even surface ponding). Figure 1, Figure 2, Figure 3 show the 25.0 m rasterized primary, secondary, and tertiary surface waters as identified by BRT TOP10NL (PDOK 2022) in the Hupsel basin. These systems may represented in multiple ways.\n\n\n\n\n\n\nFigure 1: Hupsel: primary surface water.\n\n\n\n\n\n\n\n\n\nFigure 2: Hupsel: secondary surface water.\n\n\n\n\n\n\n\n\n\nFigure 3: Hupsel: tertiary surface water.\n\n\n\nAs a single basin (A) containing all surface water, discharging to its downstream basin to the west (B):\n\n\n\n\n\ngraph LR;\n    A[\"basin A\"] --&gt; B[\"basin B\"];\n\n\n\n\n\n\nSuch a system may be capable of representing discharge, but it cannot represent residence times or differences in solute concentrations: within a single basin, a drop of water is mixed instantaneously. Instead, we may group the primary (P), secondary (S), and tertiary (T) surface waters. Then T may flow into S, S into P, and P discharges to the downstream basin (B.)\n\n\n\n\n\ngraph LR;\n    T[\"basin T\"] --&gt; S[\"basin S\"];\n    S --&gt; P[\"basin P\"];\n    P --&gt; B[\"basin B\"];\n\n\n\n\n\n\nAs each (sub)basin has its own volume, low throughput (high volume, low discharge, long residence time) and high throughput (low volume, high discharge, short residence time) systems can be represented in a lumped manner; of course, more detail requires more parameters.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Model concept"
    ]
  },
  {
    "objectID": "concept/modelconcept.html#structures-in-a-water-system",
    "href": "concept/modelconcept.html#structures-in-a-water-system",
    "title": "Model concept",
    "section": "1.4 Structures in a water system",
    "text": "1.4 Structures in a water system\nIn addition to free flowing waterbodies, a watersystem typically has structures to control the flow of water. Ribasim uses connector nodes which simplify the hydraulic behavior for the free flowing conditions or structures. The following type of connector nodes are available for this purpose:\n\nTabulatedRatingCurve: one-directional flow based on upstream head. Node type typically used for gravity flow conditions either free flowing open water channels or over a fixed structure.\nLinearResistance: bi-directional flow based on head difference and linear resistance. Node type typically used for bi-directional flow situations or situations where the head difference over a structure determines its actual flow capacity.\nManningResistance: bi-directional flow based on head difference and resistance using Manning-Gauckler formula. Same usage as LinearResistance, providing a better hydrological meaning to the resistance parameterization.\nPump: one-directional structure with a set flow rate. Node type typically used in combination with control to force water over the link.\nOutlet: one-directional gravity structure with a set flow rate. Node type typically used in combination with control to force water over the link, even if there is a mismatch in actual hydraulic capacity. The node type has an automated mechanism to stop the flow when the head difference is zero.\n\nThe control layer can activate or deactivate nodes, set flow rates for the Pump and Outlet, or choose different parameterizations for TabulatedRatingCurve, LinearResistance or ManningResistance.\nConnector nodes are required within a Ribasim network to determine the flow exchange between basins.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Model concept"
    ]
  },
  {
    "objectID": "concept/numerics.html",
    "href": "concept/numerics.html",
    "title": "Numerical considerations",
    "section": "",
    "text": "We want to solve the following initial value problem: \\[\n\\begin{cases}\n    \\frac{\\text{d}\\mathbf{u}}{\\text{d}t} = \\mathbf{f}(\\mathbf{u},t) \\quad t_0 &lt; t &lt; t_\\text{end} \\\\\n    \\mathbf{u}(t_0) = \\mathbf{u}_0\n\\end{cases},\n\\tag{1}\\]\nwhere \\(\\mathbf{f}\\) denotes water_balance! and \\(\\mathbf{u_0} = \\mathbf{0}\\) the initial cumulative flows (and the PID integrals which also start out at \\(0\\)).\nIn general \\(\\mathbf{f}\\) is a non-linear function in \\(\\mathbf{u}\\). These non-linearities are introduced by e.g.:\nThe problem Equation 1 can be solved by various numerical time-integration methods. To do this the time interval \\([t_0,t_\\text{end}]\\) is discretized into a finite number of time points \\(t_0 &lt; t_1 &lt; \\ldots &lt; t_N = t_\\text{end}\\) for which approximate solutions \\(\\mathbf{w}_n \\approx \\mathbf{u}(t_n)\\) are computed. In general we do not assume a fixed timestep (the interval between successive points in time). Rather, the solver attempts to make as large a step as possible while keeping error tolerances within requirements. The solver settings section details the available configuration options.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Numerical considerations"
    ]
  },
  {
    "objectID": "concept/numerics.html#euler-forward",
    "href": "concept/numerics.html#euler-forward",
    "title": "Numerical considerations",
    "section": "1.1 Euler forward",
    "text": "1.1 Euler forward\nThe simplest numerical method is Euler forward: \\[\n\\mathbf{w}_{n+1} = \\mathbf{w}_n + (t_{n+1}-t_n)\\mathbf{f}(\\mathbf{w}_n, t_n).\n\\tag{2}\\]\nHere \\(\\mathbf{w}_{n+1}\\) is given as a simple explicit function of \\(\\mathbf{w}_n\\).",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Numerical considerations"
    ]
  },
  {
    "objectID": "concept/numerics.html#euler-backward",
    "href": "concept/numerics.html#euler-backward",
    "title": "Numerical considerations",
    "section": "1.2 Euler backward",
    "text": "1.2 Euler backward\nEuler backward is formulated as follows: \\[\n\\mathbf{w}_{n+1} = \\mathbf{w}_n + (t_{n+1}-t_n)\\mathbf{f}(\\mathbf{w}_{n+1},t_{n+1}).\n\\tag{3}\\]\nNote that this is an implicit equation for \\(\\mathbf{w}_{n+1}\\), which is non-linear because of the non-linearity of \\(\\mathbf{f}\\).\nGenerally one of the following iterative methods is used for finding solutions to non-linear equations like this:\n\nPicard iteration for fixed points. This method aims to approximate \\(\\mathbf{w}_{n+1}\\) as a fixed point of the function \\[\n\\mathbf{g}(\\mathbf{x}) = \\mathbf{w}_n + (t_{n+1}-t_n)\\mathbf{f}(\\mathbf{x},t_{n+1})\n\\] by iterating \\(\\mathbf{g}\\) on an initial guess of \\(\\mathbf{w}_{n+1}\\);\nNewton iterations: approximate \\(\\mathbf{w}_{n+1}\\) as a root of the function \\[\n\\mathbf{h}(\\mathbf{x}) = \\mathbf{w}_n + (t_{n+1}-t_n)\\mathbf{f}(\\mathbf{x},t_{n+1}) - \\mathbf{x},\n\\] by iteratively finding the root of its linearized form:\n\n\\[\\begin{align}\n\\mathbf{0} =& \\mathbf{h}(\\mathbf{w}_{n+1}^k) + \\mathbf{J}(\\mathbf{h})(\\mathbf{w}_{n+1}^k)(\\mathbf{w}_{n+1}^{k+1}-\\mathbf{w}_{n+1}^k) \\\\\n=& \\mathbf{w}_n + (t_{n+1}-t_n)\\mathbf{f}(\\mathbf{w}_{n+1}^k,t_{n+1}) - \\mathbf{w}_{n+1}^k \\\\ +&\\left[(t_{n+1}-t_n)\\mathbf{J}(\\mathbf{f})(\\mathbf{w}_{n+1}^k)-\\mathbf{I}\\right](\\mathbf{w}_{n+1}^{k+1}-\\mathbf{w}_{n+1}^k).\n\\end{align}\\] Note that this thus requires an evaluation of the Jacobian of \\(\\mathbf{f}\\) and solving a linear system per iteration.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Numerical considerations"
    ]
  },
  {
    "objectID": "concept/numerics.html#basin-profiles",
    "href": "concept/numerics.html#basin-profiles",
    "title": "Numerical considerations",
    "section": "4.1 Basin profiles",
    "text": "4.1 Basin profiles\nThe basin profiles affect \\(\\mathbf{f}\\) in many ways, anywhere where a basin level or area is required.\n\n\n\n\n\n\nNote\n\n\n\nThis section needs to be updated and extended after once this issue is resolved.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Numerical considerations"
    ]
  },
  {
    "objectID": "concept/numerics.html#qh-relations",
    "href": "concept/numerics.html#qh-relations",
    "title": "Numerical considerations",
    "section": "4.2 Q(h) relations",
    "text": "4.2 Q(h) relations\nTabulatedRatingCurve nodes contribute to \\(\\mathbf{f}\\) with terms of the following form:\n\\[\n    Q(h(u))\n\\]\nwhere the continuity of this term is given by the least continuous of \\(Q\\) and \\(h\\).",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Numerical considerations"
    ]
  },
  {
    "objectID": "concept/numerics.html#empty-basins",
    "href": "concept/numerics.html#empty-basins",
    "title": "Numerical considerations",
    "section": "4.3 Empty basins",
    "text": "4.3 Empty basins\nReduction factors are introduced at several points in the definition of \\(\\mathbf{f}\\) to smooth out otherwise discontinuous transitions (e.g. the flow rate of a pump going to zero when the source basin dries out). If flows are not too large with respect to basin storage, this will prevent basins from reaching 0. Rather, the basin gets a very small storage. The reduction factors help with performance, but are also an important tool to avoid getting negative storage in basins. Negative storage needs to be avoided since it is not a real solution, and would introduce water into the model that doesn’t exist. Another tool used to avoid negative storage is the isoutoutofdomain option, which Ribasim makes use of. This rejects timesteps that lead to negative storage, instead retrying with a smaller timestep.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Numerical considerations"
    ]
  },
  {
    "objectID": "concept/equations.html",
    "href": "concept/equations.html",
    "title": "Equations",
    "section": "",
    "text": "In this section we give a formal description of the problem that is solved by Ribasim. The problem is of the form \\[\n    \\frac{\\text{d}\\mathbf{u}}{\\text{d}t} = f(\\mathbf{u},p(t),t), \\quad t \\in [t_0, t_\\text{end}],\n\\]\nwhich is a system of coupled first order differential equations.\nThe model is given by a directed graph, consisting of a set of node IDs (vertices) \\(V\\) and links \\(E\\), consisting of ordered pairs of node IDs. We denote the subset of the nodes given by the Basins \\(B \\subset V\\), and the subset of nodes that prescribe flow \\(N \\subset V\\).\nThe states \\(\\mathbf{u}\\) of the model are given by cumulative flows since the start of the simulation as prescribed by the nodes \\(N\\): \\[\n    u_n(t) = \\int_{t_0}^t q_n\\text{d}t' \\quad \\forall n \\in N,\n\\] as well as by the Basin forcings: \\[\n    u_b^\\text{forcing}(t) = \\int_{t_0}^t q_b^\\text{forcing}\\text{d}t' \\quad \\forall b \\in B.\n\\]\nBecause of this definition, the initial conditions of all states are simple: \\[\n    u_i(t_0) = 0 \\quad \\forall i.\n\\]\nFrom these cumulative flows, the storage in each Basin can be determined at each point in time: \\[\n    S_b(t) = S_i(0) + S^\\text{exact}(t) - u_b^\\text{forcing}(t) + \\sum_{n\\;|\\;(n,b)\\in E} u(t) - \\sum_{n\\;|\\;(b,n)\\in E} u(t),\n\\]\ni.e. the storage is given by:\n\nthe initial storage;\nplus the exactly integrated flows (more on that below);\nminus the cumulative outgoing forcings;\nplus the cumulative horizontal inflows;\nminus the cumulative horizontal outflows.\n\nFrom these storages in combination with the Basin profiles the Basin levels \\(h\\) are computed. The relationship between the profile and the storage is given by \\[\n    S_b = \\int_{h_0}^h A_b(\\ell)\\text{d}\\ell,\n\\]\nwhere \\(A_b\\) is the linear interpolation of the area as a function of the level. These levels are then inputs for determining the flows prescribed by the nodes \\(N\\). From this relation it also follows that\n\\[\n    \\frac{\\text{d}h}{\\text{d}t} = \\frac{1}{A_b},\n\\] and so areas of zero are not allowed in the Basin profiles.\n\n\nThere’s one other type of state, which is not a cumulative flow but a cumulative error. This is the error integral for PID control, further explained in PID equations.\n\n\n\nThe more states the problem has, the more time it takes to solve it. Therefore we want to minimize the number of states. Flows do not have to be states when they can be integrated over time exactly because they do not depend on the other states. This is true for FlowBoundary nodes, and Basin precipitation (which uses a fixed basin area) and drainage.\n\n\n\nThe Jacobian is an \\(N \\times N\\) matrix where \\(N\\) is the number of states in the simulation. It is computed as part of implicit time stepping methods. There are 2 different methods available for computing this matrix: finite difference or automatic differentiation. For more details on the computation of the Jacobian and how it is used in the solvers see numerical considerations.\nThe entries of the Jacobian \\(J\\) are given by \\[\n    J_{i,j} = \\frac{\\partial f_j}{\\partial u_i},\n\\] i.e. \\(J_{i,j}\\) quantifies how \\(f_j\\), the time derivative of state \\(j\\), changes with respect to changes in state \\(i\\). Most of these entries are \\(0\\), because flows in distant parts of the model do not depend on each other.\n\n\n\nThe water balance error quantifies how well the water volume in the model is conserved for each Basin over an output save period, i.e. whether no water erroneously appears or disappears. It looks at the storage rate \\[\n    \\text{storage rate} = \\frac{\\Delta S_b}{\\Delta t}\n\\]\nin a Basin over a time period \\(\\Delta t\\) and compares that to the total inflows and outflows of that Basin over that period. More precisely, we first compute the total inflow and outflow, where:\n\n\\(\\text{total inflow}\\): the precipitation, drainage and horizontal flows into the Basin;\n\\(\\text{total outflow}\\): the evaporation, infiltration and horizontal flows out of the Basin.\n\nWhether a flow is an inflow or an outflow depends on whether the flow contributes to or takes from the Basin storage, which means that this is independent of the link direction. This is determined for each solver timestep individually.\nThen from this we compute the errors:\n\\[\n    \\begin{align}\n    \\text{balance error} =&& \\text{storage rate} - (\\text{total inflow} - \\text{total outflow}) \\\\\n    \\text{relative error}=&& \\frac{\\text{absolute error}}{0.5(\\text{total inflow} + \\text{total outflow})}\n    \\end{align}\n\\] Hence the reference used for computing the relative error is the average of the total inflow and total outflow of the Basin (which are both non-negative).\nThe default tolerances are \\(0.001 \\text{ m}^3\\) for the balance error and \\(0.01\\) for the relative error, which should not be exceeded for realistic models.\nIn extreme cases where the storage rate is many orders of magnitude smaller than the storage itself, these computations can have floating point truncation errors which can lead to large relative errors. This is however only when the storage is roughly \\(\\geq 10^{15}\\) times bigger than the storage rate.\n\n\nSay we have the following model:\n\n\n\n\n\nand we want to calculate the water balance error for Basin 6. We have the following data:\n\nTime period length: \\(10.0 \\text{ s}\\)\nBasin storage start: \\(100.0 \\text{ m}^3\\)\nBasin storage end: \\(50.0 \\text{ m}^3\\)\nUserDemand #11 inflow average: \\(10.0 \\text{ m}^3/\\text{s}\\)\nUserDemand #11 outflow average: \\(5.0 \\text{ m}^3/\\text{s}\\)\nOutlet #7 flow average: \\(- 3.5 \\text{ m}^3/\\text{s}\\)\nOutlet #11 flow average: \\(4.0 \\text{ m}^3/\\text{s}\\)\n\nAnd so we get\n\\[\n\\begin{align}\n    \\text{storage rate} = && \\frac{50.0 - 100.0}{10.0} &= & -6.0 \\text{ m}^3/\\text{s} \\\\\n    \\text{total inflow} = && 5.0 + 3.5 &= & 8.5 \\text{ m}^3/\\text{s}\\\\\n    \\text{total outflow} = && 10.0 + 4.0 &= & 14.0 \\text{ m}^3/\\text{s}\\\\\n    \\text{balance error} = && -6.0 - (8.5 - 14.0) &= & -0.5 \\text{ m}^3/\\text{s}\\\\\n    \\text{relative error} = && \\frac{-0.5}{8.5 + 14.0} &\\approx & -0.022\n\\end{align}\n\\] Note that the balance error and relative error are negative, but we use their absolute value to compare to the respective tolerances.\n\n\n\n\nYou might wonder why in the above explanation the states are given by the cumulative flows and not by the Basin storages, which is arguably conceptually simpler. The reason is that we do not just want to model the storages in the Basins over time, but we also want accurate output of each individual flow, e.g. to model the spread of pollutants.\nWhen the states are given by the storages, generally the individual flows can not accurately be computed from that as a post processing step, because there are more flows than storages. Also, we can only compute flows at individual points in time explicitly, not over a whole interval. When the states are given by the cumulative flows however, the output of the problem solve gives these flows directly, and from those the storage over time can be computed accurately. Hence in short, the formulation above gives more information than a formulation with Basin storages as states.\n\n\n\nRibasim uses OrdinaryDiffEq.jl to provide a numerical solution to the water balance equations. Changes to forcings or parameters such as precipitation, but also the allocated water abstraction is managed through the use of callback functions (SciML Development Team 2022). In a coupled run, the exchanges with MODFLOW 6 are also managed via the use of a callback function. For a more in-depth discussion of numerical computations see Numerical considerations.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Equations"
    ]
  },
  {
    "objectID": "concept/equations.html#the-pid-control-integral-state",
    "href": "concept/equations.html#the-pid-control-integral-state",
    "title": "Equations",
    "section": "",
    "text": "There’s one other type of state, which is not a cumulative flow but a cumulative error. This is the error integral for PID control, further explained in PID equations.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Equations"
    ]
  },
  {
    "objectID": "concept/equations.html#exactly-integrating-flows-to-minimize-the-number-of-states",
    "href": "concept/equations.html#exactly-integrating-flows-to-minimize-the-number-of-states",
    "title": "Equations",
    "section": "",
    "text": "The more states the problem has, the more time it takes to solve it. Therefore we want to minimize the number of states. Flows do not have to be states when they can be integrated over time exactly because they do not depend on the other states. This is true for FlowBoundary nodes, and Basin precipitation (which uses a fixed basin area) and drainage.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Equations"
    ]
  },
  {
    "objectID": "concept/equations.html#the-jacobian",
    "href": "concept/equations.html#the-jacobian",
    "title": "Equations",
    "section": "",
    "text": "The Jacobian is an \\(N \\times N\\) matrix where \\(N\\) is the number of states in the simulation. It is computed as part of implicit time stepping methods. There are 2 different methods available for computing this matrix: finite difference or automatic differentiation. For more details on the computation of the Jacobian and how it is used in the solvers see numerical considerations.\nThe entries of the Jacobian \\(J\\) are given by \\[\n    J_{i,j} = \\frac{\\partial f_j}{\\partial u_i},\n\\] i.e. \\(J_{i,j}\\) quantifies how \\(f_j\\), the time derivative of state \\(j\\), changes with respect to changes in state \\(i\\). Most of these entries are \\(0\\), because flows in distant parts of the model do not depend on each other.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Equations"
    ]
  },
  {
    "objectID": "concept/equations.html#the-water-balance-error",
    "href": "concept/equations.html#the-water-balance-error",
    "title": "Equations",
    "section": "",
    "text": "The water balance error quantifies how well the water volume in the model is conserved for each Basin over an output save period, i.e. whether no water erroneously appears or disappears. It looks at the storage rate \\[\n    \\text{storage rate} = \\frac{\\Delta S_b}{\\Delta t}\n\\]\nin a Basin over a time period \\(\\Delta t\\) and compares that to the total inflows and outflows of that Basin over that period. More precisely, we first compute the total inflow and outflow, where:\n\n\\(\\text{total inflow}\\): the precipitation, drainage and horizontal flows into the Basin;\n\\(\\text{total outflow}\\): the evaporation, infiltration and horizontal flows out of the Basin.\n\nWhether a flow is an inflow or an outflow depends on whether the flow contributes to or takes from the Basin storage, which means that this is independent of the link direction. This is determined for each solver timestep individually.\nThen from this we compute the errors:\n\\[\n    \\begin{align}\n    \\text{balance error} =&& \\text{storage rate} - (\\text{total inflow} - \\text{total outflow}) \\\\\n    \\text{relative error}=&& \\frac{\\text{absolute error}}{0.5(\\text{total inflow} + \\text{total outflow})}\n    \\end{align}\n\\] Hence the reference used for computing the relative error is the average of the total inflow and total outflow of the Basin (which are both non-negative).\nThe default tolerances are \\(0.001 \\text{ m}^3\\) for the balance error and \\(0.01\\) for the relative error, which should not be exceeded for realistic models.\nIn extreme cases where the storage rate is many orders of magnitude smaller than the storage itself, these computations can have floating point truncation errors which can lead to large relative errors. This is however only when the storage is roughly \\(\\geq 10^{15}\\) times bigger than the storage rate.\n\n\nSay we have the following model:\n\n\n\n\n\nand we want to calculate the water balance error for Basin 6. We have the following data:\n\nTime period length: \\(10.0 \\text{ s}\\)\nBasin storage start: \\(100.0 \\text{ m}^3\\)\nBasin storage end: \\(50.0 \\text{ m}^3\\)\nUserDemand #11 inflow average: \\(10.0 \\text{ m}^3/\\text{s}\\)\nUserDemand #11 outflow average: \\(5.0 \\text{ m}^3/\\text{s}\\)\nOutlet #7 flow average: \\(- 3.5 \\text{ m}^3/\\text{s}\\)\nOutlet #11 flow average: \\(4.0 \\text{ m}^3/\\text{s}\\)\n\nAnd so we get\n\\[\n\\begin{align}\n    \\text{storage rate} = && \\frac{50.0 - 100.0}{10.0} &= & -6.0 \\text{ m}^3/\\text{s} \\\\\n    \\text{total inflow} = && 5.0 + 3.5 &= & 8.5 \\text{ m}^3/\\text{s}\\\\\n    \\text{total outflow} = && 10.0 + 4.0 &= & 14.0 \\text{ m}^3/\\text{s}\\\\\n    \\text{balance error} = && -6.0 - (8.5 - 14.0) &= & -0.5 \\text{ m}^3/\\text{s}\\\\\n    \\text{relative error} = && \\frac{-0.5}{8.5 + 14.0} &\\approx & -0.022\n\\end{align}\n\\] Note that the balance error and relative error are negative, but we use their absolute value to compare to the respective tolerances.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Equations"
    ]
  },
  {
    "objectID": "concept/equations.html#why-this-formulation",
    "href": "concept/equations.html#why-this-formulation",
    "title": "Equations",
    "section": "",
    "text": "You might wonder why in the above explanation the states are given by the cumulative flows and not by the Basin storages, which is arguably conceptually simpler. The reason is that we do not just want to model the storages in the Basins over time, but we also want accurate output of each individual flow, e.g. to model the spread of pollutants.\nWhen the states are given by the storages, generally the individual flows can not accurately be computed from that as a post processing step, because there are more flows than storages. Also, we can only compute flows at individual points in time explicitly, not over a whole interval. When the states are given by the cumulative flows however, the output of the problem solve gives these flows directly, and from those the storage over time can be computed accurately. Hence in short, the formulation above gives more information than a formulation with Basin storages as states.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Equations"
    ]
  },
  {
    "objectID": "concept/equations.html#numerical-solution",
    "href": "concept/equations.html#numerical-solution",
    "title": "Equations",
    "section": "",
    "text": "Ribasim uses OrdinaryDiffEq.jl to provide a numerical solution to the water balance equations. Changes to forcings or parameters such as precipitation, but also the allocated water abstraction is managed through the use of callback functions (SciML Development Team 2022). In a coupled run, the exchanges with MODFLOW 6 are also managed via the use of a callback function. For a more in-depth discussion of numerical computations see Numerical considerations.",
    "crumbs": [
      "Concepts",
      "Numerics",
      "Equations"
    ]
  },
  {
    "objectID": "concept/allocation.html",
    "href": "concept/allocation.html",
    "title": "Allocation",
    "section": "",
    "text": "In water resources management, allocation deals with distributing limited water resources among competing demands in a fair and efficient manner. This is particularly important in situations where water demands exceed available supply, requiring a systematic approach to prioritize and optimize water distribution across the entire network. In Ribasim we formulate this with linear programming using JuMP and solve the problem using the HiGHS solver.\n\n\n\n\n\n\nNoteDeveloper Documentation\n\n\n\nFor technical implementation details including how mathematical formulations translate to code, see the Allocation.\n\n\nA concise overview of the interaction between the physical and allocation layers of Ribasim is shown in the diagram below.\n\n\n\n\n\nsequenceDiagram\n    Physical layer-&gt;&gt;+ Allocation layer: Storages, linearized physics\n    Note over Allocation layer: Allocation timestep &lt;br/&gt; t → t + Δt_allocation &lt;br/&gt; \"Prediction\"\n    Allocation layer-&gt;&gt; Physical layer: Allocated flow rates, &lt;br/&gt; controlled Pump/Outlet flow rates\n    Note over Physical layer: Physical layer timesteps &lt;br/&gt; t → t + Δt_allocation &lt;br/&gt; Attempted realization of &lt;br/&gt; allocated flows\n\n\n\n\n\n\n\n\nAllocation is the process of assigning an optimized allocated flow rate to demand nodes in the physical layer of the model based on information about sources and their route priorities, the different demand nodes over various demand priorities, constraints introduced by nodes, local water availability and graph topology. It solves a linearized version of the problem formulated for the physical layer a period of time ahead of the physical layer, while simultaneously optimizing allocated flows and steering certain structures to get the water from (preferred) source to demand. The physics is implemented in an implicit manner, rather like the implicit Euler numerical method.\nThe allocation problem is solved per subnetwork of the Ribasim model. A subnetwork is defined by all nodes that have the same subnetwork ID in the Node table. By default, all nodes get a subnetwork ID of 1. Each subnetwork is used to formulate a linear optimization problem with the JuMP package, which is solved using the HiGHS solver. For more in-depth information see also the example of solving the maximum flow problem with JuMP.jl here.\nWhen we build a Ribasim model in which we want to utilize allocation, it can be computationally efficient and stable to divide a large allocation network into a primary network which connects to multiple subnetworks. The primary network should be the main water system and treats each connected subnetwork as a single demand node.\nWe can first solve an allocation optimization for the primary network, that calculates how to optimally divide the available water to each subnetwork. With this allocated amount for a subnetwork, we can optimize how to divide this water within the subnetwork to the demand nodes.\nSubnetworks are defined by grouping nodes that share the same subnetwork ID in the Node table. The primary network is associated with subnetwork ID 1. This will always represent the main water system. This is shown in Figure 1 below.\n\n\n\n\n\n\nFigure 1: The primary network (subnetwork 1, blue) with connected secondary subnetworks (subnetwork 2 and 3, grey).\n\n\n\nSecondary networks:\n\nCan only connect to the primary network via Pump or Outlet nodes\nCannot connect directly to other secondary networks\nThe demand of a subnetwork to the primary network is the sum of all unmet demands within the subnetwork\nMust have a subnetwork greater than 1.\n\nFor each subnetwork, a linear optimization problem is formulated. If a node has subnetwork ID of 0, it will not be taken into account during optimization. This way you can define subnetworks where allocation is not active.\n\n\n\nIn Ribasim, we optimize and assign allocated flow rates to demand nodes based on:\n\nInformation about sources and their route priorities\nDifferent demand nodes and their priorities\nConstraints from nodes, local water availability and network topology\n\nThe optimization problem aims to minimize the difference between requested demands and supplied amounts, subject to water balance constraints:\n\\[\n\\begin{aligned}\n\\text{min}\\quad & z = \\sum_{i=0}^{N_d} E_i(Q, S) \\\\\n\\text{s.t.}\\quad & \\frac{dS_j}{dt} = \\sum_{k=1}^{N_l} Q_{k}\\\\\n\\end{aligned}\n\\tag{1}\\]\nwhere:\n\n\\(z\\) is the total error\n\\(N_d\\) is the number of demands within a priority [-]\n\\(E_i\\) is a deviation error between allocated and demand as function of flow and storage\n\\(S_j\\) is the storage of node \\(j\\) [m³]\n\\(Q_k\\) is the volumetric flow rate on link \\(k\\), which is positive for inflow and negative for outflow [m³/s]\n\\(N_l\\) is the number of flow links connected to node \\(j\\)\n\\(t\\) is the time [s]\n\n\n\n\nIn the optimization problem, the water balance must be discretized over the allocation timestep.\n\\[\\Delta t = t^{n+1} - t^{n}\\]\nWhere the superscript \\(^n\\) denotes evaluation at the beginning of the timestep and \\(^{n+1}\\) at the end. We then use a backward Euler approximation:\n\\[\\frac{dS}{dt} \\approx \\frac{S^{n+1} - S^{n}}{\\Delta t} = \\sum_{k=1}^{N_l} Q_{k}^{n+1} \\]\nUnder the assumption that\n\nflows are constant over \\(\\Delta t\\)\ncoefficients in linearized equations are evaluated at the beginning of the timestep\nThe allocation timestep \\(\\Delta t\\) is short enough that linearization remains valid\n\n\n\n\nTo use efficient linear programming algorithms, nonlinear relationships can be linearized around the current time \\(t^n\\). For example, a nonlinear relationship between flow \\(Q\\), an upstream variable (\\(x_1\\)) and a downstream variable (\\(x_2\\)), can be linearized as:\n\\[Q(x_1,x_2) \\approx Q(x_1^n,x_2^n) + \\frac{\\partial Q}{\\partial x_1}(x_1^n,x_2^n)(x_1^{n+1}-x_1^n) + \\frac{\\partial Q}{\\partial x_2}(x_1^n,x_2^n)(x_2^{n+1}-x_2^n)\\]\nThis yields a linear programming problem that can be solved efficiently while maintaining acceptable accuracy for small changes around the operating point.\n\n\n\nThe allocation algorithm contains 2 types of optimization:\n\nDemand collection, where water is allocated in the secondary networks with the sole purpose of finding out what the demand of the secondary network is from the primary network;\nAllocation, where water is allocated in all subnetworks, and the amount of water that is allocated to demands is written as output and communicated to the physical layer.\n\nThe full algorithm goes through the following steps:\n\nPerform demand collection in the secondary subnetworks;\nPerform allocation in the primary network;\nPerform sequentially allocation (in the future maybe in parallel) in the subnetworks.\n\nIf no primary network is present, then step 1 and 2 are skipped and the entire network is treated as a single subnetwork.",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#allocation-networks",
    "href": "concept/allocation.html#allocation-networks",
    "title": "Allocation",
    "section": "",
    "text": "Allocation is the process of assigning an optimized allocated flow rate to demand nodes in the physical layer of the model based on information about sources and their route priorities, the different demand nodes over various demand priorities, constraints introduced by nodes, local water availability and graph topology. It solves a linearized version of the problem formulated for the physical layer a period of time ahead of the physical layer, while simultaneously optimizing allocated flows and steering certain structures to get the water from (preferred) source to demand. The physics is implemented in an implicit manner, rather like the implicit Euler numerical method.\nThe allocation problem is solved per subnetwork of the Ribasim model. A subnetwork is defined by all nodes that have the same subnetwork ID in the Node table. By default, all nodes get a subnetwork ID of 1. Each subnetwork is used to formulate a linear optimization problem with the JuMP package, which is solved using the HiGHS solver. For more in-depth information see also the example of solving the maximum flow problem with JuMP.jl here.\nWhen we build a Ribasim model in which we want to utilize allocation, it can be computationally efficient and stable to divide a large allocation network into a primary network which connects to multiple subnetworks. The primary network should be the main water system and treats each connected subnetwork as a single demand node.\nWe can first solve an allocation optimization for the primary network, that calculates how to optimally divide the available water to each subnetwork. With this allocated amount for a subnetwork, we can optimize how to divide this water within the subnetwork to the demand nodes.\nSubnetworks are defined by grouping nodes that share the same subnetwork ID in the Node table. The primary network is associated with subnetwork ID 1. This will always represent the main water system. This is shown in Figure 1 below.\n\n\n\n\n\n\nFigure 1: The primary network (subnetwork 1, blue) with connected secondary subnetworks (subnetwork 2 and 3, grey).\n\n\n\nSecondary networks:\n\nCan only connect to the primary network via Pump or Outlet nodes\nCannot connect directly to other secondary networks\nThe demand of a subnetwork to the primary network is the sum of all unmet demands within the subnetwork\nMust have a subnetwork greater than 1.\n\nFor each subnetwork, a linear optimization problem is formulated. If a node has subnetwork ID of 0, it will not be taken into account during optimization. This way you can define subnetworks where allocation is not active.",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#mathematical-formulation",
    "href": "concept/allocation.html#mathematical-formulation",
    "title": "Allocation",
    "section": "",
    "text": "In Ribasim, we optimize and assign allocated flow rates to demand nodes based on:\n\nInformation about sources and their route priorities\nDifferent demand nodes and their priorities\nConstraints from nodes, local water availability and network topology\n\nThe optimization problem aims to minimize the difference between requested demands and supplied amounts, subject to water balance constraints:\n\\[\n\\begin{aligned}\n\\text{min}\\quad & z = \\sum_{i=0}^{N_d} E_i(Q, S) \\\\\n\\text{s.t.}\\quad & \\frac{dS_j}{dt} = \\sum_{k=1}^{N_l} Q_{k}\\\\\n\\end{aligned}\n\\tag{1}\\]\nwhere:\n\n\\(z\\) is the total error\n\\(N_d\\) is the number of demands within a priority [-]\n\\(E_i\\) is a deviation error between allocated and demand as function of flow and storage\n\\(S_j\\) is the storage of node \\(j\\) [m³]\n\\(Q_k\\) is the volumetric flow rate on link \\(k\\), which is positive for inflow and negative for outflow [m³/s]\n\\(N_l\\) is the number of flow links connected to node \\(j\\)\n\\(t\\) is the time [s]",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#discretization",
    "href": "concept/allocation.html#discretization",
    "title": "Allocation",
    "section": "",
    "text": "In the optimization problem, the water balance must be discretized over the allocation timestep.\n\\[\\Delta t = t^{n+1} - t^{n}\\]\nWhere the superscript \\(^n\\) denotes evaluation at the beginning of the timestep and \\(^{n+1}\\) at the end. We then use a backward Euler approximation:\n\\[\\frac{dS}{dt} \\approx \\frac{S^{n+1} - S^{n}}{\\Delta t} = \\sum_{k=1}^{N_l} Q_{k}^{n+1} \\]\nUnder the assumption that\n\nflows are constant over \\(\\Delta t\\)\ncoefficients in linearized equations are evaluated at the beginning of the timestep\nThe allocation timestep \\(\\Delta t\\) is short enough that linearization remains valid",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#linearization",
    "href": "concept/allocation.html#linearization",
    "title": "Allocation",
    "section": "",
    "text": "To use efficient linear programming algorithms, nonlinear relationships can be linearized around the current time \\(t^n\\). For example, a nonlinear relationship between flow \\(Q\\), an upstream variable (\\(x_1\\)) and a downstream variable (\\(x_2\\)), can be linearized as:\n\\[Q(x_1,x_2) \\approx Q(x_1^n,x_2^n) + \\frac{\\partial Q}{\\partial x_1}(x_1^n,x_2^n)(x_1^{n+1}-x_1^n) + \\frac{\\partial Q}{\\partial x_2}(x_1^n,x_2^n)(x_2^{n+1}-x_2^n)\\]\nThis yields a linear programming problem that can be solved efficiently while maintaining acceptable accuracy for small changes around the operating point.",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#sec-high-level-algorithm",
    "href": "concept/allocation.html#sec-high-level-algorithm",
    "title": "Allocation",
    "section": "",
    "text": "The allocation algorithm contains 2 types of optimization:\n\nDemand collection, where water is allocated in the secondary networks with the sole purpose of finding out what the demand of the secondary network is from the primary network;\nAllocation, where water is allocated in all subnetworks, and the amount of water that is allocated to demands is written as output and communicated to the physical layer.\n\nThe full algorithm goes through the following steps:\n\nPerform demand collection in the secondary subnetworks;\nPerform allocation in the primary network;\nPerform sequentially allocation (in the future maybe in parallel) in the subnetworks.\n\nIf no primary network is present, then step 1 and 2 are skipped and the entire network is treated as a single subnetwork.",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#the-basin-profile",
    "href": "concept/allocation.html#the-basin-profile",
    "title": "Allocation",
    "section": "2.1 The basin profile",
    "text": "2.1 The basin profile\nThe level in a basin is generally a non-linear function of the storage (except when the area is constant). To incorporate this into a linear programming framework, we linearize the basin profile at the current timestep.\n\\[h^{n+1} \\approx h^n + \\frac{dh}{dS}(S^n)(S^{n+1} - S^n)\\]\nwith\n\\[\\frac{dh}{dS}(S^n) = \\frac{1}{A^n}\\]\nand \\(A^n\\) is the area evaluated at the beginning of the time step\n\\[h^{n+1} \\approx h^{n} + \\frac{1}{A^n}(S^{n+1} - S^n)\\]",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#in-and-out-flows",
    "href": "concept/allocation.html#in-and-out-flows",
    "title": "Allocation",
    "section": "2.2 In and out flows",
    "text": "2.2 In and out flows\nIn Ribasim, the in and out flows on a basin are determined by connector nodes (LinearResistance, ManningResistance and TabulatedRatingCurve) and basin forcings (Precipitation, Evaporation and Infiltration, Surface Runoff and Drainage). These flows can be a function of the current basin state and/or a neighboring basin state. Accounting for the non-linearity in allocation can be done through multi variable linearisation:\n\\[ Q^{n+1} \\approx Q^{n} + \\frac{\\partial Q}{\\partial h_1}(h_1^n,h_2^n)(h_1^{n+1} - h_1^{n}) + \\frac{\\partial Q}{\\partial h_2}(h_1^n,h_2^n)(h_2^{n+1} - h_2^{n}) \\]\nHowever, we need to relate the level to a storage (in case of a basin). So we can substitute the linearised basin profile. For example if a non linear flow node connects downstream to a basin and upstream to a level boundary:\n\\[ Q_m^{n+1} \\approx Q_m^{n} + \\frac{1}{A^n}\\frac{\\partial Q_m}{\\partial h_1}(h_1^n, h_2^n) (S_1^{n+1} - S_1^n) + \\frac{\\partial Q}{\\partial h_2}(h_1^n,h_2^n)(h_2^{n+1} - h_2^{n}) \\]",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#boundary-nodes",
    "href": "concept/allocation.html#boundary-nodes",
    "title": "Allocation",
    "section": "2.3 Boundary nodes",
    "text": "2.3 Boundary nodes\nWe have the following boundary nodes in Ribasim:\n\nThe Terminal, where water simply leaves the model\nThe LevelBoundary, which yields fixed water levels; \\(h^{n+1}_{lb}\\) is read from the interpolated timeseries \\(h_{lb}\\) of the node or is a constant value\nThe FlowBoundary, which specifies a flow rate. Here the average outflow of the FlowBoundary in the physical layer over the previous \\(\\Delta t\\) is used as a prediction of the flow rate in the next \\(\\Delta t\\) over which the optimization takes place.\n\n\n\n\n\n\n\nNote\n\n\n\nThe flow rate of a FlowBoundary is given as a timeseries so we could use the interpolation of that timeseries to compute the average flow in the coming \\(\\Delta t_\\text{allocation}\\). However, that would not always be accurate, since FlowBoundary nodes can be deactivated by Discrete Control which can not (easily) be anticipated.",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#control",
    "href": "concept/allocation.html#control",
    "title": "Allocation",
    "section": "3.1 Control",
    "text": "3.1 Control\n\n3.1.1 Control by allocation\nWhen Pumps and Outlets are part of a subnetwork, they can be controlled by allocation. To accomplish this, they must be given the special control state Ribasim.allocation in the static table for Pump or Outlet. When a Pump or Outlet has this control state, the flow through the node is only bounded by its capacity and Pump or Outlet specific constraints based on the difference between upstream and downstream level (see Pump equations or Outlet equations). After all goals have been optimized for, the flow rate through the Pump or Outlet is communicated to the physical layer.\n\n\n3.1.2 Interaction of allocation with other control systems\nThere are several other control systems in Ribasim:\n\nDiscreteControl: This node type can change parameters of other nodes in between time steps of the solver of the physical layer. If the affected node is within a subnetwork, the parameter change will also be taken into account in the next allocation run. So the parameters in the allocation layer are always up to date with those in the physical layer, but the allocation algorithm cannot anticipate parameter changes from DiscreteControl that occur within the allocation time step which is being optimized over, so this can be a source of discrepancies between the physical layer and the allocation layer.\nContinuousControl: The continuous nature of this control type is not taken into account. The flow rate the controlled structure has at the start of the allocation optimization step will be extrapolated in a constant manner.\nPidControl: The continuous nature of this control type is not taken into account. The flow rate the controlled structure has at the start of the allocation optimization step will be extrapolated in a constant manner.\n\nThe following data of the parameters and state of a Ribasim model are relevant for the allocation problem.",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#schematisation-input",
    "href": "concept/allocation.html#schematisation-input",
    "title": "Allocation",
    "section": "3.2 Schematisation input",
    "text": "3.2 Schematisation input\n\n3.2.1 The subnetwork\nThe allocation problem is solved per subnetwork, which is given by a subset \\(S \\subset V\\) of node IDs. Different subnetworks are disjoint from each other. Nodes can also not be part of any subnetwork.\n\n\n3.2.2 Source flows\nSources are indicated by a set of links in the subnetwork \\[\nE_S^\\text{source} \\subset E,\n\\] which are automatically inferred as all links that point out of LevelBoundary or FlowBoundary nodes. That is, if \\((i,j) \\in E_S^\\text{source}\\), then the average over the last allocation interval \\(\\Delta t_{\\text{alloc}}\\) of the flow over this link \\[\n    \\frac{1}{\\Delta t_{\\text{alloc}}}\\int_{t - \\Delta t_{\\text{alloc}}}^tQ_{ij}(t') dt'\n\\] is treated as a source flow in the allocation problem. These links are either coming from a boundary/source node (e.g. a level or flow boundary) or connect the primary network to a subnetwork. For the definition of \\(Q_{ij}\\) see the formal model description.\n\n\n3.2.3 User demands\nThe subnetwork contains a subset of UserDemand nodes \\(U_S \\subset S\\), who all have static or time varying demands over various priorities \\(p\\): \\[\n    d^p_i(t), \\quad i \\in U_S, p = 1,2,\\ldots, p_{\\max}.\n\\]\n\n\n\n\n\n\nNote\n\n\n\nOn this page we assume that the priorities are given by all integers from \\(1\\) to some \\(p_{\\max} \\in \\mathbb{N}\\). For the Ribasim input this is not a requirement; some of these in between priority values can be missing, only the ordering of the given priorities is taken into account.\n\n\n\n\n3.2.4 Flow demands\nThe subnetwork contains a subset of nodes \\(FD_S \\subset S\\) which have a demand of a single priority \\(p_{\\text{fd}}\\) for the flow through that node. With this we define \\[\n    d^p_i(t) =\n    \\begin{cases}\n        0 \\text{ if } p \\ne p_{\\text{fd}} \\\\\n        d^{p_{\\text{df}}} \\text{ if } p = p_{\\text{fd}}\n    \\end{cases}\n\\] for all \\(i \\in FD_S\\). Here \\(d^{p_{\\text{df}}}\\) is given by the original flow demand minus the flows through node \\(i\\) at all priorities \\(p &lt; p_{\\text{fd}}\\).",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#simulation-physical-layer-input",
    "href": "concept/allocation.html#simulation-physical-layer-input",
    "title": "Allocation",
    "section": "3.3 Simulation (physical layer) input",
    "text": "3.3 Simulation (physical layer) input\n\n3.3.1 Constraining factors\n\n3.3.1.1 Flow magnitude and direction constraints\nNodes in the Ribasim model that have a max_flow_rate, i.e. Pump, Outlet and LinearResistance, put a constraint on the flow through that node. Some nodes only allow flow in one direction, like Pump, Outlet and TabulatedRatingCurve.\n\n\n3.3.1.2 UserDemand return flows\nUserDemand nodes dictate proportional relationships between flows over links in the subnetwork. The return factor is given by \\(0 \\le r_i(t) \\le 1, i \\in U_S\\).",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#the-subnetwork-1",
    "href": "concept/allocation.html#the-subnetwork-1",
    "title": "Allocation",
    "section": "3.4 The subnetwork",
    "text": "3.4 The subnetwork\nThe subnetwork consists of a set of nodes \\(S \\subset V\\) and links\n\\[\n    E_S = (S \\times S) \\cup E_S^\\text{source},\n\\]\ni.e. the links that lie within the subnetwork together with the source links (which can be partially outside the subnetwork). The nodes in \\(S\\) together with the connected nodes outside the subnetwork are called the extended subnetwork.\n\n3.4.1 Capacities\nEach link in the subnetwork has an associated capacity. These capacities are collected in the sparse capacity matrix \\(C_S \\in \\overline{\\mathbb{R}}_{\\ge 0}^{n\\times n}\\) where \\(n\\) is the number of nodes in the extended subnetwork. An link capacity is infinite if there is nothing in the model constraining the capacity.\nThe capacities are determined in different ways:\n\nIf an link does not exist in the allocation network, i.e. \\((i,j) \\notin E_S\\) for certain \\(1 \\le i,j\\le n'\\), then \\((C_S)_{i,j} = 0\\);\nThe capacity of the link \\(e \\in E_S\\) is given by the smallest max_flow_rate of the nodes along the equivalent links in the subnetwork. If there are no nodes with a max_flow_rate, the link capacity is infinite. If the max_flow_rate is time-dependent, only the value at the starttime of the simulation is considered;\nIf the link is a source, the capacity of the link is given by the flow rate of that source;\n\nThere are also capacities for special links:\n\n\\(C^{LD}_S \\in \\mathbb{R}^b_{\\ge 0}\\) where \\(b = \\# B_S\\) is the number of basins, for the flow supplied by basins based on level demand (this capacity is 0 for basins that have no level demand).\n\\(C^{FD}_S \\in \\mathbb{R}^c_{\\ge 0}\\) where \\(c = \\# FD_S\\) is the number of nodes with a flow demand, for the flow supplied by flow buffers at these nodes with a flow demand.\n\\(C^{UD}_S \\in \\mathbb{R}^f_{\\ge 0}\\) where \\(f = \\# U_S\\), for the flow supplied by the user demand outflow source whose capacity is given by return flows.",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/allocation.html#route-priority",
    "href": "concept/allocation.html#route-priority",
    "title": "Allocation",
    "section": "3.5 Route priority",
    "text": "3.5 Route priority\nNodes can be assigned priorities that influence how water is preferentially routed. These priorities are given as weights \\(w_i \\geq 0\\) for node \\(i\\) with an outflow link \\(Q_i\\).\nThe route priority weights act as a cost per flow rate. For a given demand priority \\(p\\), the objective is to minimize the cost of the water allocation:\n\\[\n\\min \\sum w_i \\cdot Q_{i}\n\\]\nThis term is added to the optimization problem after the demand objectives have been satisfied, ensuring that:\n\nDemands are met first according to their priority\nAmong solutions that satisfy demands equally well, water is preferentially allocated via routes with the lowest cost\n\n\n3.5.1 Example\nIn Figure 1 the water can take multiple routes from the flow boundary to user demands 14 and 17. We have set all route priorities (cost) to 0 except for outlets 3 and 8, which have a higher cost (lower priority). This results in the flow routing preferentially through the pumps, since flowing through the outlets incurs a higher penalty in the objective function due to their non-zero route priority. The results are shown in Figure 2.\n\n\n\n\n\n\nFigure 2: Flow rate results with a preferential routes via the pumps",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Allocation"
    ]
  },
  {
    "objectID": "concept/core.html",
    "href": "concept/core.html",
    "title": "Julia core",
    "section": "",
    "text": "With the term “core”, we mean the computational engine of Ribasim. As detailed in the usage documentation, it is generally used as a command line tool.\nA quick overview of the model concept is available in the introduction, while a more in-depth discussion is available on the model concept page. The theory is described on the equations page, and more in-depth numerical considerations are described on the numerical considerations page. As allocation is a large and self-contained part of the Ribasim core, it is described on the separate allocation page. Input validation is described on the validation page.\nThe core is implemented in the Julia programming language, and can be found in the Ribasim repository under the core/ folder. For developers we also advise to read the developer documentation. Information on coupling can be found here.\nAn overview of all components is given in the installation section.\n\n1 The simulation loop\nThe computational process can be divided into three phases:\n\nModel initialization\nRunning the simulation loop\nWriting the output files\n\nThe figure below gives a more detailed description of the simulation loop in the form of a sequence diagram. From top to bottom, it contains the following blocks:\n\nAllocation optimization; activated when the allocation timestep has been passed;\nControl actions; activated when some discrete control callback is triggered;\nWater balance; computing the flows over flow links happens each timestep;\nTime integration step; done by the integrator from OrdinaryDiffEq.jl.\n\n\n\n\n\n\nsequenceDiagram\n    autonumber\n    participant Int as Process: Integrator\n    participant Optim as Process: Allocation optimization\n    participant Param as Data: Parameters\n    participant State as Data: State\n    participant Sim as Process: Water balance\n    loop Simulation loop (OrdinaryDiffEq.jl)\n        activate Int\n        %% Allocation\n        rect rgb(200, 200, 200)\n            opt Allocation optimization, per allocation network (JuMP.jl, HiGHS)\n                activate Optim\n                Int-&gt;&gt;Optim: Callback: allocation timestep has passed\n                Param--&gt;&gt;Optim: Input\n                State--&gt;&gt;Optim: Input\n                Optim-&gt;&gt;Optim: Optimize Basin allocations if below target level\n                Optim-&gt;&gt;Optim: Optimize UserDemand allocation, per priority\n                Optim--&gt;&gt;Param: Set allocated flow rates\n                deactivate Optim\n            end\n        end\n        %% Control\n        rect rgb(200, 200, 200)\n            opt Control actions\n                Int-&gt;&gt;Int: DiscreteControl callback\n                Int--&gt;&gt;Param: Parameter updates by control\n            end\n        end\n        %% water_balance!\n        rect rgb(200, 200, 200)\n            activate Sim\n            State--&gt;&gt;Sim: Input\n            Param--&gt;&gt;Sim: Input\n            Sim-&gt;&gt;Sim: Compute flows over links per node type\n            Sim--&gt;&gt;Param: Set flows\n            deactivate Sim\n        end\n        %% Time integration\n        rect rgb(200, 200, 200)\n            State--&gt;&gt;Int: Input\n            Param--&gt;&gt;Int: Input\n            Int-&gt;&gt;Int: Time integration step\n            Int--&gt;&gt;State: Update state\n        end\n        deactivate Int\n  end\n\n\n\n\n\n\n\n\n2 Nested allocation\nSince water systems may be extensive, like in the Netherlands, Ribasim models may become large networks with over ten thousand nodes. To maintain a properly functioning allocation concept under these circumstances, the modeler can decompose the network domain into a primary network and multiple sub-networks. The allocation will then be conducted in three steps:\n\nconduct an inventory of demands from the sub-networks to inlets from the primary network,\nallocate the available water in the primary network to the subnetwork inlets,\nallocate the assigned water within each subnetwork to the individual demand nodes.\n\nThe demand nodes will then request this updated demand from the rule-based simulation. Whether this updated demand is indeed abstracted depends on all the control mechanisms implemented in the rule-based simulation.\nThe following sequence diagram illustrates this calculation process within the allocation phase.\n\n\n\n\n\nsequenceDiagram\nparticipant boundary\nparticipant basin\nparticipant user_demand\nparticipant allocation_subNetwork\nparticipant allocation_mainNetwork\n\nuser_demand-&gt;&gt;allocation_subNetwork: demand\nloop\n   allocation_subNetwork--&gt;&gt;allocation_mainNetwork: demand inventory at inlets\nend\nuser_demand-&gt;&gt;allocation_mainNetwork: demand\nboundary-&gt;&gt;allocation_mainNetwork: source availability\nbasin-&gt;&gt;allocation_mainNetwork: source availability\nallocation_mainNetwork--&gt;&gt;allocation_mainNetwork: allocate to inlets (and user_demands)\nallocation_mainNetwork-&gt;&gt;user_demand: allocated\nallocation_mainNetwork-&gt;&gt;allocation_subNetwork: allocated\nloop\n   allocation_subNetwork--&gt;&gt;allocation_subNetwork: allocate to user_demands\nend\nallocation_subNetwork-&gt;&gt;user_demand: allocated\nuser_demand-&gt;&gt;basin: abstracted\n\n\n\n\n\n\n\n\n3 Substance (tracer) concentrations\n\n\n\n\n\n\nCaution\n\n\n\nThis is an unsupported experimental feature and is disabled by default. We advise to use the Delwaq coupling for tracer calculations. If you’re interested in using this experimental feature, please contact us.\n\n\nRibasim can calculate concentrations of conservative tracers (i.e. substances that are non-reactive). It does so by calculating the mass transports by flows for each timestep, in the update_cumulative_flows! callback. Specifically, for each Basin at each timestep it calculates:\n\nall mass inflows (\\(flow * source\\_concentration\\)) given the link inflows\nupdate the concentrations in the Basin based on the added storage (\\(previous storage + inflows\\))\nall mass outflows (\\(flow * basin\\_concentration\\_state\\)) given the link outflows\nupdate the concentrations in the Basin based on the current storage\n\nWe thus keep track of both mass and concentration of substances for each Basin. Note that we have not added the substance mass to the states, and we assume that concentrations of flows are piecewise constant over a timestep. This excludes the use of tracer injections.\nBy default the following source tracers are enabled.\n\nContinuity (mass balance, fraction of all water sources, sum of all other source tracers)\nInitial (fraction of initial storages)\nLevelBoundary, FlowBoundary, UserDemand, Drainage, Precipitation (fraction of different boundaries)\nResidenceTime (the average residence time of a water body in seconds)",
    "crumbs": [
      "Concepts",
      "Implementation",
      "Julia core"
    ]
  },
  {
    "objectID": "concept/concept.html",
    "href": "concept/concept.html",
    "title": "Introduction",
    "section": "",
    "text": "Decision makers need to balance the supply and demand of water at the river basin scale, under increasing environmental pressure. Ribasim allows users to model basins under current and changing conditions to evaluate, design, and manage water systems. It is available as free and open source software under the MIT license. Besides a model simulation core, Ribasim also includes tooling to assist in building models from basic datasets and visualize results. The model and its results provides insights to decision makers, enabling them to build consensus amongst water users and make informed decisions about how to manage water resources optimally.\nThe model concept of Ribasim is composed of multiple layers:\n\na physical layer representing water bodies and associated infrastructure as well as abstractions,\na rule-based control layer to manage the infrastructure, and\n(optionally) a priority-based allocation layer to take centralized decisions on user abstractions.\n(optionally) a coupling layer to exchange fluxes and heads with other kernels\n\nTypically hydrological processes on land will be represented in detail by other models which can be coupled (online) to Ribasim with the help of iMOD Coupler. Currently, an online coupling with MODFLOW 6 (groundwater) and with Metaswap + MODFLOW 6 (unsaturated zone + groundwater) is available. The corresponding documentation can be found within the iMOD Suite Documentation.\nThis version of Ribasim is the follow up of the legacy Fortran kernel of Ribasim (version 7) applied world wide, the Fortran kernel SIMRES applied in the Netherlands, and the surface water models Distribution Model and Mozart of the Dutch National Hydrological Instrument.",
    "crumbs": [
      "Concepts",
      "Introduction"
    ]
  },
  {
    "objectID": "concept/concept.html#sec-physical",
    "href": "concept/concept.html#sec-physical",
    "title": "Introduction",
    "section": "2.1 Physical layer",
    "text": "2.1 Physical layer\nTo represent the physical characteristics of the water system in an area, Ribasim allows you to divide the area into a network of connected representative elementary watersheds (Reggiani, Sivapalan, and Majid Hassanizadeh 1998). Within Ribasim, these elements are called basins, which are essentially buckets or reservoirs holding an aggregated volume of water bodies in an area. Basins are chained in a graph with connector nodes determining the exchange of water between the basins. These connector nodes can represent open water connections (e.g. bifurcations or resistance in a free flowing open water channel) or infrastructure elements such as pumps, gates or weirs. An overview of node types and associated data inputs is provided on the usage page, while the associated mathematical formations are described on the equations page.",
    "crumbs": [
      "Concepts",
      "Introduction"
    ]
  },
  {
    "objectID": "concept/concept.html#sec-control",
    "href": "concept/concept.html#sec-control",
    "title": "Introduction",
    "section": "2.2 Control layer",
    "text": "2.2 Control layer\nInfrastructure elements are often controlled by humans to implement a certain water management strategy. Ribasim allows the configuration of conditional rules to influence the exchange of water between basins, either by setting inflow or outflow, or by controlling a water level. Control rules evaluate one or multiple conditions to change a parameter setting of an infrastructure element when the conditional criteria are met. Conditions can be either calculated values within the network as well as boundary conditions or (todo) external observations, i.e. observation values external to the model. An overview of node types and associated data inputs is provided on the usage page, while the associated mathematical formations are described on the equations page.",
    "crumbs": [
      "Concepts",
      "Introduction"
    ]
  },
  {
    "objectID": "concept/concept.html#sec-allocation",
    "href": "concept/concept.html#sec-allocation",
    "title": "Introduction",
    "section": "2.3 Allocation layer",
    "text": "2.3 Allocation layer\nRibasim allows water users (water demands) to abstract water from the basins (i.e. from the physical layer) unless the water level drops below a minimum level. Under dry conditions, water managers may want to prioritize some abstractions over other abstractions. The Ribasim allocation layer can take care of this prioritization by reducing the abstraction rates of lower-priority demands to ensure that sufficient water remains available in the system for the higher-priority demands. The associated mathematical formulations are described on the allocation page. In case of large networks, a subdivision in a primary network with subnetworks is recommended. For more details see the explanation of the simulation loop.\nThe layers and the main components and dataflows between the layers are shown in the next figure:\n\n\n\n\n\nflowchart TB\nphysical:::layer\nrbc:::layer\nallocation:::layer\nuser_demand\nbasin\nconnector[basin connector]\ncontrol[control rules]\ncondition\nalloc[global allocation]\n\nsubgraph physical[physical layer]\n    user_demand--&gt;|abstraction| basin\n    basin&lt;--&gt;|flow| connector\nend\n\nsubgraph rbc[rule based control layer]\n   condition --&gt; control\nend\n\nsubgraph allocation[allocation layer]\n    alloc\nend\n\nuser_demand--&gt;|request demand| alloc\nalloc--&gt;|assign allocation| user_demand\nbasin--&gt;|volume| alloc\nbasin --&gt; |volume or level| condition\nalloc --&gt; |optional flow update| control\ncontrol --&gt; |action| connector\n\n%% class definitions for C4 model\nclassDef layer fill:transparent,stroke-dasharray:5 5",
    "crumbs": [
      "Concepts",
      "Introduction"
    ]
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact us",
    "section": "",
    "text": "You can contact us via email.",
    "crumbs": [
      "Overview",
      "Contact us"
    ]
  },
  {
    "objectID": "reference/python/index.html",
    "href": "reference/python/index.html",
    "title": "1 Python API",
    "section": "",
    "text": "run_ribasim\nRun the Ribasim CLI executable.\n\n\nAllocation\nDefines the allocation optimization algorithm options.\n\n\nLogging\nDefines the logging behavior of the core.\n\n\nNode\nDefines a node for the model.\n\n\nSolver\nDefines the numerical solver options.\n\n\nLinkTable\nDefines the connections between nodes.\n\n\nModel\nA model of inland water resources systems.",
    "crumbs": [
      "Reference",
      "Python API"
    ]
  },
  {
    "objectID": "reference/python/index.html#ribasim",
    "href": "reference/python/index.html#ribasim",
    "title": "1 Python API",
    "section": "",
    "text": "run_ribasim\nRun the Ribasim CLI executable.\n\n\nAllocation\nDefines the allocation optimization algorithm options.\n\n\nLogging\nDefines the logging behavior of the core.\n\n\nNode\nDefines a node for the model.\n\n\nSolver\nDefines the numerical solver options.\n\n\nLinkTable\nDefines the connections between nodes.\n\n\nModel\nA model of inland water resources systems.",
    "crumbs": [
      "Reference",
      "Python API"
    ]
  },
  {
    "objectID": "reference/python/LinkTable.html",
    "href": "reference/python/LinkTable.html",
    "title": "1 LinkTable",
    "section": "",
    "text": "LinkTable()\nDefines the connections between nodes.\n\n\n\n\n\nName\nDescription\n\n\n\n\ndf\n\n\n\nfilepath\n\n\n\nmodel_config\n\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\nadd\nAdd an link between nodes.\n\n\ncolumns\nRetrieve column names.\n\n\ndiff\n\n\n\nmodel_dump\n\n\n\nplot\nPlot the links of the model.\n\n\nset_filepath\nSet the filepath of this instance.\n\n\nsort\n\n\n\ntablename\nRetrieve tablename based on attached Schema.\n\n\ntableschema\nRetrieve Pandera Schema.\n\n\n\n\n\nLinkTable.add(\n    from_node,\n    to_node,\n    geometry=None,\n    name='',\n    link_id=None,\n    **kwargs,\n)\nAdd an link between nodes.\nThe type of the link (flow or control) is automatically inferred from the type of the from_node.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfrom_node\nNodeData\nA node indexed by its node ID, e.g. model.basin[1]\nrequired\n\n\nto_node\nNodeData\nA node indexed by its node ID, e.g. model.linear_resistance[1]\nrequired\n\n\ngeometry\nLineString | MultiLineString | None\nThe geometry of a line. If not supplied, it creates a straight line between the nodes.\nNone\n\n\nname\nstr\nAn optional name for the link.\n''\n\n\nlink_id\nint\nAn optional non-negative link ID. If not supplied, it will be automatically generated.\nNone\n\n\n**kwargs\nDict\n\n{}\n\n\n\n\n\n\n\nLinkTable.columns()\nRetrieve column names.\n\n\n\nLinkTable.diff(other, ignore_meta=False)\n\n\n\nLinkTable.model_dump(**kwargs)\n\n\n\nLinkTable.plot(**kwargs)\nPlot the links of the model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\n**kwargs\nDict\nSupported: ‘ax’, ‘color_flow’, ‘color_control’\n{}\n\n\n\n\n\n\n\nLinkTable.set_filepath(filepath)\nSet the filepath of this instance.\nArgs: filepath (Path): The filepath to set.\n\n\n\nLinkTable.sort()\n\n\n\nLinkTable.tablename()\nRetrieve tablename based on attached Schema.\nNodeSchema -&gt; Node TabularRatingCurveStaticSchema -&gt; TabularRatingCurve / static\n\n\n\nLinkTable.tableschema()\nRetrieve Pandera Schema.\nThe type of the field df is known to always be an DataFrame[TableT]]] | None"
  },
  {
    "objectID": "reference/python/LinkTable.html#attributes",
    "href": "reference/python/LinkTable.html#attributes",
    "title": "1 LinkTable",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndf\n\n\n\nfilepath\n\n\n\nmodel_config"
  },
  {
    "objectID": "reference/python/LinkTable.html#methods",
    "href": "reference/python/LinkTable.html#methods",
    "title": "1 LinkTable",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\nadd\nAdd an link between nodes.\n\n\ncolumns\nRetrieve column names.\n\n\ndiff\n\n\n\nmodel_dump\n\n\n\nplot\nPlot the links of the model.\n\n\nset_filepath\nSet the filepath of this instance.\n\n\nsort\n\n\n\ntablename\nRetrieve tablename based on attached Schema.\n\n\ntableschema\nRetrieve Pandera Schema.\n\n\n\n\n\nLinkTable.add(\n    from_node,\n    to_node,\n    geometry=None,\n    name='',\n    link_id=None,\n    **kwargs,\n)\nAdd an link between nodes.\nThe type of the link (flow or control) is automatically inferred from the type of the from_node.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\nfrom_node\nNodeData\nA node indexed by its node ID, e.g. model.basin[1]\nrequired\n\n\nto_node\nNodeData\nA node indexed by its node ID, e.g. model.linear_resistance[1]\nrequired\n\n\ngeometry\nLineString | MultiLineString | None\nThe geometry of a line. If not supplied, it creates a straight line between the nodes.\nNone\n\n\nname\nstr\nAn optional name for the link.\n''\n\n\nlink_id\nint\nAn optional non-negative link ID. If not supplied, it will be automatically generated.\nNone\n\n\n**kwargs\nDict\n\n{}\n\n\n\n\n\n\n\nLinkTable.columns()\nRetrieve column names.\n\n\n\nLinkTable.diff(other, ignore_meta=False)\n\n\n\nLinkTable.model_dump(**kwargs)\n\n\n\nLinkTable.plot(**kwargs)\nPlot the links of the model.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\n**kwargs\nDict\nSupported: ‘ax’, ‘color_flow’, ‘color_control’\n{}\n\n\n\n\n\n\n\nLinkTable.set_filepath(filepath)\nSet the filepath of this instance.\nArgs: filepath (Path): The filepath to set.\n\n\n\nLinkTable.sort()\n\n\n\nLinkTable.tablename()\nRetrieve tablename based on attached Schema.\nNodeSchema -&gt; Node TabularRatingCurveStaticSchema -&gt; TabularRatingCurve / static\n\n\n\nLinkTable.tableschema()\nRetrieve Pandera Schema.\nThe type of the field df is known to always be an DataFrame[TableT]]] | None"
  },
  {
    "objectID": "reference/python/Allocation.html",
    "href": "reference/python/Allocation.html",
    "title": "1 Allocation",
    "section": "",
    "text": "Allocation()\nDefines the allocation optimization algorithm options.\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\ntimestep\nfloat\nThe simulated time in seconds between successive allocation calls (Optional, defaults to 86400)\n\n\n\n\n\n\n\n\n\nName\nDescription\n\n\n\n\ndiff\nCompare two instances of a BaseModel.\n\n\nmodel_dump\n\n\n\n\n\n\nAllocation.diff(other, ignore_meta=False)\nCompare two instances of a BaseModel.\n** Warning: This method is experimental and is likely to change. **\nIf they are equal, return None. Otherwise, return a nested dictionary with the differences. When the differences are not a DataFrame (like the toml config), the dict has self and other as key. For DataFrames we return a dict with diff as key, and a datacompy Comparison object.\nWhen ignore_meta is set to True, the meta_* columns in the DataFrames are ignored. Note that in that case the key will still be returned and the value will be None.\n\n\n&gt;&gt;&gt; nbasic == basic\nFalse\n&gt;&gt;&gt; x = nbasic.diff(basic)\n{'basin': {'node': {'diff': &lt;datacompy.core.Compare object at 0x16e5a45c0&gt;},\n        'static': {'diff': &lt;datacompy.core.Compare object at 0x16eb90080&gt;}},\n'solver': {'saveat': {'other': 86400.0, 'self': 0.0}}}\n&gt;&gt;&gt; x[\"basin\"][\"static\"][\"diff\"].report()\nDataComPy Comparison\n--------------------\n...\n\n\n\n\nAllocation.model_dump(**kwargs)"
  },
  {
    "objectID": "reference/python/Allocation.html#attributes",
    "href": "reference/python/Allocation.html#attributes",
    "title": "1 Allocation",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\ntimestep\nfloat\nThe simulated time in seconds between successive allocation calls (Optional, defaults to 86400)"
  },
  {
    "objectID": "reference/python/Allocation.html#methods",
    "href": "reference/python/Allocation.html#methods",
    "title": "1 Allocation",
    "section": "",
    "text": "Name\nDescription\n\n\n\n\ndiff\nCompare two instances of a BaseModel.\n\n\nmodel_dump\n\n\n\n\n\n\nAllocation.diff(other, ignore_meta=False)\nCompare two instances of a BaseModel.\n** Warning: This method is experimental and is likely to change. **\nIf they are equal, return None. Otherwise, return a nested dictionary with the differences. When the differences are not a DataFrame (like the toml config), the dict has self and other as key. For DataFrames we return a dict with diff as key, and a datacompy Comparison object.\nWhen ignore_meta is set to True, the meta_* columns in the DataFrames are ignored. Note that in that case the key will still be returned and the value will be None.\n\n\n&gt;&gt;&gt; nbasic == basic\nFalse\n&gt;&gt;&gt; x = nbasic.diff(basic)\n{'basin': {'node': {'diff': &lt;datacompy.core.Compare object at 0x16e5a45c0&gt;},\n        'static': {'diff': &lt;datacompy.core.Compare object at 0x16eb90080&gt;}},\n'solver': {'saveat': {'other': 86400.0, 'self': 0.0}}}\n&gt;&gt;&gt; x[\"basin\"][\"static\"][\"diff\"].report()\nDataComPy Comparison\n--------------------\n...\n\n\n\n\nAllocation.model_dump(**kwargs)"
  },
  {
    "objectID": "reference/python/run_ribasim.html",
    "href": "reference/python/run_ribasim.html",
    "title": "1 run_ribasim",
    "section": "",
    "text": "run_ribasim(toml_path=None, *, ribasim_exe=None, version=False, threads=None)\nRun the Ribasim CLI executable.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ntoml_path\nstr | Path | None\nPath to the TOML file. Required unless version=True.\nNone\n\n\nribasim_exe\nstr | Path | None\nPath to the Ribasim CLI executable. If not provided, first checks the RIBASIM_EXE environment variable, then searches PATH.\nNone\n\n\nversion\nbool\nPrint version\nFalse\n\n\nthreads\nint | None\nNumber of threads to use. Defaults to 1.\nNone\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\nFileNotFoundError\nIf the Ribasim CLI is not found via RIBASIM_EXE or on PATH (when ribasim_exe is not provided), or the toml_path does not exist.\n\n\n\nValueError\nIf neither toml_path nor version is provided.\n\n\n\nsubprocess.CalledProcessError\nIf the Ribasim CLI returns a non-zero exit code.\n\n\n\n\n\n\n&gt;&gt;&gt; run_ribasim(\"model.toml\")\n&gt;&gt;&gt; run_ribasim(\"model.toml\", ribasim_exe=\"/path/to/ribasim\")\n&gt;&gt;&gt; run_ribasim(version=True)"
  },
  {
    "objectID": "reference/python/run_ribasim.html#parameters",
    "href": "reference/python/run_ribasim.html#parameters",
    "title": "1 run_ribasim",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ntoml_path\nstr | Path | None\nPath to the TOML file. Required unless version=True.\nNone\n\n\nribasim_exe\nstr | Path | None\nPath to the Ribasim CLI executable. If not provided, first checks the RIBASIM_EXE environment variable, then searches PATH.\nNone\n\n\nversion\nbool\nPrint version\nFalse\n\n\nthreads\nint | None\nNumber of threads to use. Defaults to 1.\nNone"
  },
  {
    "objectID": "reference/python/run_ribasim.html#raises",
    "href": "reference/python/run_ribasim.html#raises",
    "title": "1 run_ribasim",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\nFileNotFoundError\nIf the Ribasim CLI is not found via RIBASIM_EXE or on PATH (when ribasim_exe is not provided), or the toml_path does not exist.\n\n\n\nValueError\nIf neither toml_path nor version is provided.\n\n\n\nsubprocess.CalledProcessError\nIf the Ribasim CLI returns a non-zero exit code."
  },
  {
    "objectID": "reference/python/run_ribasim.html#examples",
    "href": "reference/python/run_ribasim.html#examples",
    "title": "1 run_ribasim",
    "section": "",
    "text": "&gt;&gt;&gt; run_ribasim(\"model.toml\")\n&gt;&gt;&gt; run_ribasim(\"model.toml\", ribasim_exe=\"/path/to/ribasim\")\n&gt;&gt;&gt; run_ribasim(version=True)"
  },
  {
    "objectID": "reference/test-models.html",
    "href": "reference/test-models.html",
    "title": "Test models",
    "section": "",
    "text": "Ribasim developers use the following models in their testbench and in order to test new features.\n\nCode\nimport ribasim_testmodels\nimport matplotlib.pyplot as plt\nfrom IPython.display import Markdown, display\n\nfor model_name, model_constructor in ribasim_testmodels.constructors.items():\n    if model_name.startswith(\"invalid\"):\n        continue\n\n    display(Markdown(f\"\\n# {model_name}\\n\"))\n    if model_constructor.__doc__ is not None:\n        display(Markdown(model_constructor.__doc__))\n\n    model = model_constructor()\n    fig, ax = plt.subplots(figsize=(6, 4))\n    model.plot(ax)\n    ax.axis(\"off\")\n    plt.show()\n    plt.close(fig)\n\n\n1 allocation_control\nCreate a model that has a pump controlled by allocation. \n\n\n2 allocation_example\nGenerate a model that is used as an example of allocation in the docs. \n\n\n3 allocation_off_flow_demand\nSet up a model with a Pump with a FlowDemand but allocation turned off. \n\n\n4 allocation_training\n\n\n\n5 backwater\nBackwater curve as an integration test for ManningResistance. \n\n\n6 basic_arrow\n\n\n\n7 basic_basin_both_area_and_storage\n\n\n\n8 basic_basin_only_area\n\n\n\n9 basic_basin_only_storage\n\n\n\n10 basic\n\n\n\n11 basic_transient\nUpdate the basic model with transient forcing. \n\n\n12 bommelerwaard\n\n\n\n13 bucket\nBucket model with just a single basin at Deltares’ headquarter. \n\n\n14 circular_flow\nCreate a model with a circular flow and a discrete control on a pump. \n\n\n15 compound_variable_condition\nModel with a condition on a compound variable for DiscreteControl. \n\n\n16 concentration_condition\nDiscreteControl based on a concentration condition. \n\n\n17 connector_node_flow_condition\nDiscreteControl with a condition on the flow through a connector node. \n\n\n18 continuous_concentration_condition\nDiscreteControl based on a continuous (calculated) concentration condition.\nIn this case, we setup a salt concentration and mimic the Dutch coast.\n       dc\n     /   |\nlb –&gt; lr -&gt; basin &lt;– fb | out | term\n\n\n\n19 cyclic_demand\nCreate a model that has cyclic User- Flow- and LevelDemand. \n\n\n20 cyclic_time\n\n\n\n21 discrete_control_of_pid_control\nSet up a basic model where a discrete control node sets the target level of a pid control node. \n\n\n22 drain_surplus\nSet up a model which activates an outlet to drain surplus water out of a Basin. \n\n\n23 drought\nCreate a small subsection of the LHM Vechtstromen model containing a basin that runs dry (#2189). \n\n\n24 fair_distribution\nSee the behavior of allocation with few restrictions within the graph. \n\n\n25 flow_boundary_interpolation\n\n\n\n26 flow_boundary_time\nSet up a minimal model with time-varying flow boundary. \n\n\n27 flow_condition\nSet up a basic model that involves discrete control based on a flow condition. \n\n\n28 flow_demand\nSmall model with a FlowDemand. \n\n\n29 junction_chained\nTestmodel with chained junctions. \n\n\n30 junction_combined\nTestmodel combining confluence and bifurcation junctions. \n\n\n31 leaky_bucket\nBucket model with dynamic forcing with missings at Deltares’ headquarter. \n\n\n32 level_boundary_condition\nSet up a small model with a condition on a level boundary. \n\n\n33 level_demand\nSmall model with LevelDemand nodes. \n\n\n34 level_range\nKeep the level of a Basin within a range around a setpoint, under the influence of time-varying forcing.\nThis is done by bringing the level back to the setpoint once the level goes beyond this range.\n\n\n\n35 linear_resistance_demand\nSmall model with a FlowDemand for a node with a max flow rate. \n\n\n36 linear_resistance\nSet up a minimal model which uses a linear_resistance node. \n\n\n37 local_pidcontrolled_cascade\nDemonstrating model for the cascade polder project from our partner. \n\n\n38 looped_subnetwork\nCreate a UserDemand testmodel representing a subnetwork containing a loop in the topology.\nThis model is merged into primary_and_secondary_subnetworks_model.\n\n\n\n39 manning_resistance\nSet up a minimal model which uses a manning_resistance node. \n\n\n40 medium_primary_secondary_network\n\n\n\n41 medium_primary_secondary_network_verification\n\n\n\n42 minimal_subnetwork\nCreate a subnetwork that is minimal with non-trivial allocation. \n\n\n43 misc_nodes\nSet up a minimal model using flow_boundary and pump nodes. \n\n\n44 multi_level_demand\nCreate a model that has a level demand with multiple priorities. \n\n\n45 multi_priority_flow_demand\nSet up a model which contains a FlowDemand node with multiple demand priorities. \n\n\n46 multiple_route_priorities\nSet up a model to test route prioritization. \n\n\n47 outlet_continuous_control\nSet up a small model that distributes flow over 2 branches. \n\n\n48 outlet\nSet up a basic model with an outlet that encounters various physical constraints. \n\n\n49 pid_control_equation\nSet up a model with pid control for an analytical solution test. \n\n\n50 pid_control\nSet up a basic model with a PID controlled pump controlling a basin with abundant inflow. \n\n\n51 polder_management\nSet up a model where the water level in the boezem is be higher than in the polder system.\nTo maintain the target water levels in dry periods in the polder system, a water supply of 2 m³/s is required during two periods of the year: day 90 to 180 and day 270 to 366. Flushing is included as well: 1.5 m³/s during day 90 to 180.\n\n\n\n52 primary_and_secondary_subnetworks\nGenerate a model which consists of a main network and multiple connected subnetworks. \n\n\n53 pump_discrete_control\nSet up a basic model with a Pump controlled based on Basin levels.\nThe LinearResistance is deactivated when the levels are almost equal.\n\n\n\n54 rating_curve_between_basins\nSet up a minimal model which uses a tabulated_rating_curve node. \n\n\n55 rating_curve\nSet up a minimal model which uses a tabulated_rating_curve node. \n\n\n56 secondary_networks_with_sources\nGenerate a model with subnetworks which contain sources. \n\n\n57 small_primary_secondary_network\n\n\n\n58 small_primary_secondary_network_verification\n\n\n\n59 storage_condition\nCreate a model with a discrete control condition based on the storage of a Basin. \n\n\n60 subnetwork\nCreate a UserDemand testmodel representing a subnetwork.\nThis model is merged into primary_and_secondary_subnetworks_model.\n\n\n\n61 tabulated_rating_curve_control\nDiscrete control on a TabulatedRatingCurve.\nThe Basin drains over a TabulatedRatingCurve into a Terminal. The Control node will effectively increase the crest level to prevent further drainage at some threshold level.\n\n\n\n62 tabulated_rating_curve\nSet up a model where the upstream Basin has two TabulatedRatingCurve attached.\nThey both flow to the same downstream Basin, but one has a static rating curve, and the other one a time-varying rating curve. Only the upstream Basin receives a (constant) precipitation.\n\n\n\n63 transient_condition\nDiscreteControl based on transient condition. \n\n\n64 transient_pump_outlet\nSet up a model with time dependent pump and outlet flows. \n\n\n65 trivial\nTrivial model with just a basin, tabulated rating curve and terminal node. \n\n\n66 two_basin\nCreate a model of two basins.\nThe basins are not connected; the model is mostly designed to test in combination with a groundwater model.\nThe left basin receives water. In case of a coupled run, the water infiltrates in the left basin, and exfiltrates in the right basin. The right basin fills up and discharges over the rating curve.\n\n\n\n67 user_demand\nCreate a UserDemand test model with static and dynamic UserDemand on the same basin.",
    "crumbs": [
      "Reference",
      "Test models"
    ]
  },
  {
    "objectID": "reference/usage.html",
    "href": "reference/usage.html",
    "title": "Usage",
    "section": "",
    "text": "Ribasim has a single configuration file, which is written in the TOML format. It contains settings, as well as paths to other input and output files. Ribasim expects the GeoPackage database database.gpkg as well as optional Arrow input files to be available in the input_dir.\n# start- and endtime of the simulation\n# can also be set to a date-time like 1979-05-27T07:32:00\nstarttime = 2019-01-01 # required\nendtime = 2021-01-01   # required\n\n# Coordinate Reference System\n# The accepted strings are documented here:\n# https://proj.org/en/9.4/development/reference/functions.html#c.proj_create\ncrs = \"EPSG:4326\"      # required\n\n# input and results directories relative to the TOML file\ninput_dir = \"input\"     # required\nresults_dir = \"results\" # required\n\nribasim_version = \"2025.6.0\" # required\n\n# Specific tables can also go into Arrow files rather than the database.\n# For large tables this can benefit from better compressed file sizes.\n# This is optional, tables are retrieved from the database if not specified in the TOML.\n[basin]\ntime = \"basin/time.arrow\"\n\n[interpolation]\nflow_boundary = \"block\"   # optional, default \"block\", can otherwise be \"linear\"\nblock_transition_period = 0  # optional, default 0\n\n[allocation]\ntimestep = 86400         # optional (required if experimental.allocation = true), default 86400\n\n[allocation.route_priority]\nlevel_boundary = 1000       # optional, default 1000\nbasin = 2000                # optional, default 2000\nmanning_resistance = 10     # optional, default 10\nlinear_resistance = 20      # optional, default 20\ntabulated_rating_curve = 30 # optional, default 30\noutlet = 30                 # optional, default 40\npump = 40                   # optional, default 50\n\n[solver]\nalgorithm = \"QNDF\"  # optional, default \"QNDF\"\nsaveat = 86400      # optional, default 86400, 0 saves every timestep, inf saves only at start- and endtime\ndt = 60.0           # optional, remove for adaptive time stepping\ndtmin = 0.0         # optional, default 0.0\ndtmax = 0.0         # optional, default length of simulation\nforce_dtmin = false # optional, default false\nabstol = 1e-5       # optional, default 1e-5\nreltol = 1e-5       # optional, default 1e-5\nwater_balance_abstol = 1e-3 # optional, default 1e-3\nwater_balance_reltol = 1e-2 # optional, default 1e-2\nmaxiters = 1e9      # optional, default 1e9\nsparse = true       # optional, default true\nautodiff = true     # optional, default true\nevaporate_mass = true  # optional, default true to simulate a correct mass balance\ndepth_threshold = 0.1  # optional, default 0.1\nlevel_difference_threshold = 0.02 # optional, default 0.02\nspecialize = false  # optional, default false\n\n[logging]\n# defines the logging level of Ribasim\nverbosity = \"info\" # optional, default \"info\", can also be \"debug\", \"warn\" or \"error\"\n\n[results]\nformat = \"arrow\"      # optional, default \"arrow\", can also be \"netcdf\"\ncompression = true    # optional, default true, using zstd compression\ncompression_level = 6 # optional, default 6\nsubgrid = false       # optional, default false\n\n[experimental]\n# Experimental features, disabled by default\nconcentration = false # tracer calculations\nallocation = false # allocation layer, replaced by 'first come first serve' when inactive\n\n\nThe solver section in the configuration file is entirely optional, since we aim to use defaults that will generally work well. Common reasons to modify the solver settings are to adjust the calculation or result stepsizes: dt, and saveat. If your model does not converge, or your performance is lower than expected, it can help to adjust other solver settings as well.\nThe default solver algorithm = \"QNDF\", which is a multistep method similar to Matlab’s ode15s (Shampine and Reichelt 1997). It is an implicit method that supports the default adaptive timestepping. The full list of available solvers is: QNDF, FBDF, Rosenbrock23, Rodas4P, Rodas5P, TRBDF2, KenCarp4, Tsit5, RK4, ImplicitEuler, Euler. Information on the solver algorithms can be found on the ODE solvers page.\nBy default Ribasim uses adaptive timestepping, though not all algorithms support adaptive timestepping. To use fixed timesteps, provide a timestep size in seconds; dt = 3600.0 corresponds to an hourly timestep. With adaptive timestepping, dtmin and dtmax control the minimum and maximum allowed dt. If a smaller dt than dtmin is needed to meet the set error tolerances, the simulation stops, unless force_dtmin is set to true. force_dtmin is off by default to ensure an accurate solution.\nThe saveat setting controls the output frequency. It is the number of seconds between timestamps in the results. The default result stepsize, saveat = 86400 will save results daily. The calculation and result stepsize need not be the same. If you wish to save every calculation step, set saveat = 0. With the default adaptive timestepping that will result in irregular time series. If you wish to not save any intermediate steps, set saveat = inf. For output frequencies that are not of fixed length, like months or years, we suggest to resample from daily results during post-processing.\nThe water balance error is a measure of the error in the consistency with which the core keeps track of the water resources per Basin, for more details see here. water_balance_abstol and water_balance_reltol give upper bounds on this error, above which an error is thrown. A too large error generally indicates an error in the code or floating point truncation errors.\nThe Jacobian matrix provides information about the local sensitivity of the model with respect to changes in the states. For implicit solvers it must be calculated often, which can be expensive to do. There are several methods to do this. By default Ribasim uses a Jacobian derived automatically using ForwardDiff.jl with memory management provided by PreallocationTools.jl. If this is not used by setting autodiff = false, the Jacobian is calculated with a finite difference method, which can be less accurate and more expensive.\nBy default the Jacobian matrix is a sparse matrix (sparse = true). Since each state typically only depends on a small number of other states, this is generally more efficient, especially for larger models. The sparsity structure is calculated from the network and provided as a Jacobian prototype to the solver. For small or highly connected models it could be faster to use a dense Jacobian matrix instead by setting sparse = false.\nThe total maximum number of iterations maxiters = 1e9, can normally stay as-is unless doing extremely long simulations.\nThe absolute and relative tolerance for adaptive timestepping can be set with abstol and reltol. For more information on these and other solver options, see the DifferentialEquations.jl docs and the DifferentialEquations.jl FAQ.\nThe evaporate_mass = true setting determines whether mass is lost due to evaporation in water quality calculations, by default set to true. While physically incorrect, it is useful for a first correctness check on a model in terms of mass balance (Continuity tracer should always have a concentration of 1). To simulate increasing concentrations (e.g. salinity) due to evaporation, change the setting to false.\nBy default specialize = false to reduce the time it takes to initialize fully. It can be enabled for long-running simulations, trading initialization speed for simulation speed. Concretely, setting it will set the specialization level to NoSpecialize for false, and FullSpecialize for true. Additionally setting it to false also fixes the autodiff chunk size to 1, making a similar tradeoff as the specialization level.\nThere are two threshold parameters that control when reduction factors start smoothly reducing flow. Note that these are global settings, and cannot be set for individual nodes. depth_threshold = 0.1 is the water depth (level - profile bottom) in meters at which the low storage factor kicks in. This will limit any extraction from nearly empty Basins, and avoids drying them out completely. level_difference_threshold = 0.02 is the level difference below which several flows are reduced. Examples are approaching min_upstream_level from above and max_downstream_level from below, level difference across TabulatedRatingCurve and Outlet nodes, and UserDemand approaching the min_level from above. For details see the equations on the node reference pages, and the section on reduction factors\n\n\n\nThere are the following interpolation settings:\n\nflow_boundary: The interpolation type of flow boundary timeseries. This is linear by default, but can also be set to block.\nblock_transition_period: When an interpolation type is set to block, this parameter determines an interval in time on either side of each data point which is used to smooth the transition between data points. See also the documentation for this interpolation type.\n\n\n\n\nThere are the following allocation settings:\n\ntimestep: A float value in seconds which dictates the update interval for allocations;\nroute_priority: An integer per source type for the allocation algorithm. The prioritisable sources are: basin, level_boundary, linear_resistance, manning_resistance, outlet and pump.\n\nIf you wish to set the route priority for specific nodes rather than a fallback per node type, these can be set in the Node table.\nBy default, all nodes of the same type have the same route priority. To obtain a strict source ordering, the sources are sorted by node ID for each route priority within a subnetwork.\nWhen no default route priorities are specified, default values are applied (see the TOML example above).\n\nThe way the route priorities work is as follows: The priority that is assigned to a node is interpreted as the cost it takes for water to flow through that node. The flow through each node is multiplied with the priority, and we find the water distribution solution that has the lowest cost of fulfilling the desired demands.\n\n\n\n\nThe following entries can be set in the configuration in the [results] section.\n\n\n\n\n\n\n\n\nentry\ntype\ndescription\n\n\n\n\nformat\nString\nFile format, default is “arrow” for Apache Arrow, other option is “netcdf” for NetCDF with CF conventions.\n\n\ncompression\nBool\nWhether to apply compression or not.\n\n\ncompression_level\nInt\nZstandard compression level. Default is 6, higher compresses more.\n\n\nsubgrid\nBool\nCompute and output more detailed water levels.\n\n\n\nCurrently compression is only used for Apache Arrow. NetCDF will be the only output format later on.\n\n\n\nThe following can be set in the configuration in the [logging] section.\n\n\n\n\n\n\n\n\nentry\ntype\ndescription\n\n\n\n\nverbosity\nString\nVerbosity level: debug, info, warn, or error.\n\n\n\nIf verbosity is set to debug, the used Basin / profile dimensions (level, area and storage) are written to a CSV file in the results folder. This can be useful if you only provide 2 of the 3 columns and want to inspect the dimensions used in the computation.\nThe format of the CSV is: column 1 = node id, column 2 = level, column 3 = area and column 4 is storage.\nLets say you have 2 basins at node 1 and node 2. Dimensions node 1: level = [0, 1, 2], area = [2, 2, 4] and storage = [0, 2, 6], Dimensions node 1: level = [0, 1, 2], area = [4, 4, 8] and storage = [0, 4, 12].\nThen the CSV will look like:\n\n\n\nnode_id\nlevel\narea\nstorage\n\n\n\n\n1\n0\n2\n0\n\n\n1\n1\n2\n2\n\n\n1\n2\n4\n6\n\n\n2\n0\n4\n0\n\n\n2\n1\n4\n4\n\n\n2\n2\n8\n12\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nExperimental features are completely unsupported. They can break at any time and results will be wrong. Do not use them in production. If you’re interested in using an experimental feature, please contact us.\n\n\nOne can enable experimental features in the [experimental] section. Currently the following features can be enabled (all are disabled by default).\n\n\n\n\n\n\n\n\nentry\ntype\ndescription\n\n\n\n\nconcentration\nBool\nWhether to enable tracer calculations or not.\n\n\nallocation\nBool\nWhether to activate the activation layer. Replaced by ‘first come first serve’ when deactivated",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#sec-solver-settings",
    "href": "reference/usage.html#sec-solver-settings",
    "title": "Usage",
    "section": "",
    "text": "The solver section in the configuration file is entirely optional, since we aim to use defaults that will generally work well. Common reasons to modify the solver settings are to adjust the calculation or result stepsizes: dt, and saveat. If your model does not converge, or your performance is lower than expected, it can help to adjust other solver settings as well.\nThe default solver algorithm = \"QNDF\", which is a multistep method similar to Matlab’s ode15s (Shampine and Reichelt 1997). It is an implicit method that supports the default adaptive timestepping. The full list of available solvers is: QNDF, FBDF, Rosenbrock23, Rodas4P, Rodas5P, TRBDF2, KenCarp4, Tsit5, RK4, ImplicitEuler, Euler. Information on the solver algorithms can be found on the ODE solvers page.\nBy default Ribasim uses adaptive timestepping, though not all algorithms support adaptive timestepping. To use fixed timesteps, provide a timestep size in seconds; dt = 3600.0 corresponds to an hourly timestep. With adaptive timestepping, dtmin and dtmax control the minimum and maximum allowed dt. If a smaller dt than dtmin is needed to meet the set error tolerances, the simulation stops, unless force_dtmin is set to true. force_dtmin is off by default to ensure an accurate solution.\nThe saveat setting controls the output frequency. It is the number of seconds between timestamps in the results. The default result stepsize, saveat = 86400 will save results daily. The calculation and result stepsize need not be the same. If you wish to save every calculation step, set saveat = 0. With the default adaptive timestepping that will result in irregular time series. If you wish to not save any intermediate steps, set saveat = inf. For output frequencies that are not of fixed length, like months or years, we suggest to resample from daily results during post-processing.\nThe water balance error is a measure of the error in the consistency with which the core keeps track of the water resources per Basin, for more details see here. water_balance_abstol and water_balance_reltol give upper bounds on this error, above which an error is thrown. A too large error generally indicates an error in the code or floating point truncation errors.\nThe Jacobian matrix provides information about the local sensitivity of the model with respect to changes in the states. For implicit solvers it must be calculated often, which can be expensive to do. There are several methods to do this. By default Ribasim uses a Jacobian derived automatically using ForwardDiff.jl with memory management provided by PreallocationTools.jl. If this is not used by setting autodiff = false, the Jacobian is calculated with a finite difference method, which can be less accurate and more expensive.\nBy default the Jacobian matrix is a sparse matrix (sparse = true). Since each state typically only depends on a small number of other states, this is generally more efficient, especially for larger models. The sparsity structure is calculated from the network and provided as a Jacobian prototype to the solver. For small or highly connected models it could be faster to use a dense Jacobian matrix instead by setting sparse = false.\nThe total maximum number of iterations maxiters = 1e9, can normally stay as-is unless doing extremely long simulations.\nThe absolute and relative tolerance for adaptive timestepping can be set with abstol and reltol. For more information on these and other solver options, see the DifferentialEquations.jl docs and the DifferentialEquations.jl FAQ.\nThe evaporate_mass = true setting determines whether mass is lost due to evaporation in water quality calculations, by default set to true. While physically incorrect, it is useful for a first correctness check on a model in terms of mass balance (Continuity tracer should always have a concentration of 1). To simulate increasing concentrations (e.g. salinity) due to evaporation, change the setting to false.\nBy default specialize = false to reduce the time it takes to initialize fully. It can be enabled for long-running simulations, trading initialization speed for simulation speed. Concretely, setting it will set the specialization level to NoSpecialize for false, and FullSpecialize for true. Additionally setting it to false also fixes the autodiff chunk size to 1, making a similar tradeoff as the specialization level.\nThere are two threshold parameters that control when reduction factors start smoothly reducing flow. Note that these are global settings, and cannot be set for individual nodes. depth_threshold = 0.1 is the water depth (level - profile bottom) in meters at which the low storage factor kicks in. This will limit any extraction from nearly empty Basins, and avoids drying them out completely. level_difference_threshold = 0.02 is the level difference below which several flows are reduced. Examples are approaching min_upstream_level from above and max_downstream_level from below, level difference across TabulatedRatingCurve and Outlet nodes, and UserDemand approaching the min_level from above. For details see the equations on the node reference pages, and the section on reduction factors",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#interpolation-settings",
    "href": "reference/usage.html#interpolation-settings",
    "title": "Usage",
    "section": "",
    "text": "There are the following interpolation settings:\n\nflow_boundary: The interpolation type of flow boundary timeseries. This is linear by default, but can also be set to block.\nblock_transition_period: When an interpolation type is set to block, this parameter determines an interval in time on either side of each data point which is used to smooth the transition between data points. See also the documentation for this interpolation type.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#sec-allocation-settings",
    "href": "reference/usage.html#sec-allocation-settings",
    "title": "Usage",
    "section": "",
    "text": "There are the following allocation settings:\n\ntimestep: A float value in seconds which dictates the update interval for allocations;\nroute_priority: An integer per source type for the allocation algorithm. The prioritisable sources are: basin, level_boundary, linear_resistance, manning_resistance, outlet and pump.\n\nIf you wish to set the route priority for specific nodes rather than a fallback per node type, these can be set in the Node table.\nBy default, all nodes of the same type have the same route priority. To obtain a strict source ordering, the sources are sorted by node ID for each route priority within a subnetwork.\nWhen no default route priorities are specified, default values are applied (see the TOML example above).\n\nThe way the route priorities work is as follows: The priority that is assigned to a node is interpreted as the cost it takes for water to flow through that node. The flow through each node is multiplied with the priority, and we find the water distribution solution that has the lowest cost of fulfilling the desired demands.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#results-settings",
    "href": "reference/usage.html#results-settings",
    "title": "Usage",
    "section": "",
    "text": "The following entries can be set in the configuration in the [results] section.\n\n\n\n\n\n\n\n\nentry\ntype\ndescription\n\n\n\n\nformat\nString\nFile format, default is “arrow” for Apache Arrow, other option is “netcdf” for NetCDF with CF conventions.\n\n\ncompression\nBool\nWhether to apply compression or not.\n\n\ncompression_level\nInt\nZstandard compression level. Default is 6, higher compresses more.\n\n\nsubgrid\nBool\nCompute and output more detailed water levels.\n\n\n\nCurrently compression is only used for Apache Arrow. NetCDF will be the only output format later on.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#logging-settings",
    "href": "reference/usage.html#logging-settings",
    "title": "Usage",
    "section": "",
    "text": "The following can be set in the configuration in the [logging] section.\n\n\n\n\n\n\n\n\nentry\ntype\ndescription\n\n\n\n\nverbosity\nString\nVerbosity level: debug, info, warn, or error.\n\n\n\nIf verbosity is set to debug, the used Basin / profile dimensions (level, area and storage) are written to a CSV file in the results folder. This can be useful if you only provide 2 of the 3 columns and want to inspect the dimensions used in the computation.\nThe format of the CSV is: column 1 = node id, column 2 = level, column 3 = area and column 4 is storage.\nLets say you have 2 basins at node 1 and node 2. Dimensions node 1: level = [0, 1, 2], area = [2, 2, 4] and storage = [0, 2, 6], Dimensions node 1: level = [0, 1, 2], area = [4, 4, 8] and storage = [0, 4, 12].\nThen the CSV will look like:\n\n\n\nnode_id\nlevel\narea\nstorage\n\n\n\n\n1\n0\n2\n0\n\n\n1\n1\n2\n2\n\n\n1\n2\n4\n6\n\n\n2\n0\n4\n0\n\n\n2\n1\n4\n4\n\n\n2\n2\n8\n12",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#experimental-features",
    "href": "reference/usage.html#experimental-features",
    "title": "Usage",
    "section": "",
    "text": "Important\n\n\n\nExperimental features are completely unsupported. They can break at any time and results will be wrong. Do not use them in production. If you’re interested in using an experimental feature, please contact us.\n\n\nOne can enable experimental features in the [experimental] section. Currently the following features can be enabled (all are disabled by default).\n\n\n\n\n\n\n\n\nentry\ntype\ndescription\n\n\n\n\nconcentration\nBool\nWhether to enable tracer calculations or not.\n\n\nallocation\nBool\nWhether to activate the activation layer. Replaced by ‘first come first serve’ when deactivated",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#table-requirements",
    "href": "reference/usage.html#table-requirements",
    "title": "Usage",
    "section": "2.1 Table requirements",
    "text": "2.1 Table requirements\nBelow we give details per file, in which we describe the schema of the table using a syntax like this:\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nsorted\n\n\nstorage\nFloat64\n\\(\\text{m}^3\\)\nnon-negative\n\n\n\nThis means that two columns are required, one named node_id, that contained elements of type Int32, and a column named storage that contains elements of type Float64. The order of the columns does not matter. In some cases there may be restrictions on the values. This is indicated under restriction.\nTables are also allowed to have rows for timestamps that are not part of the simulation, these will be ignored. That makes it easy to prepare data for a larger period, and test models on a shorter period.\nWhen preparing the model for simulation, input validation is performed in the Julia core. The validation rules are described in the validation section.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#custom-metadata",
    "href": "reference/usage.html#custom-metadata",
    "title": "Usage",
    "section": "2.2 Custom metadata",
    "text": "2.2 Custom metadata\nIt may be advantageous to add metadata to rows. For example, basin areas might have names and objects such as weirs might have specific identification codes. Additional columns can be freely added to tables. The column names should be prefixed with meta_. They will not be used in computations or validated by the Julia core.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#cyclic-time-series",
    "href": "reference/usage.html#cyclic-time-series",
    "title": "Usage",
    "section": "3.1 Cyclic time series",
    "text": "3.1 Cyclic time series\nWhen cyclic_time is set to true for a node in the Node table, every time series associated with that node in the corresponding table(s) will be interpreted as cyclic. That is: the time series is exactly repeated left and right of the original time interval to cover the whole simulation period. For this it is validated that the first and last data values in the timeseries are the same. For instance, quarterly precipitation requires giving values for every quarter at the start of the quarter, and then the value for the first quarter again at the start of the next year.\nNote that periods like months or years are not of constant length in the calendar, so over long simulation periods the timeseries can get out of sync with these periods on the calendar.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#subnetwork-id",
    "href": "reference/usage.html#subnetwork-id",
    "title": "Usage",
    "section": "3.2 Subnetwork ID",
    "text": "3.2 Subnetwork ID\nNodes can only be controlled by allocation if the have a subnetwork_id. In the Node table, give for example subnetwork_id an integer value of 1 or 2.\nWhen Pumps and Outlets are part of a subnetwork, they can be controlled by allocation. To accomplish this, besides a subnetwork_id, they must be given the special control state Ribasim.allocation in the static table for Pump or Outlet.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#basin---basin",
    "href": "reference/usage.html#basin---basin",
    "title": "Usage",
    "section": "5.1 Basin - basin",
    "text": "5.1 Basin - basin\nThe Basin table contains:\n\nResults of the storage and level of each Basin, which are instantaneous values;\nResults of the fluxes on each Basin, which are mean values over the saveat intervals. In the time column the start of the period is indicated.\nThe initial condition is written to the file, but the final state is not. It will be placed in a separate output state file in the future.\nThe inflow_rate and outflow_rate are the sum of the flows from other nodes into and out of the Basin respectively. The actual flows determine in which term they are counted, not the link direction.\nThe storage_rate is the net mean flow that is needed to achieve the storage change between timesteps.\nThe inflow_rate consists of the sum of all modelled flows into the basin: inflow_rate (horizontal flows into the basin, independent of link direction) + precipitation + drainage.\nThe outflow_rate consists of the sum of all modelled flows out of the basin: outflow_rate (horizontal flows out of the basin, independent of link direction) + evaporation + infiltration.\nThe balance_error is the difference between the storage_rate on one side and the inflow_rate and outflow_rate on the other side: storage_rate - (inflow_rate - outflow_rate). It can be used to check if the numerical error when solving the water balance is sufficiently small.\nThe relative_error is the fraction of the balance_error over the mean of the total_inflow and total_outflow.\nThe convergence is the scaled residual of the solver, giving an indication of which nodes converge the worst (are hardest to solve).\n\nFor a more in-depth explanation of the water balance error see here.\n\n\n\ncolumn\ntype\nunit\n\n\n\n\ntime\nDateTime\n-\n\n\nnode_id\nInt32\n-\n\n\nlevel\nFloat64\n\\(\\text{m}\\)\n\n\nstorage\nFloat64\n\\(\\text{m}^3\\)\n\n\ninflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\noutflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\nstorage_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\nprecipitation\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\nsurface_runoff\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\nevaporation\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\ndrainage\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\ninfiltration\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\nbalance_error\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\nrelative_error\nFloat64\n-\n\n\nconvergence\nFloat64/Missing\n-\n\n\n\nThe table is sorted by time, and per time it is sorted by node_id.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#flow---flow",
    "href": "reference/usage.html#flow---flow",
    "title": "Usage",
    "section": "5.2 Flow - flow",
    "text": "5.2 Flow - flow\nThe flow table contains calculated mean flows over the saveat intervals for every flow link in the model. In the time column the start of the period is indicated.\n\n\n\ncolumn\ntype\nunit\n\n\n\n\ntime\nDateTime\n-\n\n\nlink_id\nInt32\n-\n\n\nfrom_node_type\nString\n-\n\n\nfrom_node_id\nInt32\n-\n\n\nto_node_type\nString\n-\n\n\nto_node_id\nInt32\n-\n\n\nflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\nconvergence\nFloat64/Missing\n-\n\n\n\nThe table is sorted by time, and per time the same link_id order is used, though not sorted. The link_id value is the same as the fid written to the Link table, and can be used to directly look up the Link geometry. Flows from the “from” to the “to” node have a positive sign, and if the flow is reversed it will be negative. - The convergence is the scaled residual of the solver, giving an indication of which nodes converge the worst (are hardest to solve).",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#sec-state",
    "href": "reference/usage.html#sec-state",
    "title": "Usage",
    "section": "5.3 State - basin_state",
    "text": "5.3 State - basin_state\nThe Basin state table contains the water levels in each Basin at the end of the simulation.\n\n\n\ncolumn\ntype\nunit\n\n\n\n\nnode_id\nInt32\n-\n\n\nlevel\nFloat64\n\\(\\text{m}\\)\n\n\n\nTo use this result as the initial condition of another simulation, see the Basin / state table reference.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#discretecontrol---control",
    "href": "reference/usage.html#discretecontrol---control",
    "title": "Usage",
    "section": "5.4 DiscreteControl - control",
    "text": "5.4 DiscreteControl - control\nThe control table contains a record of each change of control state: when it happened, which control node was involved, to which control state it changed and based on which truth state.\n\n\n\ncolumn\ntype\nunit\n\n\n\n\ntime\nDateTime\n-\n\n\ncontrol_node_id\nInt32\n-\n\n\ntruth_state\nString\n-\n\n\ncontrol_state\nString\n-",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#allocation---allocation",
    "href": "reference/usage.html#allocation---allocation",
    "title": "Usage",
    "section": "5.5 Allocation - allocation",
    "text": "5.5 Allocation - allocation\nThe allocation table contains a record of allocation results: when it happened, for which node, in which allocation network, and what the demand, allocated flow and realized flow were. The realized values at the starting time of the simulation can be ignored.\n\n\n\ncolumn\ntype\nunit\n\n\n\n\ntime\nDateTime\n-\n\n\nsubnetwork_id\nInt32\n-\n\n\nnode_type\nString\n-\n\n\nnode_id\nInt32\n-\n\n\ndemand_priority\nInt32\n-\n\n\ndemand\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\nallocated\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\nrealized\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe LevelDemand node allocations are listed as node type Basin. This is because one LevelDemand node can link to multiple Basins, and doesn’t receive flow by itself.\n\n\nFor Basins the values demand, allocated and realized are positive if the Basin level is below the minimum level given by a LevelDemand node. The values are negative if the Basin supplies due to a surplus of water.\n\n\n\n\n\n\nNote\n\n\n\nCurrently the stored demand and abstraction rate are those at the allocation timepoint (and the abstraction rate is based on the previous allocation optimization). In the future these will be an average over the previous allocation timestep.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#allocation-flow---allocation_flow",
    "href": "reference/usage.html#allocation-flow---allocation_flow",
    "title": "Usage",
    "section": "5.6 Allocation flow - allocation_flow",
    "text": "5.6 Allocation flow - allocation_flow\nThe allocation flow table contains results of the optimized allocation flow on every link in the model that is part of a subnetwork, for each time an optimization problem is solved (see also here). If in the model a primary network and subnetwork(s) are specified, there are 3 different types of optimization for the subnetwork: The column optimization_type provides the distinction between these optimization types.\n\ninternal_sources: first it will try using local sources internal to the subnetwork\ncollect_demands: collecting its total demand (for allocating flow from the primary network to the subnetwork)\nallocate: allocating flow within the subnetwork\n\n\n\n\ncolumn\ntype\nunit\n\n\n\n\ntime\nDateTime\n-\n\n\nlink_id\nInt32\n-\n\n\nfrom_node_type\nString\n-\n\n\nfrom_node_id\nInt32\n-\n\n\nto_node_type\nString\n-\n\n\nto_node_id\nInt32\n-\n\n\nsubnetwork_id\nInt32\n-\n\n\nflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\n\n\noptimization_type\nString\n-\n\n\nupper_bound_hit\nBool\n-\n\n\nlower_bound_hit\nBool\n-\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis file is currently not written when the results format is set to \"netcdf\".",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#allocation-feasibility-analysis---allocation_analysis_feasibility.log",
    "href": "reference/usage.html#allocation-feasibility-analysis---allocation_analysis_feasibility.log",
    "title": "Usage",
    "section": "5.7 Allocation feasibility analysis - allocation_analysis_feasibility.log",
    "text": "5.7 Allocation feasibility analysis - allocation_analysis_feasibility.log\nWhen an allocation optimization problem turns out to be infeasible, an infeasibility analysis is performed. Some user friendly data is logged in the main log, but the full report of the analysis is written to this separate file. For details on the infeasibility analysis see here.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#allocation-scaling-analysis---allocation_analysis_scaling.log",
    "href": "reference/usage.html#allocation-scaling-analysis---allocation_analysis_scaling.log",
    "title": "Usage",
    "section": "5.8 Allocation scaling analysis - allocation_analysis_scaling.log",
    "text": "5.8 Allocation scaling analysis - allocation_analysis_scaling.log\nWhen an allocation optimization problem turns out to be infeasible, a scaling analysis is performed. Some user friendly data is logged in the main log, but the full report of the analysis is written to this separate file. For details on the infeasibility analysis see here.",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#concentration---concentration",
    "href": "reference/usage.html#concentration---concentration",
    "title": "Usage",
    "section": "5.9 Concentration - concentration",
    "text": "5.9 Concentration - concentration\nIf the experimental concentration feature is enabled, the results are written to file. This file records the Basin concentrations for each substance over time. The schema below is identical to the external Basin concentration input.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\nBasin nodes only\n\n\ntime\nDateTime\n-\n\n\n\nsubstance\nString\n-\ncan correspond to known Delwaq substances\n\n\nconcentration\nFloat64\n\\(\\text{g}/\\text{m}^3\\)",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#subgrid-level---subgrid_level",
    "href": "reference/usage.html#subgrid-level---subgrid_level",
    "title": "Usage",
    "section": "5.10 Subgrid level - subgrid_level",
    "text": "5.10 Subgrid level - subgrid_level\nThis result file is only written if the model contains a Basin / subgrid table. See there for more information on the meaning of this output.\n\n\n\ncolumn\ntype\nunit\n\n\n\n\ntime\nDateTime\n-\n\n\nsubgrid_id\nInt32\n-\n\n\nsubgrid_level\nFloat64\n\\(\\text{m}\\)",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/usage.html#solver-statistics---solver_stats",
    "href": "reference/usage.html#solver-statistics---solver_stats",
    "title": "Usage",
    "section": "5.11 Solver statistics - solver_stats",
    "text": "5.11 Solver statistics - solver_stats\nThis result file contains statistics about the solver, which can give an insight into how well the solver is performing over time. The data is solved by saveat (see configuration file). water_balance refers to the right-hand-side function of the system of differential equations solved by the Ribasim core.\nThe computation_time is the wall time in milliseconds spent on the given period. The first row tends to include compilation time as well. The dt is the size (in seconds) of the last calculation timestep (at the saveat timestep).\n\n\n\ncolumn\ntype\nunit\n\n\n\n\ntime\nDateTime\n-\n\n\ncomputation_time\nFloat64\n\\(\\text{ms}\\)\n\n\nwater_balance_calls\nInt\n-\n\n\nlinear_solves\nInt\n-\n\n\naccepted_timesteps\nInt\n-\n\n\nrejected_timesteps\nInt\n-\n\n\ndt\nFloat64\n\\(\\text{s}\\)",
    "crumbs": [
      "Reference",
      "Usage"
    ]
  },
  {
    "objectID": "reference/node/junction.html",
    "href": "reference/node/junction.html",
    "title": "Junction",
    "section": "",
    "text": "A Junction node allows explicitly representing confluences and bifurcations in the network. It doesn’t introduce new behavior but makes it easier to make the network layout recognizable.\nJunctions can connect to other Junctions, but are not allowed to form cycles. Note that a confluence Junction followed by bifurcation Junction is generally invalid, as it will connect a connector node with multiple basins.\n\n1 Tables\nNo tables are required for Junction nodes.\n\n\n2 Equations\nJunctions connect all upstream nodes with all downstream nodes, and are not used in the equations themselves.\n\n\n3 Examples\nThis testmodel (juction_combined) with Junctions\n\n\n\n\n\nflowchart LR\n    C{Boundary} --&gt; E[/Junction\\]\n    E --&gt; F((Basin))\n    E --&gt; G((Basin))\n    F --&gt; H{Connector}\n    G --&gt; I{Connector}\n    H --&gt; J[/Junction\\]\n    I --&gt; J\n    J --&gt; K((Basin))\n\n\n\n\n\n\ntranslates to the following model:\n\n\n\n\n\nflowchart LR\n    C{Boundary} --&gt; F((Basin))\n    C --&gt; G((Basin))\n    F --&gt; H{Connector}\n    G --&gt; I{Connector}\n    H --&gt; K((Basin))\n    I --&gt; K\n\n\n\n\n\n\nAnd this testmodel (junction_chained) with Junctions\n\n\n\n\n\nflowchart LR\n    A{Connector} --&gt; D[/Junction\\]\n    B{Connector} --&gt; D[/Junction\\]\n    C{Connector} --&gt; E[/Junction\\]\n    D --&gt; E\n    E --&gt; F((Basin))\n\n\n\n\n\n\ntranslates to the following model:\n\n\n\n\n\nflowchart LR\n    A{Connector} --&gt; F((Basin))\n    B{Connector} --&gt; F\n    C{Connector} --&gt; F",
    "crumbs": [
      "Reference",
      "Nodes",
      "Junction"
    ]
  },
  {
    "objectID": "reference/node/tabulated-rating-curve.html",
    "href": "reference/node/tabulated-rating-curve.html",
    "title": "TabulatedRatingCurve",
    "section": "",
    "text": "A TabulatedRatingCurve determines outflow from a Basin by looking up the flow rate that corresponds to the current upstream level from a rating curve. The TabulatedRatingCurve takes a rating curve as input. Use it for instance to model flow over a weir.",
    "crumbs": [
      "Reference",
      "Nodes",
      "TabulatedRatingCurve"
    ]
  },
  {
    "objectID": "reference/node/tabulated-rating-curve.html#static",
    "href": "reference/node/tabulated-rating-curve.html#static",
    "title": "TabulatedRatingCurve",
    "section": "1.1 Static",
    "text": "1.1 Static\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\nlevel\nFloat64\n\\(\\text{m}\\)\nunique\n\n\nflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nstart at 0, increasing\n\n\nmax_downstream_level\nFloat64\n\\(\\text{m}\\)\n(optional)\n\n\ncontrol_state\nString\n-\n(optional)\n\n\n\n\n1.1.1 Interpolation\nThe \\(Q(h)\\) relationship of a tabulated rating curve is defined as a PCHIPInterpolation, for more information see here.\n\n\nCode\nusing DataInterpolations\nusing Plots\n\nlevel = [12.0, 12.2, 12.5, 13.0]\nflow = [0.0, 0.5, 2.5, 8.0]\n\nlevel_aug = copy(level)\nflow_aug = copy(flow)\n\npushfirst!(level_aug, first(level) - 1.0)\npushfirst!(flow_aug, 0.0)\n\nitp = PCHIPInterpolation(\n    flow_aug,\n    level_aug;\n    extrapolation_right = DataInterpolations.ExtrapolationType.Linear,\n)\n\nlevel_eval = range(first(level), last(level); length = 1000)\nflow_eval = itp.(level_eval)\n\nlevel_extrap_left = [first(level) - 0.3, first(level)]\nflow_extrap_left = itp.(level_extrap_left)\n\nlevel_extrap_right = [last(level), last(level) + 0.3]\nflow_extrap_right = itp.(level_extrap_right)\n\nc = :blue\nplot(\n    level_eval,\n    flow_eval;\n    c,\n    label = \"interpolation\",\n    xticks = false,\n    yticks = false,\n    left_margin = 5Plots.mm,\n)\nplot!(level_extrap_left, flow_extrap_left; ls = :dash, c, label = \"extrapolation\")\nplot!(level_extrap_right, flow_extrap_right; ls = :dash, c, label = \"\")\nscatter!(level, flow; c, label = \"data\", markeralpha = 0.25)\nxlabel!(\"level\")\nylabel!(\"flow\")\nxlims!(first(level) - 0.2, last(level) + 0.2)\n\n\n\n\n\nBelow the lowest given level of 12.0, the flow rate is kept at 0. Between given levels the flow rate is interpolated using PCHIP interpolation. Above the maximum given level of 13.0, the flow rate keeps increases linearly according to the slope of the last segment.\nFor tabulated rating curves with a fixed maximum value (e.g. max capacity of a weir), enter a new row and re-enter the maximum flow_rate at a higher level:\n\n\n\nnode_id\nlevel\nflow_rate\n\n\n\n\n2\n12.0\n0.0\n\n\n2\n12.2\n0.5\n\n\n2\n12.5\n2.5\n\n\n2\n13.0\n8.0\n\n\n2\n13.1\n8.0\n\n\n\nNow this tabulated rating curve node has a flow rate of 8.0 \\(\\text{m}^3/\\text{s}\\) for for all levels 13.0 or higher.\nThe flow rate is not allowed to decrease with higher levels. If you wish to e.g. simulate the (partial) closing of a weir when the water level exceeds a certain threshold, you can use and Outlet with a control node to set flow rates.",
    "crumbs": [
      "Reference",
      "Nodes",
      "TabulatedRatingCurve"
    ]
  },
  {
    "objectID": "reference/node/tabulated-rating-curve.html#time",
    "href": "reference/node/tabulated-rating-curve.html#time",
    "title": "TabulatedRatingCurve",
    "section": "1.2 Time",
    "text": "1.2 Time\nThis table is the transient form of the TabulatedRatingCurve table. The only difference is that a time column is added. With this the rating curves can be updated over time. The max_downstream_level currently cannot be updated over time. Note that a node_id can be either in this table or in the static one, but not both.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ntime\nDateTime\n-\n\n\n\nlevel\nFloat64\n\\(\\text{m}\\)\n\n\n\nflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative\n\n\nmax_downstream_level\nFloat64\n\\(\\text{m}\\)\n(optional)",
    "crumbs": [
      "Reference",
      "Nodes",
      "TabulatedRatingCurve"
    ]
  },
  {
    "objectID": "reference/node/manning-resistance.html",
    "href": "reference/node/manning-resistance.html",
    "title": "ManningResistance",
    "section": "",
    "text": "The ManningResistance node calculates a flow rate between two Basins based on their water levels. The flow rate is calculated by conservation of energy and the Manning-Gauckler formula to estimate friction losses.",
    "crumbs": [
      "Reference",
      "Nodes",
      "ManningResistance"
    ]
  },
  {
    "objectID": "reference/node/manning-resistance.html#static",
    "href": "reference/node/manning-resistance.html#static",
    "title": "ManningResistance",
    "section": "1.1 Static",
    "text": "1.1 Static\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\nlength\nFloat64\n\\(\\text{m}\\)\npositive\n\n\nmanning_n\nFloat64\n\\(\\text{s} \\text{m}^{-\\frac{1}{3}}\\)\npositive\n\n\nprofile_width\nFloat64\n\\(\\text{m}\\)\npositive\n\n\nprofile_slope\nFloat64\n-\n-\n\n\ncontrol_state\nString\n-\n(optional)",
    "crumbs": [
      "Reference",
      "Nodes",
      "ManningResistance"
    ]
  },
  {
    "objectID": "reference/node/level-boundary.html",
    "href": "reference/node/level-boundary.html",
    "title": "LevelBoundary",
    "section": "",
    "text": "LevelBoundary is a node whose water level is determined by the input. It can be used as a boundary condition like the level of the sea or a lake. Since the water level is unaffected by flow, it acts like an infinitely large Basin. Connect the LevelBoundary to a node that will look at the level to calculate the flow, like a LinearResistance.",
    "crumbs": [
      "Reference",
      "Nodes",
      "LevelBoundary"
    ]
  },
  {
    "objectID": "reference/node/level-boundary.html#static",
    "href": "reference/node/level-boundary.html#static",
    "title": "LevelBoundary",
    "section": "1.1 Static",
    "text": "1.1 Static\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\nlevel\nFloat64\n\\(\\text{m}\\)\n-",
    "crumbs": [
      "Reference",
      "Nodes",
      "LevelBoundary"
    ]
  },
  {
    "objectID": "reference/node/level-boundary.html#time",
    "href": "reference/node/level-boundary.html#time",
    "title": "LevelBoundary",
    "section": "1.2 Time",
    "text": "1.2 Time\nThis table is the transient form of the LevelBoundary table. The only difference is that a time column is added. With this the levels can be updated over time. In between the given times the level is interpolated linearly, and outside the flow rate is constant given by the nearest time value. Note that a node_id can be either in this table or in the static one, but not both.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ntime\nDateTime\n-\n\n\n\nlevel\nFloat64\n\\(\\text{m}\\)\n-",
    "crumbs": [
      "Reference",
      "Nodes",
      "LevelBoundary"
    ]
  },
  {
    "objectID": "reference/node/level-boundary.html#sec-level-boundary-conc",
    "href": "reference/node/level-boundary.html#sec-level-boundary-conc",
    "title": "LevelBoundary",
    "section": "1.3 Concentration",
    "text": "1.3 Concentration\nThis table defines the concentration of substances for the flow from the LevelBoundary.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ntime\nDateTime\n-\n\n\n\nsubstance\nString\n-\ncan correspond to known Delwaq substances\n\n\nconcentration\nFloat64\n\\(\\text{g}/\\text{m}^3\\)",
    "crumbs": [
      "Reference",
      "Nodes",
      "LevelBoundary"
    ]
  },
  {
    "objectID": "reference/node/level-demand.html",
    "href": "reference/node/level-demand.html",
    "title": "LevelDemand",
    "section": "",
    "text": "A LevelDemand node associates a minimum and a maximum level (possibly multiple over different priorities) with connected Basins to be used by the allocation algorithm.\nSince this connection conveys information rather than flow, an outgoing control link must be used. Below the minimum level the Basin has a demand, above the maximum level the Basin has a surplus and acts as a source. The source can be used by all nodes with demands in order of demand priority.\nThe same LevelDemand node can be used for Basins in different subnetworks.\nBoth min_level and max_level are optional, to be able to handle only the demand or surplus side. If both are missing, LevelDemand won’t have any effects on allocation.",
    "crumbs": [
      "Reference",
      "Nodes",
      "LevelDemand"
    ]
  },
  {
    "objectID": "reference/node/level-demand.html#static",
    "href": "reference/node/level-demand.html#static",
    "title": "LevelDemand",
    "section": "1.1 Static",
    "text": "1.1 Static\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\nmin_level\nFloat64\n\\(\\text{m}\\)\n(optional, default -Inf)\n\n\nmax_level\nFloat64\n\\(\\text{m}\\)\n(optional, default Inf)\n\n\ndemand_priority\nInt32\n-\npositive",
    "crumbs": [
      "Reference",
      "Nodes",
      "LevelDemand"
    ]
  },
  {
    "objectID": "reference/node/level-demand.html#time",
    "href": "reference/node/level-demand.html#time",
    "title": "LevelDemand",
    "section": "1.2 Time",
    "text": "1.2 Time\nThis table is the transient form of the LevelDemand table, in which time-dependent minimum and maximum levels can be supplied. With this the levels can be updated over time. In between the given times the levels are interpolated with forward fill (block interpolation), and outside the demand is constant given by the nearest time value. The allocation algorithm evaluates the interpolation at the end of the allocation time step.\nThis is in contrast with UserDemand and FlowDemand, as allocation will aim to reach the desired level at the end of the allocation time step.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ntime\nDateTime\n-\n\n\n\nmin_level\nFloat64\n\\(\\text{m}\\)\n-\n\n\nmax_level\nFloat64\n\\(\\text{m}\\)\n-\n\n\ndemand_priority\nInt32\n-\npositive",
    "crumbs": [
      "Reference",
      "Nodes",
      "LevelDemand"
    ]
  },
  {
    "objectID": "reference/node/flow-demand.html",
    "href": "reference/node/flow-demand.html",
    "title": "FlowDemand",
    "section": "",
    "text": "A FlowDemand node associates a non-consuming flow demand to a connector node (e.g. Pump, TabulatedRatingCurve) for one or more demand priorities. FlowDemand nodes can set a flow demand only for a single connector node. FlowDemand nodes do nothing when allocation is not activated, except when they are connected to a Pump or an Outlet. In that case the flow demand flow rate is taken as the minimum flow through that Pump or Outlet.",
    "crumbs": [
      "Reference",
      "Nodes",
      "FlowDemand"
    ]
  },
  {
    "objectID": "reference/node/flow-demand.html#static",
    "href": "reference/node/flow-demand.html#static",
    "title": "FlowDemand",
    "section": "1.1 Static",
    "text": "1.1 Static\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ndemand_priority\nInt32\n-\npositive\n\n\ndemand\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative",
    "crumbs": [
      "Reference",
      "Nodes",
      "FlowDemand"
    ]
  },
  {
    "objectID": "reference/node/flow-demand.html#time",
    "href": "reference/node/flow-demand.html#time",
    "title": "FlowDemand",
    "section": "1.2 Time",
    "text": "1.2 Time\nThis table is the transient form of the FlowDemand table, in which a time-dependent demand can be supplied. With this the demand can be updated over time. In between the given times the demand is block interpolated (forward fill), and outside the demand is constant given by the nearest time value. The allocation algorithm evaluates the interpolation at the start of the allocation time step.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ntime\nDateTime\n-\n\n\n\ndemand_priority\nInt32\n-\npositive\n\n\ndemand\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative",
    "crumbs": [
      "Reference",
      "Nodes",
      "FlowDemand"
    ]
  },
  {
    "objectID": "reference/node/flow-boundary.html",
    "href": "reference/node/flow-boundary.html",
    "title": "FlowBoundary",
    "section": "",
    "text": "A FlowBoundary adds water to the model at a specified flow rate. It can be used as a boundary condition like a measured upstream flow rate, or lateral inflow. We require that an link connected to a FlowBoundary is always outgoing, and points towards a Basin.",
    "crumbs": [
      "Reference",
      "Nodes",
      "FlowBoundary"
    ]
  },
  {
    "objectID": "reference/node/flow-boundary.html#static",
    "href": "reference/node/flow-boundary.html#static",
    "title": "FlowBoundary",
    "section": "1.1 Static",
    "text": "1.1 Static\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\nflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative",
    "crumbs": [
      "Reference",
      "Nodes",
      "FlowBoundary"
    ]
  },
  {
    "objectID": "reference/node/flow-boundary.html#time",
    "href": "reference/node/flow-boundary.html#time",
    "title": "FlowBoundary",
    "section": "1.2 Time",
    "text": "1.2 Time\nThis table is the transient form of the FlowBoundary table. The only difference is that a time column is added. With this the flow rates can be updated over time. In between the given times the flow rate is interpolated in a way specified in the interpolation settings (block interpolation by default), and outside the flow rate is constant given by the nearest time value unless the node is cyclic in time. Note that a node_id can be either in this table or in the static one, but not both.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ntime\nDateTime\n-\n\n\n\nflow_rate\nFloat64\n\\(\\text{m}^3/\\text{s}\\)\nnon-negative",
    "crumbs": [
      "Reference",
      "Nodes",
      "FlowBoundary"
    ]
  },
  {
    "objectID": "reference/node/flow-boundary.html#sec-flow-boundary-conc",
    "href": "reference/node/flow-boundary.html#sec-flow-boundary-conc",
    "title": "FlowBoundary",
    "section": "1.3 Concentration",
    "text": "1.3 Concentration\nThis table defines the concentration of substances for the flow from the FlowBoundary.\n\n\n\n\n\n\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\ntime\nDateTime\n-\n\n\n\nsubstance\nString\n-\ncan correspond to known Delwaq substances\n\n\nconcentration\nFloat64\n\\(\\text{g}/\\text{m}^3\\)",
    "crumbs": [
      "Reference",
      "Nodes",
      "FlowBoundary"
    ]
  },
  {
    "objectID": "reference/node/flow-boundary.html#area",
    "href": "reference/node/flow-boundary.html#area",
    "title": "FlowBoundary",
    "section": "1.4 Area",
    "text": "1.4 Area\nThe optional area table is not used during computation, but provides a place to associate areas in the form of polygons to a FlowBoundary. Using this makes it easier to recognize which water or land surfaces are represented by a FlowBoundary.\n\n\n\ncolumn\ntype\nrestriction\n\n\n\n\nnode_id\nInt32\n\n\n\ngeom\nPolygon or MultiPolygon\n(optional)",
    "crumbs": [
      "Reference",
      "Nodes",
      "FlowBoundary"
    ]
  },
  {
    "objectID": "reference/node/pid-control.html",
    "href": "reference/node/pid-control.html",
    "title": "PidControl",
    "section": "",
    "text": "The PidControl node controls the level in a Basin by continuously controlling the flow rate of a connected Pump or Outlet. See also PID controller.\nIn the future controlling the flow on a particular link could be supported.",
    "crumbs": [
      "Reference",
      "Nodes",
      "PidControl"
    ]
  },
  {
    "objectID": "reference/node/pid-control.html#time",
    "href": "reference/node/pid-control.html#time",
    "title": "PidControl",
    "section": "2.1 Time",
    "text": "2.1 Time\nThis table is the transient form of the PidControl table. The difference is that a time column is added. With this the target level and PID coefficients can be updated over time. In between the given times the these values interpolated linearly, and outside these values area constant given by the nearest time value. Note that a node_id can be either in this table or in the static one, but not both.\n\n\n\ncolumn\ntype\nunit\nrestriction\n\n\n\n\nnode_id\nInt32\n-\n\n\n\nlisten_node_id\nInt32\n-\nmust be a Basin\n\n\ntime\nDateTime\n-\n\n\n\ntarget\nFloat64\n\\(\\text{m}\\)\n-\n\n\nproportional\nFloat64\n\\(\\text{s}^{-1}\\)\n-\n\n\nintegral\nFloat64\n\\(\\text{s}^{-2}\\)\n-\n\n\nderivative\nFloat64\n-\n-",
    "crumbs": [
      "Reference",
      "Nodes",
      "PidControl"
    ]
  },
  {
    "objectID": "reference/node/pid-control.html#the-derivative-term",
    "href": "reference/node/pid-control.html#the-derivative-term",
    "title": "PidControl",
    "section": "3.1 The derivative term",
    "text": "3.1 The derivative term\nWhen \\(K_d \\ne 0\\) this adds a level of complexity. We can see this by looking at the error derivative more closely: \\[\n\\frac{\\text{d}e}{\\text{d}t} = \\frac{\\text{d}\\text{SP}}{\\text{d}t} - \\frac{1}{A(u_\\text{PID})}\\frac{\\text{d}u_\\text{PID}}{\\text{d}t},\n\\]\nwhere \\(A(u_\\text{PID})\\) is the area of the controlled basin as a function of the storage of the controlled basin \\(u_\\text{PID}\\). The complexity arises from the fact that \\(Q_\\text{PID}\\) is a contribution to \\(\\frac{\\text{d}u_\\text{PID}}{\\text{d}t} = f_\\text{PID}\\), which makes Equation 2 an implicit equation for \\(Q_\\text{PID}\\). We define\n\\[\nf_\\text{PID} = \\hat{f}_\\text{PID} \\pm Q_\\text{pump/outlet},\n\\]\nthat is, \\(\\hat{f}_\\text{PID}\\) is the right hand side of the ODE for the controlled basin storage state without the contribution of the PID controlled pump. The plus sign holds for an outlet and the minus sign for a pump, dictated by the way the pump and outlet connectivity to the controlled basin is enforced.\nUsing this, solving Equation 2 for \\(Q_\\text{PID}\\) yields \\[\nQ_\\text{pump/outlet} = \\text{clamp}\\left(\\phi(u_\\text{us})\\frac{K_pe + K_iI + K_d \\left(\\frac{\\text{d}\\text{SP}}{\\text{d}t}-\\frac{\\hat{f}_\\text{PID}}{A(u_\\text{PID})}\\right)}{1\\pm\\phi(u_\\text{us})\\frac{K_d}{A(u_\\text{PID})}}, Q_{\\min}, Q_{\\max}\\right),\n\\]\nwhere the clamping is again done last. Note that to compute this, \\(\\hat{f}_\\text{PID}\\) has to be known first, meaning that the PID controlled Pump or Outlet flow rate has to be computed after all other contributions to the PID controlled Basin’s storage are known.",
    "crumbs": [
      "Reference",
      "Nodes",
      "PidControl"
    ]
  },
  {
    "objectID": "reference/node/pid-control.html#the-sign-of-the-parameters",
    "href": "reference/node/pid-control.html#the-sign-of-the-parameters",
    "title": "PidControl",
    "section": "3.2 The sign of the parameters",
    "text": "3.2 The sign of the parameters\nNote by Equation 1 that the error is positive if the setpoint is larger than the Basin level and negative if the setpoint is smaller than the Basin level.\nWe enforce the convention that when a Pump is controlled, its link points away from the Basin, and when an Outlet is controlled, its link points towards the Basin, so that the main flow direction along these links is positive. Therefore, positive flows of the Pump and Outlet have opposite effects on the Basin, and thus the parameters \\(K_p,K_i,K_d\\) of the Pump and Outlet must have opposite signs to achieve the same goal.",
    "crumbs": [
      "Reference",
      "Nodes",
      "PidControl"
    ]
  },
  {
    "objectID": "guide/debug.html",
    "href": "guide/debug.html",
    "title": "Debugging models",
    "section": "",
    "text": "When a connector node (e.g., TabulatedRatingCurve, Pump, Outlet, ManningResistance) produces unexpected flow rates, it’s important to understand how Ribasim calculates flows and which reduction factors may apply.\n\n\nEach connector node type has specific equations that govern its behavior. Review the equations for your node type in the reference documentation. For example, see the TabulatedRatingCurve equations.\n\n\n\nRibasim applies several reduction factors that can limit flows. To verify that none of them unexpectedly applies, check the following examples:\n\nUpstream Basin level and storage: If the upstream Basin is nearly empty, a reduction factor prevents extracting more water than available.\nDownstream Basin level: If the downstream Basin level is higher, only Pumps can flow against gravity.\nConnector node parameters: Review the node’s parameters in your model input to ensure they match your expectations. Parameters like max_flow_rate or min_upstream_level directly affect the computed flow.\n\n\n\n\nIf the node is subject to control or allocation:\n\nDiscrete Control: Check the control results to see which control state is active and when it changes. The active state determines which parameter set is used.\nAllocation: Check the allocation results to see the allocated flow for the node.\n\nIn all these cases the reduction factors still apply, and may be the reason allocated flows cannot be realized.",
    "crumbs": [
      "How-to guides",
      "Debugging models"
    ]
  },
  {
    "objectID": "guide/debug.html#unexpected-flow-rates",
    "href": "guide/debug.html#unexpected-flow-rates",
    "title": "Debugging models",
    "section": "",
    "text": "When a connector node (e.g., TabulatedRatingCurve, Pump, Outlet, ManningResistance) produces unexpected flow rates, it’s important to understand how Ribasim calculates flows and which reduction factors may apply.\n\n\nEach connector node type has specific equations that govern its behavior. Review the equations for your node type in the reference documentation. For example, see the TabulatedRatingCurve equations.\n\n\n\nRibasim applies several reduction factors that can limit flows. To verify that none of them unexpectedly applies, check the following examples:\n\nUpstream Basin level and storage: If the upstream Basin is nearly empty, a reduction factor prevents extracting more water than available.\nDownstream Basin level: If the downstream Basin level is higher, only Pumps can flow against gravity.\nConnector node parameters: Review the node’s parameters in your model input to ensure they match your expectations. Parameters like max_flow_rate or min_upstream_level directly affect the computed flow.\n\n\n\n\nIf the node is subject to control or allocation:\n\nDiscrete Control: Check the control results to see which control state is active and when it changes. The active state determines which parameter set is used.\nAllocation: Check the allocation results to see the allocated flow for the node.\n\nIn all these cases the reduction factors still apply, and may be the reason allocated flows cannot be realized.",
    "crumbs": [
      "How-to guides",
      "Debugging models"
    ]
  },
  {
    "objectID": "guide/debug.html#slow-models",
    "href": "guide/debug.html#slow-models",
    "title": "Debugging models",
    "section": "2 Slow models",
    "text": "2 Slow models\nWhen your model is slow, it’s often only a handful of nodes that are hard to solve. If the model finishes or is interrupted, convergence bottlenecks are shown like so:\n┌ Info: Convergence bottlenecks in descending order of severity:\n│   ManningResistance #251242 = 0.09023997405863035\n│   ManningResistance #70523 = 0.006218636603583534\n│   ManningResistance #251181 = 0.004716432403226626\n│   ManningResistance #251182 = 0.0035319514660666165\n└   ManningResistance #591558 = 0.003284110004804508\nIt’s best to inspect these nodes, and try to adjust the parametrization, or merge smaller nodes. You can find the convergence measure per node over time in the flow.arrow and basin.arrow output files.\nTo gain further insight into model performance, one can inspect the solver_stats.arrow output file, which gives the number of computations, number of rejected and accepted solutions, and the size of each calculation timestep.",
    "crumbs": [
      "How-to guides",
      "Debugging models"
    ]
  },
  {
    "objectID": "guide/debug.html#unstable-models",
    "href": "guide/debug.html#unstable-models",
    "title": "Debugging models",
    "section": "3 Unstable models",
    "text": "3 Unstable models\nWhen your model exits with a message like so:\n┌ Error: The model exited at model time 2024-01-27T14:46:17.791 with return code Unstable. See https://docs.sciml.ai/DiffEqDocs/stable/basics/solution/#retcodes\nit’s best to rerun the model with saveat = 0 in the solver settings. The model might then instead exit with\n┌ Error: Too large water balance error\n│   id = Basin #2\n│   balance_error = 0.0017985748886167501\n│   relative_error = 1.3503344464431657\nwhich helps you pin down the problematic node(s). The normal output for every calculation timestep is written until the moment of error, so one can use this information to understand the problem.",
    "crumbs": [
      "How-to guides",
      "Debugging models"
    ]
  },
  {
    "objectID": "guide/updating-ribasim.html",
    "href": "guide/updating-ribasim.html",
    "title": "Updating Ribasim",
    "section": "",
    "text": "This guide explains how to update Ribasim models from older versions to newer versions. To update the Ribasim installation itself, follow the installation steps, ensuring that all installed components are the same. To see the most important changes in Ribasim, consult the changelog.\n\n1 Version numbers and breaking changes\nRibasim uses version numbers like 2023.1.0, following YYYY.MINOR.MICRO from calver. It starts with the year the release was made, followed by the minor version number for normal releases, and a micro number for non-breaking, hotfix releases. This means that whenever the year or minor version changes, there is a possibility that the user has to make changes to the model for it to keep working. If this is the case, it will be highlighted in the changelog. When possible, we automate this process using model migration in Ribasim Python, see the section below.\n\n\n2 Automatic model migration\nModels are automatically migrated when read from file using Ribasim Python, and this is the recommended way to update your models.\nThe Ribasim Python package contains a set of migration functions that are applied automatically when you read a model file from an older version. When Ribasim developers make changes to the model structure (for example, adding new required columns to tables), these changes would normally break compatibility with existing models. To prevent this, migration functions automatically update your model data to match the current version’s requirements.\nThe core always expects models to be written by the same Ribasim Python version as itself, which is why it gives a warning whenever the ribasim_version in the TOML does not match ribasim --version.\nWhen you read an older model, Ribasim Python will automatically apply all necessary migrations and update the model version accordingly. To migrate an existing model to the latest version, simply use the following script:\nimport ribasim\n\n# Read the old model (migration happens automatically)\nmodel = ribasim.Model.read(\"path/to/your/old_model.toml\")\n\n# Write the migrated model\nmodel.write(\"path/to/your/migrated_model.toml\")\nIf you have a script that builds your model from scratch, simply re-running that script with the new Ribasim Python version will produce a model with the updated version, making the above migration step unnecessary.",
    "crumbs": [
      "How-to guides",
      "Updating Ribasim"
    ]
  },
  {
    "objectID": "guide/coupling.html",
    "href": "guide/coupling.html",
    "title": "Coupling",
    "section": "",
    "text": "Ribasim can also be (online) coupled to other kernels with the help of iMOD Coupler. The corresponding documentation can be found within the iMOD Suite Documentation.",
    "crumbs": [
      "How-to guides",
      "Coupling"
    ]
  },
  {
    "objectID": "guide/coupling.html#setup",
    "href": "guide/coupling.html#setup",
    "title": "Coupling",
    "section": "2.1 Setup",
    "text": "2.1 Setup\nDelwaq can calculate the concentration of substances in Basin nodes over time, based on initial concentrations, and of FlowBoundary nodes. Ribasim exposes the Basin / concentration, Basin / concentration_state, FlowBoundary / concentration, and LevelBoundary / concentration tables to setup these substances and concentrations.\nWhen a Ribasim model ran with the above tables, one can use the utilities in the delwaq namespace of the Ribasim Python API to generate the input required for Delwaq to run, as well as to parse the output from Delwaq into a Ribasim compatible format. For more information see the guide.",
    "crumbs": [
      "How-to guides",
      "Coupling"
    ]
  },
  {
    "objectID": "dev/allocation.html",
    "href": "dev/allocation.html",
    "title": "Allocation",
    "section": "",
    "text": "This document provides a comprehensive technical reference for the allocation implementation in Ribasim. It bridges the gap between the mathematical formulation described in the concept documentation and the actual code implementation using JuMP.jl.\nThe allocation algorithm solves linear optimization problems to distribute water among competing demands. This document explains:\n\nHow mathematical formulations translate to JuMP code\nProblem Building (placeholder initialization → real value updates)\nIntegration between the physical layer and optimization layer\nData structures and indexing patterns\nImplementation details for each node type",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#problem-building",
    "href": "dev/allocation.html#problem-building",
    "title": "Allocation",
    "section": "2.1 Problem Building",
    "text": "2.1 Problem Building\nThe allocation optimization problems are build using a two-phase approach:\n\n2.1.1 Phase 1: Problem Structure Initialization (allocation_init.jl)\nDuring initialization, JuMP variables and constraints are created with placeholder values. These placeholders define the structure and relationships but not the actual values:\n# Example from add_basin! function\ncurrent_storage = 1000.0 # Placeholder value\nmax_storage = 5000.0 # Placeholder value\nproblem[:basin_storage_change] = JuMP.@variable(\n    problem,\n    -current_storage / scaling.storage ≤\n    basin_storage_change[node_id = basin_ids_subnetwork] ≤\n    (max_storage - current_storage) / scaling.storage\n)\nWhy placeholders? JuMP requires the problem structure (variables, constraints, objective) to be defined upfront. The actual physical values (water levels, flows, demands) are not yet known during initialization and will change at each allocation timestep.\n\n\n2.1.2 Phase 2: Real Value Updates (allocation_optim.jl)\nBefore each optimization, the set_simulation_data! functions update constraints with real values from the physical layer:\n# From set_simulation_data! for Basin\nfor basin_id in basin_ids_subnetwork\n    basin_idx = basin_id.idx\n    current_storage_basin = current_storage[basin_idx]\n\n    # Update the variable bounds with actual storage values\n    storage_change_variable = storage_change[basin_id]\n    JuMP.set_lower_bound(\n        storage_change_variable,\n        -current_storage_basin / scaling.storage\n    )\n    # ... more updates\nend\nThis pattern allows efficient repeated optimization: the problem structure remains fixed while only the constraint coefficients and bounds are updated.",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#physical-layer-integration",
    "href": "dev/allocation.html#physical-layer-integration",
    "title": "Allocation",
    "section": "2.2 Physical Layer Integration",
    "text": "2.2 Physical Layer Integration\nThe allocation layer operates on a linearized version of the physical layer. Here’s how physical quantities map to optimization variables:\n\n2.2.1 Basin Levels and Storage\nIn the physical layer, basin level \\(h\\) is a nonlinear function of storage \\(S\\) determined by the basin profile (area-storage relationship). For optimization, we linearize around the current state:\nMathematical formulation: \\[h^{n+1} \\approx h^n + \\frac{1}{A^n}(S^{n+1} - S^n)\\]\nwhere \\(A^n\\) is the basin area at the current timestep.\nCode implementation:\n# In set_simulation_data! for Basin\n# Get linearization point\nh_n = basin.current_level[basin_idx]\nA_n = current_area[basin_idx]  # Area at current level\nS_n = current_storage[basin_idx]\n\n# Define the decision variable for storage change\n# ΔS = S^{n+1} - S^n (scaled)\nstorage_change = problem[:basin_storage_change]\n\n# The level at end of timestep is:\n# h^{n+1} = h^n + (1/A^n) * ΔS\n# This relationship is embedded in constraint coefficients (see below)\n\n\n2.2.2 Connector Nodes (Flow as Function of Levels)\nNodes like TabulatedRatingCurve, LinearResistance, and ManningResistance have flow \\(Q\\) that depends on upstream level \\(h_a\\) and downstream level \\(h_b\\):\nMathematical formulation: \\[Q^{n+1} \\approx Q^n + \\frac{\\partial Q}{\\partial h_a}(h_a - h_a^n) + \\frac{\\partial Q}{\\partial h_b}(h_b - h_b^n)\\]\nFor a basin downstream: \\(h_b^{n+1} - h_b^n \\approx \\frac{1}{A_b}(S_b^{n+1} - S_b^n)\\)\nCode implementation:\n# From linearize_connector_node!\n# Evaluate flow and derivatives at current state\nh_a = get_level(p, upstream_id, t)\nh_b = get_level(p, downstream_id, t)\nQ_n = flow_function(p, upstream_id, downstream_id, t_after)\n\n# Compute partial derivatives\n∂Q∂h_a = derivative_flow_wrt_level(p, upstream_id, downstream_id, t_after, :upstream)\n∂Q∂h_b = derivative_flow_wrt_level(p, upstream_id, downstream_id, t_after, :downstream)\n\n# Update constraint: Q = Q^n + ∂Q/∂h_a * (h_a - h_a^n) + ∂Q/∂h_b * (h_b - h_b^n)\n# When h_b is a basin, substitute the linearized profile:\n# Q = Q^n + (∂Q/∂h_b / A_b) * ΔS_b + ...\nThe function set_partial_derivative_wrt_level! handles converting level derivatives to storage derivatives:\nfunction set_partial_derivative_wrt_level!(\n    allocation_model::AllocationModel,\n    node_id::NodeID,\n    ∂q∂h::Float64,  # Partial derivative of flow w.r.t. level\n    p::Parameters,\n    constraint::JuMP.ConstraintRef,\n)::Nothing\n    (; problem, scaling) = allocation_model\n    (; current_area) = p.state_and_time_dependent_cache\n\n    # Convert ∂Q/∂h to ∂Q/∂S using ∂h/∂S = 1/A\n    storage_change = problem[:basin_storage_change][node_id]\n    JuMP.set_normalized_coefficient(\n        constraint,\n        storage_change,\n        ∂q∂h / (current_area[node_id.idx] * scaling.flow * Δt_allocation)\n    )\n    return nothing\nend",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#decision-variables",
    "href": "dev/allocation.html#decision-variables",
    "title": "Allocation",
    "section": "3.1 Decision Variables",
    "text": "3.1 Decision Variables\n\n3.1.1 Flow Variables\nMathematical formulation: For each link \\((i,j)\\) in the network, a flow variable \\(Q_{ij}\\) represents the volumetric flow rate.\nCode implementation:\n# From add_flow!\nproblem[:flow] = JuMP.@variable(\n    problem,\n    flow_capacity_lower_bound(link, p_independent) / scaling.flow ≤\n    flow[link = flow_links_subnetwork] ≤\n    flow_capacity_upper_bound(link, p_independent) / scaling.flow\n)\nKey points: - Indexed by link::Tuple{NodeID, NodeID} representing (source, destination) - Bounds determined by node capacities (pump max flow, etc.) - Scaled by scaling.flow for numerical stability - Stored in sparse array for efficient access: problem[:flow][link]\n\n\n3.1.2 Basin Storage Change Variables\nMathematical formulation: For each basin \\(b\\), a storage change variable \\(\\Delta S_b = S_b^{n+1} - S_b^n\\) represents the change in storage over the allocation timestep.\nCode implementation:\n# From add_basin!\nproblem[:basin_storage_change] = JuMP.@variable(\n    problem,\n    -current_storage / scaling.storage ≤\n    basin_storage_change[node_id = basin_ids_subnetwork] ≤\n    (max_storage - current_storage) / scaling.storage\n)\nKey points: - Lower bound prevents storage from going negative - Upper bound prevents exceeding maximum basin capacity - Placeholder values replaced before each optimization - Scaled by scaling.storage for numerical conditioning\n\n\n3.1.3 Allocated Flow Variables (Demand Nodes)\nMathematical formulation: For each demand node \\(v\\) and priority \\(p \\in P_v\\): \\[0 \\le F^p_v \\le d_v^p\\]\nCode implementation:\n# From add_user_demand!\nuser_demand_allocated = JuMP.@variable(\n    problem,\n    0 ≤ user_demand_allocated[\n        node_id = user_demand_ids_subnetwork,\n        demand_priority = demand_priorities_all;\n        has_demand_priority[node_id.idx, demand_priority_idx]\n    ] ≤ d / scaling.flow\n)\nKey points: - Doubly-indexed by (node_id, demand_priority) - Only created for priorities where has_demand_priority is true - Bounded by demand value (placeholder, updated before optimization) - Similar structures for FlowDemand and LevelDemand\n\n\n3.1.4 Error Variables\nMathematical formulation: For UserDemand/FlowDemand: \\[E^p_v \\ge 0, \\quad \\overline{E}^p_v \\ge 0\\]\nCode implementation:\n# From add_user_demand!\nuser_demand_error = JuMP.@variable(\n    problem,\n    user_demand_error[\n        node_id = user_demand_ids_subnetwork,\n        demand_priority = demand_priorities_all,\n        objective_type = 1:2;  # 1 = absolute error, 2 = fairness error\n        has_demand_priority[node_id.idx, demand_priority_idx]\n    ] ≥ 0\n)\nKey points: - Triple-indexed: (node_id, demand_priority, objective_type) - objective_type = 1: absolute error \\(E^p_v\\) - objective_type = 2: fairness error \\(\\overline{E}^p_v\\) - Non-negative to represent error magnitude",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#constraints",
    "href": "dev/allocation.html#constraints",
    "title": "Allocation",
    "section": "3.2 Constraints",
    "text": "3.2 Constraints\n\n3.2.1 Flow Conservation\nMathematical formulation: For conservative nodes (pumps, outlets, resistances), inflow equals outflow: \\[Q_{\\text{in}} = Q_{\\text{out}}\\]\nCode implementation:\n# From add_flow_conservation!\nproblem[Symbol(constraint_name)] = JuMP.@constraint(\n    problem,\n    [node_id = node_ids],\n    flow[inflow_link[node_id.idx].link] == flow[outflow_link[node_id.idx].link],\n    base_name = \"flow_conservation_$node_name\"\n)\nKey points: - Simple equality constraint between two flow variables - Applied to Pump, Outlet, LinearResistance, ManningResistance, TabulatedRatingCurve - Ensures mass conservation through the node\n\n\n3.2.2 Volume Conservation (Basin Water Balance)\nMathematical formulation: \\[\\frac{dS}{dt} = \\sum_{k=1}^{N_l} Q_k + f_{\\text{pos}} - f_{\\text{neg}}\\]\nDiscretized with backward Euler: \\[\\frac{S^{n+1} - S^n}{\\Delta t} = \\sum_{k} Q_k^{n+1} + f^{n+1}_{\\text{pos}} - f^{n+1}_{\\text{neg}}\\]\nOr in terms of storage change \\(\\Delta S = S^{n+1} - S^n\\): \\[\\Delta S = \\Delta t \\left(\\sum_{k} Q_k^{n+1} + f^{n+1}_{\\text{pos}} - f^{n+1}_{\\text{neg}}\\right)\\]\nCode implementation:\n# From add_conservation!\nproblem[:volume_conservation] = JuMP.@constraint(\n    problem,\n    [node_id = basin_ids_subnetwork],\n    storage_change[node_id] ==\n        Δt_allocation / scaling.storage * (\n            sum(flow[link] for link in inflow_links; init = 0.0) * scaling.flow -\n            sum(\n                low_storage_factor[node_id] * flow[link]\n                for link in outflow_links;\n                init = 0.0\n            ) * scaling.flow +\n            f_pos - f_neg  # Forcing terms (precipitation, evaporation, etc.)\n        ),\n    base_name = \"volume_conservation\"\n)\nKey points: - The low_storage_factor multiplies outflows to prevent negative storage - Forcing terms (f_pos, f_neg) represent precipitation, evaporation, etc. - Careful scaling to maintain numerical stability - Updated each optimization with current forcing values\n\n\n3.2.3 UserDemand Allocated Sum\nMathematical formulation: The sum of allocated flows over all priorities equals the total inflow: \\[F_{(b_{\\text{upstream}}, v)} = \\sum_{p \\in P_v} F^p_v\\]\nCode implementation:\n# From add_user_demand!\nproblem[:user_demand_allocated_sum_constraint] = JuMP.@constraint(\n    problem,\n    [node_id = user_demand_ids_subnetwork],\n    flow[inflow_link[node_id.idx].link] ==\n        sum(\n            user_demand_allocated[node_id, demand_priority]\n            for (demand_priority_idx, demand_priority) in\n            enumerate(demand_priorities_all) if\n            has_demand_priority[node_id.idx, demand_priority_idx];\n            init = JuMP.AffExpr(0.0)\n        ),\n    base_name = \"user_demand_allocated_sum\"\n)\nKey points: - Ensures only demanded water enters UserDemand nodes - Sum is over priorities where the node has a demand - Links the flow variable to allocated flow variables\n\n\n3.2.4 Error Constraints\nMathematical formulation: For UserDemand/FlowDemand: \\[d_v^p \\cdot E_v^p \\ge d_v^p - F_v^p\\]\nCode implementation:\n# From add_user_demand!\nproblem[:user_demand_relative_error_constraint] = JuMP.@constraint(\n    problem,\n    [\n        node_id = user_demand_ids_subnetwork,\n        demand_priority = demand_priorities_all,\n        objective_type = 1:2;\n        has_demand_priority[node_id.idx, demand_priority_idx]\n    ],\n    d * user_demand_error[node_id, demand_priority, objective_type] ≥\n        d - user_demand_allocated[node_id, demand_priority],\n    base_name = \"user_demand_relative_error\"\n)\nKey points: - Multiplication by demand d makes this effectively an absolute error - The error variable is forced to be at least the unmet demand fraction - Updated before each optimization with current demands\nFor LevelDemand:\nMathematical formulation: \\[E^p_{b, \\text{lower}} \\ge s(h^p_{b, \\min}) - (s(h_b^\\text{init}) + \\Delta S_b)\\]\nCode implementation:\n# From add_level_demand!\nproblem[:storage_constraint_lower] = JuMP.@constraint(\n    problem,\n    [\n        node_id = basin_ids_subnetwork_with_level_demand,\n        demand_priority = demand_priorities_all;\n        has_demand_priority[node_id.idx, demand_priority_idx]\n    ],\n    storage_change[node_id] +\n        level_demand_error[node_id, demand_priority, 1] * current_area[node_id.idx] ≥\n        (minimum_storage - starting_storage) / scaling.storage,\n    base_name = \"storage_constraint_lower\"\n)\nKey points: - Error represents storage deficit below minimum level - Multiplication by area converts level error to storage error - Separate constraints for upper and lower bounds\n\n\n3.2.5 Return Flow Constraints\nMathematical formulation: For UserDemand with return factor \\(r_i(t)\\): \\[Q_{\\text{out}} = r_i \\cdot Q_{\\text{in}}\\]\nCode implementation:\n# From add_user_demand!\nproblem[:user_demand_return_flow] = JuMP.@constraint(\n    problem,\n    [node_id = user_demand_ids_subnetwork],\n    flow[outflow_link[node_id.idx].link] ==\n        return_factor * flow[inflow_link[node_id.idx].link],\n    base_name = \"user_demand_return_flow\"\n)\nKey points: - return_factor is a placeholder, updated before optimization - Links inflow and outflow of UserDemand node - Models consumptive use (when return factor &lt; 1)\n\n\n3.2.6 Linearized Connector Node Constraints\nMathematical formulation: For nodes like TabulatedRatingCurve: \\[Q^{n+1} \\approx Q^n + \\frac{\\partial Q}{\\partial h_a}(h_a^{n+1} - h_a^n) + \\frac{\\partial Q}{\\partial h_b}(h_b^{n+1} - h_b^n)\\]\nCode implementation:\n# From add_linearized_connector_node!\nproblem[Symbol(constraint_name)] = JuMP.@constraint(\n    problem,\n    [node_id = node_ids_subnetwork],\n    flow[inflow_link[node_id.idx].link] ==\n        q0 +  # Flow at linearization point\n        (upstream_is_basin ?\n            (∂q∂h_upstream / A_upstream) * storage_change[upstream_id] :\n            0.0) +\n        (downstream_is_basin ?\n            (∂q∂h_downstream / A_downstream) * storage_change[downstream_id] :\n            0.0),\n    base_name = constraint_name\n)\nKey points: - q0, ∂q∂h_upstream, ∂q∂h_downstream are placeholders - Derivatives divided by area when basin is involved (converts \\(\\partial Q/\\partial h\\) to \\(\\partial Q/\\partial S\\)) - Updated in set_simulation_data! before each optimization - Handles various combinations (basin-basin, basin-boundary, etc.)",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#objectives",
    "href": "dev/allocation.html#objectives",
    "title": "Allocation",
    "section": "3.3 Objectives",
    "text": "3.3 Objectives\nThe allocation optimization solves multiple objectives in sequence using lexicographic goal programming. Each objective is optimized, then the optimal value is constrained in subsequent objectives.\n\n3.3.1 Primary Objective: Minimize Absolute Error Sum\nMathematical formulation: For flow demands (UserDemand, FlowDemand) at priority \\(p\\): \\[\\min \\sum_{v,p} d_v^p \\cdot E_v^p\\]\nFor level demands at priority \\(p\\): \\[\\min \\sum_{b; p\\in P^\\min_b} E^p_{b, \\text{lower}} + \\sum_{b; p\\in P^\\max_b} E^p_{b, \\text{upper}}\\]\nCode implementation:\n# From add_demand_objectives!\n# For flow demands\nobjective_expression = JuMP.AffExpr(0.0)\nfor node_id in user_demand_ids_subnetwork\n    if has_demand_priority[node_id.idx, demand_priority_idx]\n        demand = get_demand(user_demand, node_id, demand_priority, t)\n        JuMP.add_to_expression!(\n            objective_expression,\n            demand * user_demand_error[node_id, demand_priority, 1]\n        )\n    end\nend\n\n# Store for later optimization\npush!(\n    objective_metadata,\n    ObjectiveMetadata(\n        demand_priority,\n        objective_expression,\n        # ... other metadata\n    )\n)\nKey points: - Error variables are weighted by demands (makes this absolute error minimization) - Separate objectives for each priority - Objectives are stored and optimized in order by optimize_multi_objective!\n\n\n3.3.2 Secondary Objective: Minimize Fairness Error\nMathematical formulation: After minimizing the total error, minimize deviations from the average allocation rate.\nFor flow demands: \\[\\min \\sum_{v,p} \\overline{E}_v^p\\]\nwhere \\(\\overline{E}_v^p \\ge E_v^p - G^p\\) and \\(G^p\\) is the global average allocation rate.\nCode implementation:\n# From add_demand_objectives!\n# Compute average error (constraint on average error variable)\naverage_flow_unit_error_constraint =\n    @constraint(\n        problem,\n        [demand_priority = demand_priorities_all; ...],\n        sum_demands * average_flow_unit_error[demand_priority] ==\n            sum(d * error[node_id, demand_priority, 1] for node_id, d in demands),\n        base_name = \"average_flow_unit_error\"\n    )\n\n# Fairness error: overline_E &gt;= E - G\n# (Implicitly defined through constraints)\n\n# Objective sums fairness errors\nobjective_expression_fairness = sum(\n    user_demand_error[node_id, demand_priority, 2]\n    for node_id in user_demand_ids_subnetwork if ...\n)\nKey points: - average_flow_unit_error represents \\(G^p\\) - Fairness errors (objective_type = 2) penalize being worse than average - Optimized after the primary objective is satisfied\n\n\n3.3.3 Route Priority Objective\nMathematical formulation: \\[\\min \\sum w_i \\cdot Q_i\\]\nwhere \\(w_i\\) is the route priority weight (cost) for node \\(i\\).\nCode implementation:\n# From add_route_priority_objective!\nobjective_expression = JuMP.AffExpr(0.0)\nfor link in flow_links\n    # Get the route priority weight for the source node\n    weight = route_priority_weight[link[1]]\n    if weight &gt; 0\n        JuMP.add_to_expression!(\n            objective_expression,\n            weight * flow[link]\n        )\n    end\nend\nKey points: - Optimized after all demand objectives are satisfied - Only affects routing, not how much is allocated - Higher weight = less preferred route (higher cost)\n\n\n3.3.4 Low Storage Factor Objective\nMathematical formulation: \\[\\max \\sum_{b \\in \\text{basins}} \\alpha_b\\]\nwhere \\(\\alpha_b\\) is the low storage factor for basin \\(b\\).\nCode implementation:\n# From add_low_storage_factor_objective!\nobjective_expression = sum(\n    low_storage_factor[node_id]\n    for node_id in basin_ids_subnetwork\n)\n\n# Note: Maximizing low_storage_factor is equivalent to minimizing its negative\npush!(\n    objective_metadata,\n    ObjectiveMetadata(\n        Int32(-1),  # Special priority for this objective\n        -objective_expression,  # Negative for maximization\n        # ...\n    )\n)\nKey points: - Maximizes the low storage factor to allow more outflow from basins - Optimized last to avoid infeasibility from emptying basins - Special priority (-1) ensures it runs after demand objectives",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#basin-updates",
    "href": "dev/allocation.html#basin-updates",
    "title": "Allocation",
    "section": "4.1 Basin Updates",
    "text": "4.1 Basin Updates\nfunction set_simulation_data!(\n    allocation_model::AllocationModel,\n    basin::Basin,\n    p::Parameters,\n    t::Float64,\n)::Bool\n    (; problem, node_ids_in_subnetwork, scaling) = allocation_model\n    (; basin_ids_subnetwork) = node_ids_in_subnetwork\n    storage_change = problem[:basin_storage_change]\n\n    for basin_id in basin_ids_subnetwork\n        basin_idx = basin_id.idx\n\n        # Get current state from physical layer\n        current_storage_basin = current_storage[basin_idx]\n        max_storage_basin = basin.storage_to_level[basin_idx].t[end]\n\n        # Update bounds on storage change variable\n        JuMP.set_lower_bound(\n            storage_change[basin_id],\n            -current_storage_basin / scaling.storage\n        )\n        JuMP.set_upper_bound(\n            storage_change[basin_id],\n            (max_storage_basin - current_storage_basin) / scaling.storage\n        )\n\n        # Update volume conservation constraint with current forcing\n        # (precipitation, evaporation, etc.)\n        # ...\n    end\n    return errors\nend\nKey concepts: - Variable bounds are updated each timestep based on current basin storage - Forcing terms (precipitation, evaporation) are computed and added to constraints - Errors are detected (e.g., storage outside valid range) and reported",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#connector-node-updates-linearization",
    "href": "dev/allocation.html#connector-node-updates-linearization",
    "title": "Allocation",
    "section": "4.2 Connector Node Updates (Linearization)",
    "text": "4.2 Connector Node Updates (Linearization)\nfunction linearize_connector_node!(\n    allocation_model::AllocationModel,\n    connector_node::AbstractParameterNode,\n    flow_constraint,\n    flow_function::Function,\n    p::Parameters,\n    t::Float64,\n)\n    (; scaling, Δt_allocation) = allocation_model\n\n    # Evaluate at the end of the allocation timestep (backward Euler)\n    t_after = t + Δt_allocation\n\n    for node_id in only(flow_constraint.axes)\n        # Get upstream and downstream IDs\n        upstream_id = connector_node.inflow_link[node_id.idx].link[1]\n        downstream_id = connector_node.outflow_link[node_id.idx].link[2]\n\n        # Get levels at linearization point\n        h_a = get_level(p, upstream_id, t)\n        h_b = get_level(p, downstream_id, t)\n\n        # Evaluate flow at linearization point\n        Q_n = flow_function(p, upstream_id, downstream_id, t_after)\n\n        # Compute partial derivatives\n        ∂Q∂h_a = compute_derivative(p, upstream_id, downstream_id, t_after, :upstream)\n        ∂Q∂h_b = compute_derivative(p, upstream_id, downstream_id, t_after, :downstream)\n\n        # Update constraint with linearization\n        constraint_ref = flow_constraint[node_id]\n\n        # Set constant term (Q_n - ∂Q/∂h_a * h_a - ∂Q/∂h_b * h_b)\n        JuMP.set_normalized_rhs(\n            constraint_ref,\n            (Q_n - ∂Q∂h_a * h_a - ∂Q∂h_b * h_b) / scaling.flow\n        )\n\n        # Set coefficients for basin storage variables if applicable\n        if upstream_id.type == NodeType.Basin\n            set_partial_derivative_wrt_level!(\n                allocation_model, upstream_id, ∂Q∂h_a, p, constraint_ref\n            )\n        end\n        if downstream_id.type == NodeType.Basin\n            set_partial_derivative_wrt_level!(\n                allocation_model, downstream_id, ∂Q∂h_b, p, constraint_ref\n            )\n        end\n    end\nend\nKey concepts: - Linearization is performed at the current physical state - Derivatives are computed using physical layer functions - Constraint coefficients are updated to match the Taylor expansion - Backward Euler: evaluate at end of timestep (\\(t + \\Delta t\\))",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#demand-updates",
    "href": "dev/allocation.html#demand-updates",
    "title": "Allocation",
    "section": "4.3 Demand Updates",
    "text": "4.3 Demand Updates\nfunction set_demands!(\n    allocation_model::AllocationModel,\n    node::Union{UserDemand, FlowDemand},\n    # ... other parameters\n)::Nothing\n    for (demand_priority_idx, demand_priority) in enumerate(demand_priorities_all)\n        for node_id in demand_node_ids_subnetwork\n            if !has_demand_priority[node_id.idx, demand_priority_idx]\n                continue\n            end\n\n            # Get current demand from physical layer\n            demand = get_demand(node, node_id, demand_priority, t)\n\n            # Update error constraint with current demand\n            error_constraint = node_relative_error_constraint[node_id, demand_priority, 1]\n            JuMP.set_normalized_coefficient(\n                error_constraint,\n                node_error[node_id, demand_priority, 1],\n                demand / scaling.flow\n            )\n\n            # Update upper bound on allocated variable\n            JuMP.set_upper_bound(\n                node_allocated[node_id, demand_priority],\n                demand / scaling.flow\n            )\n\n            # Similar updates for fairness error constraints...\n        end\n    end\n    return nothing\nend\nKey concepts: - Demands are time-varying and interpolated from input tables - Constraint coefficients are updated to reflect current demands - Upper bounds on allocation variables ensure allocated ≤ demanded",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#example-scaled-volume-conservation",
    "href": "dev/allocation.html#example-scaled-volume-conservation",
    "title": "Allocation",
    "section": "6.1 Example: Scaled Volume Conservation",
    "text": "6.1 Example: Scaled Volume Conservation\nUnscaled formulation: \\[\\Delta S \\text{ [m³]} = \\Delta t \\text{ [s]} \\cdot \\left( Q_{\\text{in}} - Q_{\\text{out}} \\text{ [m³/s]} \\right)\\]\nScaled formulation: \\[\\tilde{\\Delta S} \\cdot S_{\\text{scale}} = \\Delta t \\cdot \\left( \\tilde{Q}_{\\text{in}} \\cdot Q_{\\text{scale}} - \\tilde{Q}_{\\text{out}} \\cdot Q_{\\text{scale}} \\right)\\]\nwhere \\(\\tilde{\\Delta S} = \\Delta S / S_{\\text{scale}}\\) and \\(\\tilde{Q} = Q / Q_{\\text{scale}}\\).\nDividing through by \\(S_{\\text{scale}}\\): \\[\\tilde{\\Delta S} = \\frac{\\Delta t \\cdot Q_{\\text{scale}}}{S_{\\text{scale}}} \\left( \\tilde{Q}_{\\text{in}} - \\tilde{Q}_{\\text{out}} \\right)\\]\nIn the code:\nstorage_change[node_id] ==\n    Δt_allocation / scaling.storage * (\n        sum(flow[link] for link in inflow_links) * scaling.flow - ...\n    )",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#nodeid",
    "href": "dev/allocation.html#nodeid",
    "title": "Allocation",
    "section": "7.1 NodeID",
    "text": "7.1 NodeID\nNodes are identified by the NodeID struct:\nstruct NodeID\n    type::NodeType.T  # e.g., NodeType.Basin, NodeType.UserDemand\n    idx::Int32        # Index into the type-specific data arrays\n    value::Int32      # User-facing ID from input file\nend\nKey concepts: - idx is used to index into type-specific arrays (e.g., basin.storage[basin_id.idx]) - value is the ID from the input file (for error messages, output) - type distinguishes different node types",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#links",
    "href": "dev/allocation.html#links",
    "title": "Allocation",
    "section": "7.2 Links",
    "text": "7.2 Links\nLinks are represented as tuples of NodeIDs:\nlink::Tuple{NodeID, NodeID}  # (source, destination)\nKey concepts: - Used to index flow variables: problem[:flow][link] - Direction matters: (A, B) ≠ (B, A) - Stored in graph edge metadata",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#jump-sparse-arrays",
    "href": "dev/allocation.html#jump-sparse-arrays",
    "title": "Allocation",
    "section": "7.3 JuMP Sparse Arrays",
    "text": "7.3 JuMP Sparse Arrays\nJuMP uses SparseAxisArray for multi-dimensional variables:\n# Example: doubly-indexed variable\nuser_demand_allocated[node_id, demand_priority]\n\n# Example: triply-indexed variable\nuser_demand_error[node_id, demand_priority, objective_type]\nKey concepts: - Only creates variables for valid index combinations - Filtered by conditions (e.g., has_demand_priority[node_id.idx, demand_priority_idx]) - Efficient for sparse problems (not all nodes have all priorities)",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#allocationmodel-struct",
    "href": "dev/allocation.html#allocationmodel-struct",
    "title": "Allocation",
    "section": "7.4 AllocationModel Struct",
    "text": "7.4 AllocationModel Struct\nThe main data structure:\nstruct AllocationModel\n    subnetwork_id::Int32\n    problem::JuMP.Model  # The JuMP optimization problem\n    node_ids_in_subnetwork::NodeIDsInSubnetwork\n    scaling::ScalingFactors\n    Δt_allocation::Float64\n\n    # Cumulative tracking for output\n    cumulative_realized_volume::Dict{Tuple{NodeID, NodeID}, Float64}\n    cumulative_boundary_volume::Dict{Tuple{NodeID, NodeID}, Float64}\n\n    # Forcing volumes (precipitation, evaporation)\n    explicit_positive_forcing_volume::Dict{NodeID, Float64}\n    implicit_negative_forcing_volume::Dict{NodeID, Float64}\n\n    # Optimization objectives\n    objectives::AllocationObjectives\n\n    # Temporary constraints for lexicographic optimization\n    temporary_constraints::Vector{JuMP.ConstraintRef}\n\n    # For routing optimization\n    route_priority_expression::JuMP.AffExpr\nend",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#primary-network",
    "href": "dev/allocation.html#primary-network",
    "title": "Allocation",
    "section": "8.1 Primary Network",
    "text": "8.1 Primary Network\nThe primary network (subnetwork_id = 1) represents the main water system. It:\n\nContains its own demand nodes\nConnects to secondary networks via Pump or Outlet nodes\nTreats each secondary network as a single demand node",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#secondary-networks",
    "href": "dev/allocation.html#secondary-networks",
    "title": "Allocation",
    "section": "8.2 Secondary Networks",
    "text": "8.2 Secondary Networks\nSecondary networks (subnetwork_id &gt; 1):\n\nCan only connect to the primary network\nCannot connect to each other directly\nHave their own internal allocation optimization",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#the-two-stage-process",
    "href": "dev/allocation.html#the-two-stage-process",
    "title": "Allocation",
    "section": "8.3 The Two-Stage Process",
    "text": "8.3 The Two-Stage Process\n\n8.3.1 Stage 1: Demand Collection\nFor each secondary network:\n\nSet inflow from primary network to unlimited (temporarily)\nSolve allocation to determine total unmet demand\nThis demand becomes the secondary network’s “request” to the primary network\n\nfunction preprocess_demand_collection!(\n    allocation_model::AllocationModel,\n    p_independent::ParametersIndependent,\n)::Nothing\n    # Allow unlimited inflow from primary network\n    for link in primary_network_connections[subnetwork_id]\n        flow_var = flow[link]\n        JuMP.set_upper_bound(flow_var, MAX_ABS_FLOW / scaling.flow)\n        JuMP.set_lower_bound(flow_var, 0)\n    end\n\n    # Solve to find total demand...\nend\n\n\n8.3.2 Stage 2: Allocation\nIn primary network:\n\nSolve allocation considering:\n\nPrimary network’s own demands\nAggregated demands from secondary networks\n\nAllocated amounts to secondary networks determine their inflow limits\n\nIn each secondary network:\n\nSet inflow constraint to the allocated amount from primary network\nSolve allocation to distribute water to internal demands\n\nfunction allocate_flows_to_subnetwork(\n    allocation_models::Vector{AllocationModel},\n    primary_network_connections,\n)::Nothing\n    primary_network = get_primary_network(allocation_models)\n    primary_problem = primary_network.problem\n\n    for secondary_network in get_secondary_networks(allocation_models)\n        # Get allocated flow from primary network\n        for link in primary_network_connections[secondary_network.subnetwork_id]\n            allocated_flow = JuMP.value(primary_problem[:flow][link])\n\n            # Set as capacity for secondary network\n            secondary_problem = secondary_network.problem\n            JuMP.set_upper_bound(\n                secondary_problem[:flow][link],\n                allocated_flow\n            )\n        end\n    end\nend",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#parsing-results",
    "href": "dev/allocation.html#parsing-results",
    "title": "Allocation",
    "section": "10.1 Parsing Results",
    "text": "10.1 Parsing Results\nAfter optimization, results must be extracted and stored:\nfunction parse_allocations!(\n    integrator::DEIntegrator,\n    allocation_model::AllocationModel,\n)::Nothing\n    (; problem, subnetwork_id, scaling) = allocation_model\n\n    # Extract allocated amounts per demand node per priority\n    for node_id in user_demand_ids_subnetwork\n        for (demand_priority_idx, demand_priority) in enumerate(demand_priorities_all)\n            if !has_demand_priority[node_id.idx, demand_priority_idx]\n                continue\n            end\n\n            # Get allocated amount from optimization result\n            allocated = JuMP.value(user_demand_allocated[node_id, demand_priority])\n            allocated_unscaled = allocated * scaling.flow\n\n            # Store for output\n            record_demand[subnetwork_id][demand_priority][node_id] = (\n                demand = current_demand,\n                allocated = allocated_unscaled,\n                realized = 0.0  # To be filled in after physical layer runs\n            )\n        end\n    end\nend",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#applying-allocation-results",
    "href": "dev/allocation.html#applying-allocation-results",
    "title": "Allocation",
    "section": "10.2 Applying Allocation Results",
    "text": "10.2 Applying Allocation Results\nAllocated amounts must be communicated to the physical layer:\n\n10.2.1 UserDemand Nodes\n# In the physical layer, UserDemand nodes have a max_flow_rate that limits extraction\nfunction update_user_demand!(user_demand::UserDemand, allocation_result)\n    for node_id in user_demand.node_id\n        # Get allocated amount summed over all priorities\n        total_allocated = sum(\n            allocation_result[node_id][priority].allocated\n            for priority in priorities\n        )\n\n        # Set as maximum extraction rate\n        user_demand.max_flow_rate[node_id.idx] = total_allocated\n    end\nend\n\n\n10.2.2 Pump/Outlet Control\nWhen Pump or Outlet has control state Ribasim.allocation:\nfunction apply_control_from_allocation!(\n    node::Union{Pump, Outlet},\n    allocation_model::AllocationModel,\n    integrator::DEIntegrator,\n)::Nothing\n    (; problem, scaling) = allocation_model\n    flow = problem[:flow]\n\n    for node_id in controlled_node_ids\n        # Get optimized flow from allocation\n        link = (inflow_id(node_id), outflow_id(node_id))\n        optimized_flow = JuMP.value(flow[link]) * scaling.flow\n\n        # Set as target flow rate in physical layer\n        node.flow_rate[node_id.idx] = optimized_flow\n    end\nend",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#infeasibility-analysis",
    "href": "dev/allocation.html#infeasibility-analysis",
    "title": "Allocation",
    "section": "11.1 Infeasibility Analysis",
    "text": "11.1 Infeasibility Analysis\nfunction analyze_infeasibility(\n    allocation_model::AllocationModel,\n    t::Float64,\n    config::Config,\n)::JuMP.TerminationStatusCode\n    (; problem) = allocation_model\n\n    # Find Irreducible Inconsistent Subsystem (IIS)\n    data_infeasibility = MathOptAnalyzer.analyze(\n        MathOptAnalyzer.Infeasibility.Analyzer(),\n        problem;\n        optimizer = get_optimizer(),\n    )\n\n    # Extract conflicting constraints\n    violated_constraints = [...]\n\n    # Try relaxing constraints to identify issues\n    constraint_to_penalty = Dict(\n        constraint =&gt; (isempty(JuMP.name(constraint)) ? 1.0 : 0.5)\n        for constraint in violated_constraints\n    )\n    constraint_to_slack = JuMP.relax_with_penalty!(problem, constraint_to_penalty)\n    JuMP.optimize!(problem)\n\n    # Report which constraints are in conflict\n    for irreducible_infeasible_subset in data_infeasibility.iis\n        constraint_violations = [...]\n        @error \"Set of incompatible constraints found\" constraint_violations\n    end\n\n    return JuMP.INFEASIBLE\nend\nKey concepts: - IIS = minimal set of constraints that cannot be satisfied simultaneously - Constraint relaxation helps identify which constraints are problematic - Named constraints are more informative for debugging",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#common-infeasibility-causes",
    "href": "dev/allocation.html#common-infeasibility-causes",
    "title": "Allocation",
    "section": "11.2 Common Infeasibility Causes",
    "text": "11.2 Common Infeasibility Causes\n\nInsufficient water supply: Total demand exceeds total available water\nConflicting level demands: Min/max levels cannot be satisfied simultaneously\nCapacity constraints: Network capacity insufficient to meet demands\nStorage constraints: Basin storage limits prevent meeting level demands",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#problem-size",
    "href": "dev/allocation.html#problem-size",
    "title": "Allocation",
    "section": "12.1 Problem Size",
    "text": "12.1 Problem Size\n\nVariables: O(links + basins + demand_nodes × priorities)\nConstraints: O(links + basins + demand_nodes × priorities)\nObjectives: O(priorities)\n\nFor a network with 100 nodes, 200 links, 20 demand nodes, and 4 priorities: - ~300 variables - ~400 constraints - 4-8 objectives (depending on objectives configured)",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#solver-performance",
    "href": "dev/allocation.html#solver-performance",
    "title": "Allocation",
    "section": "12.2 Solver Performance",
    "text": "12.2 Solver Performance\nThe HiGHS solver is configured for allocation problems:\nfunction get_optimizer()\n    JuMP.optimizer_with_attributes(\n        HiGHS.Optimizer,\n        \"log_to_console\" =&gt; false,\n        \"time_limit\" =&gt; 60.0,\n        \"random_seed\" =&gt; 0,\n        \"small_matrix_value\" =&gt; 1e-12,  # Numerical threshold\n    )\nend\nTips for performance: - Use scaling to keep values O(1) - Minimize number of priorities (each adds objectives) - Warm start with physical layer flows - Simplify network topology where possible",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#allocation-timestep-selection",
    "href": "dev/allocation.html#allocation-timestep-selection",
    "title": "Allocation",
    "section": "12.3 Allocation Timestep Selection",
    "text": "12.3 Allocation Timestep Selection\nThe allocation timestep \\(\\Delta t_{\\text{allocation}}\\) must be chosen carefully:\n\nToo small: Frequent optimization overhead, linearization always valid\nToo large: Linearization may be inaccurate, less responsive to changes\nTypical range: 1 day to 1 week for water resources models",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#inspecting-the-problem",
    "href": "dev/allocation.html#inspecting-the-problem",
    "title": "Allocation",
    "section": "13.1 Inspecting the Problem",
    "text": "13.1 Inspecting the Problem\n# Write problem to file for manual inspection\nwrite_problem_to_file(problem, config)\n\n# Check variable values\nprintln(JuMP.value(flow[link]))\nprintln(JuMP.value(storage_change[basin_id]))\n\n# Check constraint values\nprintln(JuMP.normalized_rhs(constraint))\nprintln(JuMP.normalized_coefficient(constraint, variable))",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/allocation.html#common-issues",
    "href": "dev/allocation.html#common-issues",
    "title": "Allocation",
    "section": "13.2 Common Issues",
    "text": "13.2 Common Issues\n\n13.2.1 Variables at Bounds\nfunction get_bounds_hit(variable::JuMP.VariableRef)::Tuple{Bool, Bool}\n    hit_lower_bound = if JuMP.has_lower_bound(variable)\n        JuMP.value(variable) ≤ JuMP.lower_bound(variable)\n    else\n        false\n    end\n\n    hit_upper_bound = if JuMP.has_upper_bound(variable)\n        JuMP.value(variable) ≥ JuMP.upper_bound(variable)\n    else\n        false\n    end\n\n    return hit_lower_bound, hit_upper_bound\nend\nIf many variables are at bounds, the problem may be under-constrained or infeasible.\n\n\n13.2.2 Numerical Scaling Issues\nfunction analyze_scaling(\n    allocation_model::AllocationModel,\n    t::Float64,\n    config::Config,\n)::Nothing\n    data_numerical = MathOptAnalyzer.analyze(\n        MathOptAnalyzer.Numerical.Analyzer(),\n        problem;\n        threshold_small = 1e-12,\n        threshold_large = 1e6,\n    )\n\n    # Check for poorly scaled coefficients\n    for data in data_numerical.matrix_small\n        @error \"Too small coefficient\" data.coefficient\n    end\n\n    for data in data_numerical.matrix_large\n        @error \"Too large coefficient\" data.coefficient\n    end\nend",
    "crumbs": [
      "Contributing",
      "Allocation"
    ]
  },
  {
    "objectID": "dev/index.html",
    "href": "dev/index.html",
    "title": "Contributing",
    "section": "",
    "text": "Ribasim welcomes contributions.\nThere is developer documentation for the Julia core, the Basic Model Interface (BMI), Python tooling, and the QGIS plugin. A guide on how to add a new node type to both is written in adding node types. Release process describes the steps to follow when creating a new Ribasim release.",
    "crumbs": [
      "Contributing"
    ]
  },
  {
    "objectID": "dev/index.html#option-1-local-development",
    "href": "dev/index.html#option-1-local-development",
    "title": "Contributing",
    "section": "1.1 Option 1: local development",
    "text": "1.1 Option 1: local development\nIf you prefer local development, clone Ribasim as described in Clone Ribasim.\nThen, set up Pixi as described on pixi.sh.\nWe require at least Pixi version v0.48.1, but generally recommend the latest release. Check the version with pixi --version, update with pixi self-update.\nWindows users should enable Developer Mode, because the install task creates symlinks for the QGIS plugin.\nThen set up the environment by running the following command. It will take a while. You can interrupt the task if you don’t want to precompile the Julia dependencies at this moment, because that is the last task. Check out the pixi.toml file to see the tasks that are part of this, you can also run them individually.\npixi run install\nThe install task automatically installs all required Python and Julia packages for development. Our Pixi environment also provides Juliaup, QGIS and the Rust compiler. These will not conflict with any pre-installed applications, as long as you have the pixi environment enabled. You can do this in a terminal by calling pixi shell, or starting programs with pixi run julia, or pixi run qgis. The first time you open the Ribasim repo in Visual Studio Code you need to tell it where it can find the Pixi environment. Open the command box with Ctrl+Shift+PCtrl+Shift+P (Cmd+Shift+PCmd+Shift+P on macOS) and run Python: Select Interpreter. Select ('default': Pixi) in the /.pixi folder. Unless the setting python.terminal.activateEnvironment is disabled, it will already activate the environment in your terminal.\nIf you encounter issues related to Pixi dependencies, it might help to clean your Pixi environment with pixi clean, followed by pixi run install.",
    "crumbs": [
      "Contributing"
    ]
  },
  {
    "objectID": "dev/index.html#option-2-use-a-devcontainer",
    "href": "dev/index.html#option-2-use-a-devcontainer",
    "title": "Contributing",
    "section": "1.2 Option 2: use a devcontainer",
    "text": "1.2 Option 2: use a devcontainer\nIf you prefer a containerized development environment, you can use the provided devcontainer configuration. This option is particularly useful if you want to avoid installing dependencies directly on your host machine.\n\nInstall Visual Studio Code and the Remote - Containers extension.\nInstall Docker Desktop and ensure it’s running.\nPress Ctrl+Shift+PCtrl+Shift+P (or Cmd+Shift+PCmd+Shift+P on macOS) and select Dev Containers: Clone Repository in Container Volume.\nPaste https://github.com/Deltares/Ribasim.git in the prompt and continue\n\nThis will pull the repo, build the devcontainer image and start a new container with all the necessary dependencies. The build and install will take a few minutes to complete.",
    "crumbs": [
      "Contributing"
    ]
  },
  {
    "objectID": "dev/index.html#option-3-github-codespace",
    "href": "dev/index.html#option-3-github-codespace",
    "title": "Contributing",
    "section": "1.3 Option 3: github codespace",
    "text": "1.3 Option 3: github codespace\nIf you prefer a cloud-based development environment, you can use GitHub Codespaces. This option allows you to quickly set up a development environment without needing to configure your local machine.\n\nGo to the Ribasim GitHub repository.\nClick on the green “Code” button and select “Open with Codespaces”.\nFollow the prompts to create a new codespace.\n\nThis creates a cloud-based development environment with all necessary dependencies pre-installed. The environment runs on GitHub’s servers and can be accessed through your browser via the Ribasim repo.",
    "crumbs": [
      "Contributing"
    ]
  },
  {
    "objectID": "dev/index.html#clone-ribasim",
    "href": "dev/index.html#clone-ribasim",
    "title": "Contributing",
    "section": "1.4 Clone Ribasim",
    "text": "1.4 Clone Ribasim\nIn order to have the Ribasim repository locally available, you can clone it with Git. Git can be installed from git-scm.com. Once installed, run the following command at a directory of your choice:\nIn order to have the Ribasim repository locally available, run the following command at a directory of your choice:\ngit clone https://github.com/Deltares/Ribasim.git\nTo continue with the following steps, make the root of the repository your working directory by running\ncd Ribasim",
    "crumbs": [
      "Contributing"
    ]
  },
  {
    "objectID": "dev/python.html",
    "href": "dev/python.html",
    "title": "Python tooling development",
    "section": "",
    "text": "In order to run tests on Ribasim Python execute\npixi run test-ribasim-python\n\n\n\nMake sure to run Clear All Outputs on the notebook before committing.\n\n\n\nBefore running the Julia tests or building binaries, example model input needs to created. This is done by running the following:\npixi run generate-testmodels\nThis places example model input files under ./generated_testmodels/. If the example models change, re-run this script.\n\n\n\nInstall the Python, ruff and autoDocstring extensions.\n\n\n\nTo run our linting suite locally, execute:\npixi run lint",
    "crumbs": [
      "Contributing",
      "Python tooling development"
    ]
  },
  {
    "objectID": "dev/python.html#sec-test",
    "href": "dev/python.html#sec-test",
    "title": "Python tooling development",
    "section": "",
    "text": "In order to run tests on Ribasim Python execute\npixi run test-ribasim-python",
    "crumbs": [
      "Contributing",
      "Python tooling development"
    ]
  },
  {
    "objectID": "dev/python.html#updating-example-notebooks",
    "href": "dev/python.html#updating-example-notebooks",
    "title": "Python tooling development",
    "section": "",
    "text": "Make sure to run Clear All Outputs on the notebook before committing.",
    "crumbs": [
      "Contributing",
      "Python tooling development"
    ]
  },
  {
    "objectID": "dev/python.html#prepare-model-input",
    "href": "dev/python.html#prepare-model-input",
    "title": "Python tooling development",
    "section": "",
    "text": "Before running the Julia tests or building binaries, example model input needs to created. This is done by running the following:\npixi run generate-testmodels\nThis places example model input files under ./generated_testmodels/. If the example models change, re-run this script.",
    "crumbs": [
      "Contributing",
      "Python tooling development"
    ]
  },
  {
    "objectID": "dev/python.html#sec-vscode",
    "href": "dev/python.html#sec-vscode",
    "title": "Python tooling development",
    "section": "",
    "text": "Install the Python, ruff and autoDocstring extensions.",
    "crumbs": [
      "Contributing",
      "Python tooling development"
    ]
  },
  {
    "objectID": "dev/python.html#linting",
    "href": "dev/python.html#linting",
    "title": "Python tooling development",
    "section": "",
    "text": "To run our linting suite locally, execute:\npixi run lint",
    "crumbs": [
      "Contributing",
      "Python tooling development"
    ]
  },
  {
    "objectID": "dev/core.html",
    "href": "dev/core.html",
    "title": "Julia core development",
    "section": "",
    "text": "The computational core is one of the components of Ribasim as illustrated in the component overview.\nThe computational process can be divided into three phases:\n\nModel initialization\nRunning the simulation loop\nWriting the output files\n\nA more detailed sequence diagram of the simulation loop is available at the core home page.",
    "crumbs": [
      "Contributing",
      "Julia core development"
    ]
  },
  {
    "objectID": "dev/core.html#set-the-number-of-threads-julia-will-use",
    "href": "dev/core.html#set-the-number-of-threads-julia-will-use",
    "title": "Julia core development",
    "section": "2.1 Set the number of threads Julia will use",
    "text": "2.1 Set the number of threads Julia will use\nSet the JULIA_NUM_THREADS variable in your environment to auto (linux, macos) or the number of physical cores of your machine (windows). Multiple threads are used to speed up individual models, as well as running testmodels in parallel.",
    "crumbs": [
      "Contributing",
      "Julia core development"
    ]
  },
  {
    "objectID": "dev/core.html#install-optional-julia-libraries",
    "href": "dev/core.html#install-optional-julia-libraries",
    "title": "Julia core development",
    "section": "2.2 Install optional Julia libraries",
    "text": "2.2 Install optional Julia libraries\nStart the Julia REPL by executing pixi run julia in your terminal. Within the REPL type ] to enter the Pkg REPL. For more information on how to use Pkg, see the Getting Started page in its documentation. There you can add Revise to your global environment.\npkg&gt; add Revise",
    "crumbs": [
      "Contributing",
      "Julia core development"
    ]
  },
  {
    "objectID": "dev/core.html#setup-revise.jl",
    "href": "dev/core.html#setup-revise.jl",
    "title": "Julia core development",
    "section": "2.3 Setup Revise.jl",
    "text": "2.3 Setup Revise.jl\nRevise.jl is a library that allows you to modify code and use the changes without restarting Julia. You can let it start automatically by following these instructions.",
    "crumbs": [
      "Contributing",
      "Julia core development"
    ]
  },
  {
    "objectID": "dev/core.html#install-visual-studio-code-optional",
    "href": "dev/core.html#install-visual-studio-code-optional",
    "title": "Julia core development",
    "section": "2.4 Install Visual Studio Code (optional)",
    "text": "2.4 Install Visual Studio Code (optional)\nThere is a section on editors and IDEs for Julia on https://julialang.org/, scroll down to see it. We use and recommend Microsoft’s free editor Visual Studio Code. When combined with the Julia extension it provides a powerful and interactive development experience.",
    "crumbs": [
      "Contributing",
      "Julia core development"
    ]
  },
  {
    "objectID": "dev/core.html#sec-test",
    "href": "dev/core.html#sec-test",
    "title": "Julia core development",
    "section": "3.1 Running tests",
    "text": "3.1 Running tests\nYou will want to run the testsuite on a regular basis to check if your changes had unexpected side effects. It is also a good way to find out if your development environment is set up correctly.\nBefore the tests can run, you need to prepare model input.\nWith the root of the repository as your working directory you can start the REPL with activated root environment by running the following:\njulia --project\nWhile not technically required, it is advised to import Ribasim first to catch installation issues early on.\njulia&gt; using Ribasim\nThen open the Pkg REPL by typing ] and execute:\npkg&gt; test Ribasim\nIn order to debug tests, you can run individual test items from Visual Studio Code. Click the green play icon in front of a test item, as shown in the image below. The first run will be slow.",
    "crumbs": [
      "Contributing",
      "Julia core development"
    ]
  },
  {
    "objectID": "dev/core.html#render-documentation",
    "href": "dev/core.html#render-documentation",
    "title": "Julia core development",
    "section": "3.2 Render documentation",
    "text": "3.2 Render documentation\nExample models are created and simulated as part of the rendering of the documentation.\nIn order to preview documentation you can run the following command from the docs/ folder. Afterwards, a browser tab will open with the rendered documentation, updating it as you make changes.\npixi run quarto-preview\nThe documentation also includes Jupyter notebooks. Note that they are stored in the repository without any output, and this should stay this way to keep the repository small. The documentation rendering process adds the output by running the notebooks.\n\n\n\n\n\n\nTip\n\n\n\nThe Jupyter VS Code extension allows you to run Jupyter notebooks directly in VS Code.",
    "crumbs": [
      "Contributing",
      "Julia core development"
    ]
  },
  {
    "objectID": "dev/core.html#run-ribasim-simulations",
    "href": "dev/core.html#run-ribasim-simulations",
    "title": "Julia core development",
    "section": "3.3 Run Ribasim simulations",
    "text": "3.3 Run Ribasim simulations\nAssuming your working directory is the root of the repository, you can activate this project by entering the Pkg mode of the REPL with ] and execute:\npkg&gt; activate .\npkg&gt; instantiate\nPress backspace to go back to the Julia REPL. There you can run a model with:\njulia&gt; Ribasim.run(\"path/to/model/ribasim.toml\")\n\n\n\n\n\n\nTip\n\n\n\nThe Julia VS Code extension allows you to execute code cells in REPL. This is a very convenient way of executing only parts of your source file.",
    "crumbs": [
      "Contributing",
      "Julia core development"
    ]
  },
  {
    "objectID": "dev/core.html#build-ribasim",
    "href": "dev/core.html#build-ribasim",
    "title": "Julia core development",
    "section": "3.4 Build Ribasim",
    "text": "3.4 Build Ribasim\nThe Ribasim core can be built into an executable with a command line interface (CLI) and a shared library, libribasim. These products will run without a Julia installation. To create both these products at once, run:\npixi run build\nTo verify that the build was successful, you can run both these commands.\npixi run test-ribasim-api\npixi run test-ribasim-cli\nDuring development these steps are normally done on TeamCity, though in some cases it can be more convenient to build locally.",
    "crumbs": [
      "Contributing",
      "Julia core development"
    ]
  },
  {
    "objectID": "dev/qgis.html",
    "href": "dev/qgis.html",
    "title": "QGIS plugin development",
    "section": "",
    "text": "1 Set up the developer environment\nAfter you have installed the environment as described here you must still activate the QGIS plugins.\n\n\n\n\n\n\nNote\n\n\n\nNote that on macOS you currently need to manually install and point to a QGIS executable in your path. If you use pixi that could be as simple as: pixi global install --environment qgis qgis pandas.\n\n\nThe simplest way to do this is by running pixi run install-qgis-plugins. It grabs the latest version of the iMOD QGIS plugin and it makes a symlink to the ribasim_qgis folder so that QGIS can find it. It also installs plugins that make it possible to reload and debug your plugin while QGIS is open.\n\n\n\n\n\n\nNote\n\n\n\nOn Windows you need to have Developer mode enabled. Otherwise you will not have enough access rights to create symlinks. For more info, see this Windows blog.\nWe wanted to implement this via pip install --editable, but QGIS doesn’t find the metadata.txt and therefore cannot load the plugin on startup.\n\n\n\n\n2 Running QGIS\nIn order to run QGIS with the plugins, simply call pixi run qgis. You will find the Ribasim and iMOD plugins in the tool bars.\n\n\n\n\n\n\nNote\n\n\n\nOn Windows, running QGIS from the start menu will disable Python, and thus the plugins. QGIS needs some more paths during the startup and the Pixi environment provides those.\n\n\n\n\n3 Running tests\nTo run the QGIS plugin tests in the application environment of QGIS, it is best to make use of the Docker environment provided in this repository. Make sure that docker is installed and available in your path.\nThen simply call pixi run test-ribasim-qgis.\n\n\n4 Debugging\nAfter installing the plugins via pixi run install-qgis-plugins. Extra debugging tools are also installed in QGIS that is installed within your pixi environment.\nAfter you have started pixi run qgis, you can make alterations to the Python code and use the Plugin Reloader to reload the plugin without restarting QGIS. The shortcut in QGIS is CTRL+F5.\nIt is also possible to connect the debugger of Visual Studio Code. For this the debugvs plugin is installed in QGIS. In QGIS press the button to Enable Debug for Visual Studio. Then go to Visual Studio Code and start the launch task Ribasim QGIS: Attach to QGIS. Now you can place breakpoints.\n\n\n\n\n\n\nNote\n\n\n\nWe are currently using debugvs 0.7 with ptvsd as service, since there is an open issue that breaks debugvs 0.8 with debugpy.",
    "crumbs": [
      "Contributing",
      "QGIS",
      "QGIS plugin development"
    ]
  },
  {
    "objectID": "dev/ci.html",
    "href": "dev/ci.html",
    "title": "Continuous integration",
    "section": "",
    "text": "Continuous integration (CI) is about commits being merged frequently, resulting in new features being released frequently. When proposing new changes to the code base a pull request is opened. When a new commit in that pull request, a series of tests will be done to make sure that this commit is error-free and robust in different environments. This process drive each new development through building, testing, quality checking.\ngraph LR\n    A[New development]--&gt;B[Continuous integration]\n    B--&gt;C[Merge]\nThis page contains an extensive explanation on how the Ribasim continuous integration works.",
    "crumbs": [
      "Contributing",
      "Continuous integration"
    ]
  },
  {
    "objectID": "dev/ci.html#conditions-of-using-teamcity",
    "href": "dev/ci.html#conditions-of-using-teamcity",
    "title": "Continuous integration",
    "section": "2.1 Conditions of using TeamCity",
    "text": "2.1 Conditions of using TeamCity\nTeamCity only runs workflows with the following conditions:\n\nWhen the workflow would take too long to run on GitHub Action\nWhen the release depends on the artifacts of the workflow.\nWhen other TeamCity projects depend on artifacts of Ribasim (e.g. iMOD coupler)",
    "crumbs": [
      "Contributing",
      "Continuous integration"
    ]
  },
  {
    "objectID": "dev/ci.html#release-process",
    "href": "dev/ci.html#release-process",
    "title": "Continuous integration",
    "section": "2.2 Release process",
    "text": "2.2 Release process\nIn the release, we include the generated testmodels, Ribasim CLI on Windows and Linux, Ribasim QGIS, and the source code.\nWe have the following pipeline to generate artifects for releasing:\n\nGenerate Testmodels: produces generated_testmodels artifact which is part of the release.\nMake GitHub Release: uses artifacts and makes the release. TeamCity constantly monitors the GitHub repository. When a tag starts with v20 is added, it triggers the release process.\nBuild Ribasim: builds library and executable of Ribasim on Linux and Windows. The artifacts are tested in Test Ribasim Binaries and used by iMOD Coupler.\nTest Ribasim Binaries: tests libribasim artifact and ribasim_cli artifact on Linux and Windows\n\n\n\n\n\n\n\nNote\n\n\n\nMake GitHub Release does not publish artifacts of “Test Ribasim Binaries”. It only publishes artifacts of “Build Ribasim” if the beforementioned tests pass.\n\n\n\n\n\n\n\ngraph LR\n    A[Make GitHub Release]--&gt;B(Release)\n    F[Generate Testmodels]--&gt;A\n    G[Make QGIS plugin]--&gt;A\n    H[Build Ribasim]---D[Test Ribasim Binaries]\n    D--&gt;A",
    "crumbs": [
      "Contributing",
      "Continuous integration"
    ]
  },
  {
    "objectID": "getting-started/examples.html",
    "href": "getting-started/examples.html",
    "title": "Examples",
    "section": "",
    "text": "from ribasim import run_ribasim",
    "crumbs": [
      "Getting started",
      "Examples"
    ]
  },
  {
    "objectID": "getting-started/examples.html#running-a-model",
    "href": "getting-started/examples.html#running-a-model",
    "title": "Examples",
    "section": "1.1 Running a model",
    "text": "1.1 Running a model\nNow run the model:\n\nrun_ribasim(toml_path)\n\n┌ Info: Starting a Ribasim simulation at 2026-01-23T16:32:08.913.\n│   toml_path = \"data/basic/ribasim.toml\"\n│   cli.ribasim_version = \"2026.1.0-rc1\"\n│   starttime = 2020-01-01T00:00:00\n│   endtime = 2021-01-01T00:00:00\n└   threads = 1\nSimulating   0%|                                        |  ETA: N/A\nSimulating   2%|▉                                       |  ETA: 0:39:52\nSimulating   4%|█▌                                      |  ETA: 0:20:55\nSimulating   6%|██▍                                     |  ETA: 0:13:33\nSimulating   8%|███▍                                    |  ETA: 0:09:00\nSimulating  11%|████▌                                   |  ETA: 0:06:36\nSimulating  14%|█████▋                                  |  ETA: 0:05:02\nSimulating  18%|███████                                 |  ETA: 0:03:55\nSimulating  21%|████████▌                               |  ETA: 0:03:04\nSimulating  25%|██████████▏                             |  ETA: 0:02:27\nSimulating  30%|████████████                            |  ETA: 0:01:56\nSimulating  36%|██████████████▌                         |  ETA: 0:01:28\nSimulating  47%|██████████████████▊                     |  ETA: 0:00:57\nSimulating  53%|█████████████████████▎                  |  ETA: 0:00:44\nSimulating  64%|█████████████████████████▋              |  ETA: 0:00:28\nSimulating  77%|██████████████████████████████▋         |  ETA: 0:00:15\nSimulating  92%|████████████████████████████████████▊   |  ETA: 0:00:04\nSimulating 100%|████████████████████████████████████████| Time: 0:00:50\n[ Info: Computation time: 24 seconds, 348 milliseconds\n[ Info: The model finished successfully at 2026-01-23T16:34:49.458.\n\n\nYou can also open a terminal and run it from there. For example, to run the basic model, input:\nribasim basic/ribasim.toml\nAfter running the model, read back the results:\n\ndf_basin = pd.read_feather(datadir / \"basic/results/basin.arrow\")\ndf_basin_wide = df_basin.pivot_table(\n    index=\"time\", columns=\"node_id\", values=[\"storage\", \"level\"]\n)\nax = df_basin_wide[\"level\"].plot()\nax.set_ylabel(\"level [m]\");\n\n\n\n\n\n\n\n\n\ndf_flow = pd.read_feather(datadir / \"basic/results/flow.arrow\")\ndf_flow[\"link\"] = list(zip(df_flow.from_node_id, df_flow.to_node_id))\ndf_flow[\"flow_m3d\"] = df_flow.flow_rate * 86400\nax = df_flow.pivot_table(index=\"time\", columns=\"link\", values=\"flow_m3d\").plot()\nax.legend(bbox_to_anchor=(1.3, 1), title=\"Link\")\nax.set_ylabel(\"flow [m³day⁻¹]\");",
    "crumbs": [
      "Getting started",
      "Examples"
    ]
  },
  {
    "objectID": "getting-started/tutorial/irrigation-demand.html",
    "href": "getting-started/tutorial/irrigation-demand.html",
    "title": "Irrigation demand",
    "section": "",
    "text": "from ribasim import run_ribasim\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport plotly.express as px\nfrom ribasim import Model, Node\nfrom ribasim.nodes import (\n    basin,\n    flow_boundary,\n    tabulated_rating_curve,\n    user_demand,\n)\nfrom shapely.geometry import Point\nbase_dir = Path(\"crystal-basin\")\n\nstarttime = \"2022-01-01\"\nendtime = \"2023-01-01\"\nmodel = Model(\n    starttime=starttime,\n    endtime=endtime,\n    crs=\"EPSG:4326\",\n)\nThese nodes are identical to the previous tutorial:\n# FlowBoundary\ndata = pd.DataFrame({\n    \"time\": pd.date_range(start=\"2022-01-01\", end=\"2023-01-01\", freq=\"MS\"),\n    \"main\": [74.7, 57.9, 63.2, 183.9, 91.8, 47.5, 32.6, 27.6, 26.5, 25.1, 39.3, 37.8, 57.9],\n    \"minor\": [16.3, 3.8, 3.0, 37.6, 18.2, 11.1, 12.9, 12.2, 11.2, 10.8, 15.1, 14.3, 11.8]\n})  # fmt: skip\ndata[\"total\"] = data[\"minor\"] + data[\"main\"]\nmain = model.flow_boundary.add(\n    Node(1, Point(0.0, 0.0), name=\"main\"),\n    [\n        flow_boundary.Time(\n            time=data.time,\n            flow_rate=data.main,\n        )\n    ],\n)\nminor = model.flow_boundary.add(\n    Node(2, Point(-3.0, 0.0), name=\"minor\"),\n    [\n        flow_boundary.Time(\n            time=data.time,\n            flow_rate=data.minor,\n        )\n    ],\n)\n\n# Basin\nconfluence = model.basin.add(\n    Node(3, Point(-1.5, -1), name=\"confluence\"),\n    [\n        basin.Profile(area=[672000, 5600000], level=[0, 6]),\n        basin.State(level=[4]),\n        basin.Time(time=[starttime, endtime]),\n    ],\n)\n\n# TabulatedRatingCurve\nweir = model.tabulated_rating_curve.add(\n    Node(4, Point(-1.5, -1.5), name=\"weir\"),\n    [\n        tabulated_rating_curve.Static(\n            level=[0.0, 2, 5],\n            flow_rate=[0.0, 50, 200],\n        )\n    ],\n)\n\n# Terminal\nsea = model.terminal.add(Node(5, Point(-1.5, -3.0), name=\"sea\"))",
    "crumbs": [
      "Getting started",
      "Tutorials",
      "Irrigation demand"
    ]
  },
  {
    "objectID": "getting-started/tutorial/irrigation-demand.html#irrigation-demand",
    "href": "getting-started/tutorial/irrigation-demand.html#irrigation-demand",
    "title": "Irrigation demand",
    "section": "1 Irrigation demand",
    "text": "1 Irrigation demand\nLet us modify the environment to include agricultural activities within the basin, which necessitate irrigation. Water is diverted from the main river through an irrigation canal, with a portion of it eventually returning to the main river (see Figure 1).\n\n\n\n\n\n\nFigure 1: Crystal basin with irrigation\n\n\n\nFor this schematization update, we need to incorporate three additional nodes:\n\nBasin: Represents a cross-sectional point where water is diverted.\nUserDemand: Represents the irrigation demand.\nTabulatedRatingCurve: Defines the remaining water flow from the main river at the diversion point.\n\n\n1.1 Add a second Basin node\nThis Basin will portray as the point in the river where the diversion takes place, getting the name diversion. Its profile area at this intersection is slightly smaller than at the confluence.\n\ndiversion_basin = model.basin.add(\n    Node(6, Point(-0.75, -0.5), name=\"diversion_basin\"),\n    [\n        basin.Profile(area=[500000, 5000000], level=[0, 6]),\n        basin.State(level=[3]),\n        basin.Time(time=[starttime, endtime]),\n    ],\n)\n\n\n\n1.2 Add the irrigation demand\nAn irrigation district needs to apply irrigation to its field starting from April to September. The irrigated area is \\(&gt; 17000 \\text{ ha}\\) and requires around \\(5 \\text{ mm/day}\\). In this case the irrigation district diverts from the main river an average flow rate of \\(10 \\text{ m}^3/\\text{s}\\) and \\(12 \\text{ m}^3/\\text{s}\\) during spring and summer, respectively. Start of irrigation takes place on the 1st of April until the end of September. The water intake is through a canal (demand).\nFor now, let’s assume the return flow remains \\(0.0\\) (return_factor). Meaning all the supplied water to fulfill the demand is consumed and does not return back to the river. The user demand node interpolates the demand values. Thus the following code needs to be implemented:\n\nirrigation = model.user_demand.add(\n    Node(7, Point(-1.5, 0.5), name=\"irrigation\"),\n    [\n        user_demand.Time(\n            demand=[0.0, 0.0, 10, 12, 12, 0.0],\n            return_factor=0,\n            min_level=0,\n            demand_priority=1,\n            time=[\n                starttime,\n                \"2022-03-31\",\n                \"2022-04-01\",\n                \"2022-07-01\",\n                \"2022-09-30\",\n                \"2022-10-01\",\n            ],\n        )\n    ],\n)\n\n\n\n1.3 Add a TabulatedRatingCurve\nThe second TabulatedRatingCurve node will simulate the rest of the water that is left after diverting a part from the main river to the irrigation disctrict. The rest of the water will flow naturally towards the confluence:\n\ndiversion_weir = model.tabulated_rating_curve.add(\n    Node(8, Point(-1.125, -0.75), name=\"diversion_weir\"),\n    [\n        tabulated_rating_curve.Static(\n            level=[0.0, 1.5, 5],\n            flow_rate=[0.0, 45, 200],\n        )\n    ],\n)\n\n\n\n1.4 Add links\n\nmodel.link.add(main, diversion_basin, name=\"main\")\nmodel.link.add(minor, confluence, name=\"minor\")\nmodel.link.add(diversion_basin, irrigation, name=\"irrigation\")\nmodel.link.add(irrigation, confluence)\nmodel.link.add(diversion_basin, diversion_weir, name=\"not diverted\")\nmodel.link.add(diversion_weir, confluence)\nmodel.link.add(confluence, weir)\nmodel.link.add(weir, sea, name=\"sea\")\n\n\ntoml_path = base_dir / \"Crystal-2/ribasim.toml\"\nmodel.write(toml_path)\n\nPosixPath('crystal-basin/Crystal-2/ribasim.toml')\n\n\n\n\n1.5 Plot model and run\nPlot the schematization and run the model. This time the new outputs should be written in a new folder called Crystal-2:\n\nmodel.plot();\n\n\n\n\n\n\n\n\n\nrun_ribasim(toml_path)\n\n┌ Info: Starting a Ribasim simulation at 2026-01-23T16:39:53.120.\n│   toml_path = \"crystal-basin/Crystal-2/ribasim.toml\"\n│   cli.ribasim_version = \"2026.1.0-rc1\"\n│   starttime = 2022-01-01T00:00:00\n│   endtime = 2023-01-01T00:00:00\n└   threads = 1\nSimulating   0%|                                        |  ETA: N/A\nSimulating   0%|                                        |  ETA: 23:23:06\nSimulating   2%|▊                                       |  ETA: 0:47:15\nSimulating   9%|███▍                                    |  ETA: 0:08:55\nSimulating  12%|████▋                                   |  ETA: 0:06:19\nSimulating  17%|██████▋                                 |  ETA: 0:04:11\nSimulating  24%|█████████▊                              |  ETA: 0:02:33\nSimulating  25%|█████████▉                              |  ETA: 0:02:32\nSimulating  25%|█████████▉                              |  ETA: 0:02:32\nSimulating  25%|█████████▉                              |  ETA: 0:02:32\nSimulating  25%|█████████▉                              |  ETA: 0:02:32\nSimulating  25%|██████████                              |  ETA: 0:02:30\nSimulating  27%|███████████                             |  ETA: 0:02:12\nSimulating  33%|█████████████▏                          |  ETA: 0:01:42\nSimulating  35%|██████████████▏                         |  ETA: 0:01:31\nSimulating  41%|████████████████▌                       |  ETA: 0:01:11\nSimulating  44%|█████████████████▊                      |  ETA: 0:01:03\nSimulating  50%|███████████████████▉                    |  ETA: 0:00:51\nSimulating  50%|███████████████████▉                    |  ETA: 0:00:51\nSimulating  51%|████████████████████▌                   |  ETA: 0:00:48\nSimulating  58%|███████████████████████▎                |  ETA: 0:00:36\nSimulating  62%|████████████████████████▉               |  ETA: 0:00:31\nSimulating  69%|███████████████████████████▌            |  ETA: 0:00:23\nSimulating  75%|█████████████████████████████▉          |  ETA: 0:00:17\nSimulating  75%|█████████████████████████████▉          |  ETA: 0:00:17\nSimulating  75%|██████████████████████████████▏         |  ETA: 0:00:16\nSimulating  83%|█████████████████████████████████▍      |  ETA: 0:00:10\nSimulating  85%|█████████████████████████████████▉      |  ETA: 0:00:09\nSimulating  92%|████████████████████████████████████▋   |  ETA: 0:00:05\nSimulating  97%|██████████████████████████████████████▉ |  ETA: 0:00:01\nSimulating 100%|████████████████████████████████████████| Time: 0:00:49\n[ Info: Computation time: 24 seconds, 235 milliseconds\n[ Info: The model finished successfully at 2026-01-23T16:42:29.905.\n\n\n\n\n1.6 Plot and compare the Basin results\nPlot the simulated levels and storages at the diverted section and at the confluence.\n\ndf_basin = pd.read_feather(base_dir / \"Crystal-2/results/basin.arrow\")\n\n# Create pivot tables and plot for basin data\ndf_basin_wide = df_basin.pivot_table(\n    index=\"time\", columns=\"node_id\", values=[\"storage\", \"level\"]\n)\n\ndf_basin_div = df_basin_wide.loc[:, pd.IndexSlice[:, diversion_basin.node_id]]\ndf_basin_conf = df_basin_wide.loc[:, pd.IndexSlice[:, confluence.node_id]]\n\n\ndef plot_basin_data(\n    ax, ax_twin, df_basin, level_color=\"b\", storage_color=\"r\", title=\"Basin\"\n):\n    # Plot level data\n    for column in df_basin[\"level\"].columns:\n        ax.plot(\n            df_basin.index,\n            df_basin[\"level\"][column],\n            linestyle=\"-\",\n            color=level_color,\n            label=f\"Level - {column}\",\n        )\n\n    # Plot storage data\n    for column in df_basin[\"storage\"].columns:\n        ax_twin.plot(\n            df_basin.index,\n            df_basin[\"storage\"][column],\n            linestyle=\"--\",\n            color=storage_color,\n            label=f\"Storage - {column}\",\n        )\n\n    ax.set_ylabel(\"Level [m]\", color=level_color)\n    ax_twin.set_ylabel(\"Storage [m³]\", color=storage_color)\n\n    ax.tick_params(axis=\"y\", labelcolor=level_color)\n    ax_twin.tick_params(axis=\"y\", labelcolor=storage_color)\n\n    ax.set_title(title)\n\n    # Combine legends from both axes\n    lines, labels = ax.get_legend_handles_labels()\n    lines_twin, labels_twin = ax_twin.get_legend_handles_labels()\n    ax.legend(lines + lines_twin, labels + labels_twin, loc=\"upper left\")\n\n\n# Create subplots\nfig, (ax1, ax3) = plt.subplots(2, 1, figsize=(12, 12), sharex=True)\n\n# Plot Div basin data\nax2 = ax1.twinx()  # Secondary y-axis for storage\nplot_basin_data(ax1, ax2, df_basin_div, title=\"Diversion Basin level and storage\")\n\n# Plot Conf basin data\nax4 = ax3.twinx()  # Secondary y-axis for storage\nplot_basin_data(ax3, ax4, df_basin_conf, title=\"Confluence Basin level and storage\")\n\n# Common X label\nax3.set_xlabel(\"Time\")\nfig.tight_layout()  # Adjust layout to fit labels\nplt.show()\n\n\n\n\n\n\n\n\nThe figure above illustrates the water levels and storage capacities for each Basin.\nWhen compared to the natural flow conditions, where no water is abstracted for irrigation (See Crystal 1), there is a noticeable decrease in both storage and water levels at the confluence downstream. This reduction is attributed to the irrigation demand upstream with no return flow, which decreases the amount of available water in the main river, resulting in lower water levels at the confluence.\n\n\n1.7 Plot and compare the flow results\nPlot the flow results in an interactive plotting tool.\n\ndf_flow = pd.read_feather(base_dir / \"Crystal-2/results/flow.arrow\")\n# Add the link names and then remove unnamed links\ndf_flow[\"name\"] = model.link.df[\"name\"].loc[df_flow[\"link_id\"]].to_numpy()\ndf_flow = df_flow[df_flow[\"name\"].astype(bool)]\n\n# Plot the flow data, interactive plot with Plotly\npivot_flow = df_flow.pivot_table(\n    index=\"time\", columns=\"name\", values=\"flow_rate\"\n).reset_index()\nfig = px.line(pivot_flow, x=\"time\", y=pivot_flow.columns[1:], title=\"Flow [m3/s]\")\n\nfig.update_layout(legend_title_text=\"Link\")\nfig.show()\n\n                            \n                                            \n\n\nTry toggling the links on and off by clicking on them in the links.",
    "crumbs": [
      "Getting started",
      "Tutorials",
      "Irrigation demand"
    ]
  },
  {
    "objectID": "changelog.html",
    "href": "changelog.html",
    "title": "1 Changelog",
    "section": "",
    "text": "All notable changes to this project will be documented in this file. The format is based on Keep a Changelog,\n\n\n\n\n\nThis is the first pre-release running up to the stable v2026.1.0 release. It is a release candidate, and we recommend most users to stick with v2025.6.0 for now. We expect to make more breaking changes and add features before the final release. This release sees significant performance increases for the core as well as the QGIS plugin, which especially help large models. Route priority in allocation was added to steer the path taken by allocated water.\nBreaking changes: In the Node table, source_priority has been renamed to route_priority, and the optional active column was removed. Note that Ribasim Python will migrate existing models automatically, see also the new guide on updating Ribasim. If nodes where set to inactive, they will have to be removed manually first. The ribasim executable was moved to the bin subfolder, so users may need to update their PATH or RIBASIM_EXE environment variables.\n\n\n\nAdd Windows installation script. #2682\nAdd ResidenceTime tracer. #2701\nAdd allocation route priorities. #2731\nDocument control by allocation. #2698\nDocument installing QGIS plugin from qgis.org. #2687\nAdd diagram for physical-allocation interaction. #2712\nAdd “getting started” section to documentation. #2734\nExpand saveat documentation for months and years. #2709\nDelwaq: Generate more modular inputs. #2745\nLog full configuration. #2730\nAdd indexes to database for QGIS performance. #2763\nImprove database read performance of the core. #2762\nLet run_ribasim use RIBASIM_EXE if set. #2783\n\n\n\n\n\nOptimize Jacobian computation for large models. #2624 #2685\nAllow replacing/deleting links. #2733\nMove ribasim executable to bin directory. #2758\nRemove feature where nodes can be inactive. #2764\nMake database reproducible by fixing timestamp. #2765\nBy default, all nodes get a subnetwork ID of 1. #2766\nDeprecate run_ribasim’s cli_path for ribasim_exe. #2783\nRename source_priority to route_priority. #2768\n\n\n\n\n\nFix “database disk image is malformed” error. #2763\nFix timing of vertical forcing in allocation. #2739\nFix reading uninitialized memory during allocation. #2691\nValidate Delwaq substance names. #2744\n\n\n\n\n\nThis release brings significant improvements to the QGIS plugin, allocation, and CLI latency. The QGIS plugin is now published in the QGIS plugin repository and has a simplified UI; you can drag a TOML to QGIS to open a model. The black screen in the iMOD plugin is fixed in the latest version of the iMOD plugin, and the Arrow errors on loading results are also fixed.\nIteratively working on a model in a Python session has become easier now that model.&lt;node_type&gt;.add can replace existing nodes, and run_ribasim(toml_path) shows you live progress in all editors.\nBreaking changes: There are two changes that shouldn’t be breaking but might affect some users nonetheless. The input_dir default has been changed to “input”. Python models now forbid any extra values in schema validation for stricter data integrity.\n\n\n\nAdd run_ribasim(toml_path) convenience function. #2653\nAllow replacing nodes with add API. #2664\nFlow communication between primary and secondary networks. #2556\nRead NetCDF files with demand_priority. #2604\nMake reduction factor thresholds configurable. #2592 #2681\nQGIS: Add menu and dropdown interface. #2634\nAdd docs on reloading model in QGIS plugin guide. #2583\nDocument pandas requirement for QGIS plugin. #2642\n\n\n\n\n\nSet input_dir default to “input”. #2641\nPython: Forbid any extra values in (base)model for stricter validation. #2595\nSupport Scientific Python SPEC 0 for broader compatibility. #2630\nQGIS: Always use GDAL instead of pyarrow for better stability. #2591\nPublish QGIS plugin. #2654 #2658\nImproved build performance and compilation. #2652\n\n\n\n\n\nFinalize progress bar. #2665\nFix Junctions with subnetwork ID. #2633\nDelwaq: Restore correct water/mass balance with Junctions. #2607\nDelwaq: Limit endtime for partially failed Ribasim runs. #2637\nDelwaq: Improved performance of flow boundary concatenation. #2597\nFix remaining DelWAQ netCDF warnings. #2621\nFix DataInterpolations integration bug. #2576\nQGIS: Fix empty Arrow results. #2585\nLog clear error on decreasing area in S(h). #2600\nQGIS: Faster results drawing. #2618\nQGIS: Fix crash on Reload Ribasim model. #2661\nReset ribasim_version in model_post_init. #2578\nConvert Path to str with .as_posix() for cross-platform compatibility. #2579\nSupport pydantic 2.12. #2650\n\n\n\n\n\nThis release focuses on improving allocation capabilities and performance optimizations. We linearize the optimization problem, and Pump and Outlets can now listen to allocation to set the flow rate. NetCDF output has been added, as well as experimental support for NetCDF input. DiscreteControl now supports an upper and lower threshold to model hysteresis. Editing models in QGIS is no longer supported; the plugin widget has been reduced one button. The Ribasim Python installation section allows you to pick your favorite package manager. Lastly, Ribasim is now multithreaded!\nBreaking changes: In the DiscreteControl / condition table, greater_than has been renamed to threshold_high, and the optional threshold_low column was added. The surface_runoff column was added to Basin / static and Basin / time. Note that Ribasim Python will migrate existing models automatically, see also the new guide on updating Ribasim.\n\n\n\nAdd surface_runoff to Basin fluxes. #2402\nSupport NetCDF results. #2497\nSupport NetCDF input. #2542\nAdd multithreading. #2562\nImplement hysteresis on DiscreteControl. #2564\nAdd FlowBoundary / area polygons. #2537\nNative multi-objective optimization in allocation. #2522\nAdd control by allocation functionality. #2401\nFlowDemand supports multiple priorities. #2500\nReport cause of infeasibility in allocation problems. #2398 #2481\nAdd convergence and dt to results for performance monitoring. #2405\nWarn when reading a new model with an old Ribasim Python version. #2410\nAdd instructions to install using Pixi. #2415\nAdd guide on updating Ribasim models. #2489\nSupport DiscreteControl listening to a Basin’s storage. #2573\n\n\n\n\n\nAllow two incoming control links for Pump and Outlet. #2531\nUse FlowDemand demand as minimum Pump/Outlet flow when allocation is not active. #2506\nExpand and improve LevelDemand functionality with absolute error handling. #2386 #2515\nAllocation optimization with warm start for better performance. #2466\nScale storage and flow in allocation for numerical stability. #2407\nSwitch from UMFPACK to KLU sparse linear solver for performance. #2391\nUse pandera v0.25, and revert using pyarrow dtypes. #2450\nQGIS: remove editing features for simplified workflow. #2472\nUse smooth interpolation of ContinuousControl and TabulatedRatingCurve functions. #2446 #2458\nUse a Reynolds based threshold for the ManningResistance relaxed root 2544\nDemand nodes with timeseries now use block interpolation 2568\n\n\n\n\n\nCore model initialization speedup. #2548 #2533\nFix validation error on multiple incoming control links. #2535\nImprove error message for DiscreteControl with no data. #2540\nMake convergence finite to avoid numerical issues. #2534\nCache FlowDemand lookup to avoid expensive operations in water_balance!. #2523\nIncrease stacksize on Windows to 8 MB to prevent stack overflow. #2546\nAlign timestep allocated and realized results in allocation.arrow. #2554\nSupport GeoPandas 1.1. #2547\n\n\n\n\n\nThis release had a big push on the stability and performance for large models. Users can now also provide a level-storage relation in Basin / profile. This means old models need to be migrated by reading them into Ribasim Python, and writing them out. We are working on reformulating the allocation problem. Until this work is finished, allocation remains an experimental feature of Ribasim.\n\n\n\nReload Ribasim model in QGIS. #2307\nSupport storage column in Basin / profile #2278\nAllow Junction to Terminal links. #2295\nAdd model performance debugging guide #2308\nMake FlowBoundary interpolation method configurable #2285\nOutput interpolated Basin / profile in debug mode #2344\nWrite log file via BMI #2370\n\n\n\n\n\nReformulate the allocation problem. #2266\nMark allocation as experimental. #2266\nLow storage threshold based on 10 cm depth #2357\nStability: decrease relative tolerance over time. #2277\nUse block interpolation for FlowBoundary by default #2285\nRemove backtracking, add more caching #2359\nMore realistic smoothing around Δh = 0 in ManningResistance. #2365\n\n\n\n\n\nFix writing results on saveat = 0 #2305\nFix error in flow limiter #2334\nFix cyclic Basin forcing #2313\nBMI: return 1 on update if solve not successful #2341\n\n\n\n\n\nThe only breaking change in this release is to disallow connecting a single FlowBoundary to multiple Basins. There are large improvements in the ability to visualize results on the map in QGIS. We also welcome the Junction node to the family, which will help laying out networks in a recognizable manner.\n\n\n\nAdd spatio-temporal results layers to QGIS. #2208\nAdd topological (straight line) link view toggle to QGIS. #2208\nAdded Junction node type. #2175\nWrite results and log bottlenecks also on an interrupt or crash. #2191 #2200\nLog computation time and save it to solver_stats.arrow. #2209\nExperimental support for writing the model network and results into files used by Delft-FEWS, model.to_fews. #2161\nDocument results/concentration.arrow. #2165\n\n\n\n\n\nAllow max 1 outflow neighbour for FlowBoundary. #2192\nAutomatic differentiation is enabled by default again, autodiff = true, leading to better performance. #2137 #2183\n\n\n\n\n\nIn this release, time is of the essence. We now support dynamic Pumps and Outlets, as well as DiscreteControl thresholds. For each node, timeseries can be marked as cyclic, such that yearly recurring timeseries can be easily used without repetition. We also developed tools to compare model input in Python.\nThe most visible change is the renaming of Edge to Link. Like always, existing models are migrated to the new version by reading them with Ribasim Python, and writing out the updated version. For now in Python model.edge will continue to work to ease the transition.\n\n\n\nCheck Model equality in Python. #2057\nCompare two models in Python. #2080\nSupport cyclic input timeseries. #2081 #2102\nTime dependent threshold_high thresholds in DiscreteControl. #2079\nValidation error on connector nodes having the same from and to Basin. #2112\nSupport time dependent Pump and Outlet tables. #2110\n\n\n\n\n\nEdges are now called links. #2023\nAll geometries are coerced to 2D. #2111\n\n\n\n\n\nFaster initialization of large tables. #2026\nDeclare incompatibility with Pandera v0.23+. #2120\nDecrease the smoothing around Δh = 0 in ManningResistance. #2136\n\n\n\n\n\nThe first release of 2025 makes the Ribasim core more robust and stable, and speeds up initialization for large models. The biggest new feature is the experimental support for calculating tracers in Ribasim directly, which will hopefully make it easier to track where the water resources are heading.\n\n\n\nRemove Z coordinate on constructing Node in Python. #1986\nAdd “Basin / subgrid_time” table. #1975\nSign Ribasim binaries. #2007\nExperimental: Calculate tracer concentrations internally. #1849\nDocument parsing Delwaq results. #1845\n\n\n\n\n\nDrop Python 3.10 support. #2012\n\n\n\n\n\nAllocation: optimize per source. #1927\nThe Edge table no longer supports subnetwork_id; this is automatically inferred. #1956\n\n\n\n\n\nManningResistance is more stable around Δh=0. #1896\nFixes to Delwaq model generation. #1903 #1917 #1948\nAdd step limiter to avoid negative flows or too large flows. #1911 #1912\nFix README.md in builds. #1935 #1938\nSpeed up initialization. #1977\nAutomatically name index in Python. #1974\nTable sorting related fixes. #2003\n\n\n\n\n\nThis major new release contains many improvements. A new formulation allows much smaller water balance errors, which is combined with several performance improvements. Ribasim Python does more validation that was previously only done in the core. The Ribasim QGIS plugin now sets the relations between tables for easier model inspection. Adding min_upstream_level and max_downstream_level to Pump and Outlet means DiscreteControl is often no longer needed. The most significant breaking change is making the node_id and edge_id the index of the Node and Edge table; these need to be globally unique.\nStarting from this release Ribasim is labeled as beta software. Since development is currently mainly driven by applications in the Dutch water system, we expect that addition work needs to be done for general use outside the Netherlands.\nFor coupled simulation with MODFLOW and/or MetaSWAP, this release is part of the iMOD Coupler, specifically release v2024.4.0\n\n\n\nSupport discrete control based on an external concentration condition. #1660\nAdd results/solver_stats.arrow with solver statistics over time. #1677\nAdd icon to ribasim.exe on Windows. #1712\nSave QGIS styling in the model database. #1713\nAdd Delwaq coupling guide. #1619\nSolver speedup due to backtracking relaxation. #1761\nReject adding a duplicate edge in Python. #1719\nSupport transient UserDemand return factor. #1727\nDocument the interpolation of input data. #1720\nAutomate Jacobian sparsity detection. #1606\nSupport specifying the edge_id as model.edge.add(a, b, edge_id=5). #1737\nUse https://ribasim.org/ to host our documentation. #1736\nValidate geometry types in Python. #1760\nAdd relationships between tables in QGIS. #1755\nSupport migrating from older Ribasim versions in Python. #1764\nAdd quick start guide to docs. #1787\nAdd min_upstream_level and max_downstream_level to Pump and Outlet. #1792\nAdd max_downstream_level to TabulatedRatingCurve. #1795\nValidate edge connections in Python. #1765\nAdd low storage reduction factor to ManningResistance. #1796\n\n\n\n\n\nRefactor of the core to ensure smaller water balance errors. #1819\nMake node_id globally unique. #1717\nMake the Node ID the index of the Node table, and Edge ID for Edge. #1737\nMake more Python functions private. #1702\nPut the contents of the CLI zips in a folder. #1722\nChanged water balance error definition. #1767\nDisallow missing priority parameter when using allocation. #1745\nRename Outlet’s min_crest_level to min_upstream_level. #1788\nOnly allow flow under gravity in TabulatedRatingCurve. #1795\nUse dtype_backend=\"pyarrow\" for Pandas DataFrames. #1781\n\n\n\n\n\nRemove oscillations in ManningResistance. #1750\nFix GeoPandas CRS warning. #1810\n\n\n\n\n\nFor this release we said goodbye to the problematic FractionalFlow node, but welcome the ContinuousControl as a long requested feature.\n\n\n\nControl: Add ContinuousControl node type. #1602\nControl: Support listening to flow through connector nodes. #1594\nValidate that TabulatedRatingCurve levels are above Basin bottom. #1607\nValidate that Outlet minimum upstream levels are above Basin bottom. #1607\nAlways show convergence bottlenecks. #1636\nDocstrings for Ribasim Python. #1643\nAllocate to UserDemand from directly connected Basin if possible. #1581\nAdd basin_state.arrow results. #1626\nAlso write stacktraces to ribasim.log. #1653\n\n\n\n\n\nRequire QGIS 3.34 (LTR) or newer for Ribasim QGIS plugin.\n\n\n\n\n\nCompatibility with latest NumPy, Pandera and PyArrow releases. #1618\nLevelDemand can now be without min_level or max_level. #1629\n\n\n\n\n\nRemoved unused urban runoff variable from Basin. #1611\nRemoved unneeded static table from Terminal. #1624\nRemoved FractionalFlow node. #1616\n\n\n\n\n\n\n\n\nSupport for concentration state and time for Delwaq coupling.\nShow exact commit on ribasim --version if it is not a release. #1479\n\n\n\n\n\nOptimized performance.\nDocumentation has been overhauled to be more user-friendly.\nStricter TabulatedRatingCurve validation. #1469\nStricter Basin / profile validation. #1486\nAllocation objective function now gives equal ratios during shortage. #1386\n\n\n\n\n\nDon’t require unique node IDs. #1513\nFix QGIS crash on plugin initialization. #1580\n\n\n\n\n\n\n\n\nThere is more validation on the edges. #1434\nIf the model does not converge and the used algorithm supports it, we log which Basins don’t converge. #1440\n\n\n\n\n\nIf negative storages inadvertently happen, we now throw an error. #1425\nUsers of the QGIS plugin need to remove the old version to avoid two copies due to #1453.\n\n\n\n\n\nPerformance improvements have been a focus of this release, giving up to 10x faster runs. #1433, #1436, #1438, #1448, #1457\nThe CLI exe is now always in the root of the zip and makes use of the libribasim shared library. #1415",
    "crumbs": [
      "Overview",
      "Changelog"
    ]
  },
  {
    "objectID": "changelog.html#v2026.1.0-rc1---2025-12-23",
    "href": "changelog.html#v2026.1.0-rc1---2025-12-23",
    "title": "1 Changelog",
    "section": "",
    "text": "This is the first pre-release running up to the stable v2026.1.0 release. It is a release candidate, and we recommend most users to stick with v2025.6.0 for now. We expect to make more breaking changes and add features before the final release. This release sees significant performance increases for the core as well as the QGIS plugin, which especially help large models. Route priority in allocation was added to steer the path taken by allocated water.\nBreaking changes: In the Node table, source_priority has been renamed to route_priority, and the optional active column was removed. Note that Ribasim Python will migrate existing models automatically, see also the new guide on updating Ribasim. If nodes where set to inactive, they will have to be removed manually first. The ribasim executable was moved to the bin subfolder, so users may need to update their PATH or RIBASIM_EXE environment variables.\n\n\n\nAdd Windows installation script. #2682\nAdd ResidenceTime tracer. #2701\nAdd allocation route priorities. #2731\nDocument control by allocation. #2698\nDocument installing QGIS plugin from qgis.org. #2687\nAdd diagram for physical-allocation interaction. #2712\nAdd “getting started” section to documentation. #2734\nExpand saveat documentation for months and years. #2709\nDelwaq: Generate more modular inputs. #2745\nLog full configuration. #2730\nAdd indexes to database for QGIS performance. #2763\nImprove database read performance of the core. #2762\nLet run_ribasim use RIBASIM_EXE if set. #2783\n\n\n\n\n\nOptimize Jacobian computation for large models. #2624 #2685\nAllow replacing/deleting links. #2733\nMove ribasim executable to bin directory. #2758\nRemove feature where nodes can be inactive. #2764\nMake database reproducible by fixing timestamp. #2765\nBy default, all nodes get a subnetwork ID of 1. #2766\nDeprecate run_ribasim’s cli_path for ribasim_exe. #2783\nRename source_priority to route_priority. #2768\n\n\n\n\n\nFix “database disk image is malformed” error. #2763\nFix timing of vertical forcing in allocation. #2739\nFix reading uninitialized memory during allocation. #2691\nValidate Delwaq substance names. #2744",
    "crumbs": [
      "Overview",
      "Changelog"
    ]
  },
  {
    "objectID": "changelog.html#v2025.6.0---2025-10-27",
    "href": "changelog.html#v2025.6.0---2025-10-27",
    "title": "1 Changelog",
    "section": "",
    "text": "This release brings significant improvements to the QGIS plugin, allocation, and CLI latency. The QGIS plugin is now published in the QGIS plugin repository and has a simplified UI; you can drag a TOML to QGIS to open a model. The black screen in the iMOD plugin is fixed in the latest version of the iMOD plugin, and the Arrow errors on loading results are also fixed.\nIteratively working on a model in a Python session has become easier now that model.&lt;node_type&gt;.add can replace existing nodes, and run_ribasim(toml_path) shows you live progress in all editors.\nBreaking changes: There are two changes that shouldn’t be breaking but might affect some users nonetheless. The input_dir default has been changed to “input”. Python models now forbid any extra values in schema validation for stricter data integrity.\n\n\n\nAdd run_ribasim(toml_path) convenience function. #2653\nAllow replacing nodes with add API. #2664\nFlow communication between primary and secondary networks. #2556\nRead NetCDF files with demand_priority. #2604\nMake reduction factor thresholds configurable. #2592 #2681\nQGIS: Add menu and dropdown interface. #2634\nAdd docs on reloading model in QGIS plugin guide. #2583\nDocument pandas requirement for QGIS plugin. #2642\n\n\n\n\n\nSet input_dir default to “input”. #2641\nPython: Forbid any extra values in (base)model for stricter validation. #2595\nSupport Scientific Python SPEC 0 for broader compatibility. #2630\nQGIS: Always use GDAL instead of pyarrow for better stability. #2591\nPublish QGIS plugin. #2654 #2658\nImproved build performance and compilation. #2652\n\n\n\n\n\nFinalize progress bar. #2665\nFix Junctions with subnetwork ID. #2633\nDelwaq: Restore correct water/mass balance with Junctions. #2607\nDelwaq: Limit endtime for partially failed Ribasim runs. #2637\nDelwaq: Improved performance of flow boundary concatenation. #2597\nFix remaining DelWAQ netCDF warnings. #2621\nFix DataInterpolations integration bug. #2576\nQGIS: Fix empty Arrow results. #2585\nLog clear error on decreasing area in S(h). #2600\nQGIS: Faster results drawing. #2618\nQGIS: Fix crash on Reload Ribasim model. #2661\nReset ribasim_version in model_post_init. #2578\nConvert Path to str with .as_posix() for cross-platform compatibility. #2579\nSupport pydantic 2.12. #2650",
    "crumbs": [
      "Overview",
      "Changelog"
    ]
  },
  {
    "objectID": "changelog.html#v2025.5.0---2025-09-09",
    "href": "changelog.html#v2025.5.0---2025-09-09",
    "title": "1 Changelog",
    "section": "",
    "text": "This release focuses on improving allocation capabilities and performance optimizations. We linearize the optimization problem, and Pump and Outlets can now listen to allocation to set the flow rate. NetCDF output has been added, as well as experimental support for NetCDF input. DiscreteControl now supports an upper and lower threshold to model hysteresis. Editing models in QGIS is no longer supported; the plugin widget has been reduced one button. The Ribasim Python installation section allows you to pick your favorite package manager. Lastly, Ribasim is now multithreaded!\nBreaking changes: In the DiscreteControl / condition table, greater_than has been renamed to threshold_high, and the optional threshold_low column was added. The surface_runoff column was added to Basin / static and Basin / time. Note that Ribasim Python will migrate existing models automatically, see also the new guide on updating Ribasim.\n\n\n\nAdd surface_runoff to Basin fluxes. #2402\nSupport NetCDF results. #2497\nSupport NetCDF input. #2542\nAdd multithreading. #2562\nImplement hysteresis on DiscreteControl. #2564\nAdd FlowBoundary / area polygons. #2537\nNative multi-objective optimization in allocation. #2522\nAdd control by allocation functionality. #2401\nFlowDemand supports multiple priorities. #2500\nReport cause of infeasibility in allocation problems. #2398 #2481\nAdd convergence and dt to results for performance monitoring. #2405\nWarn when reading a new model with an old Ribasim Python version. #2410\nAdd instructions to install using Pixi. #2415\nAdd guide on updating Ribasim models. #2489\nSupport DiscreteControl listening to a Basin’s storage. #2573\n\n\n\n\n\nAllow two incoming control links for Pump and Outlet. #2531\nUse FlowDemand demand as minimum Pump/Outlet flow when allocation is not active. #2506\nExpand and improve LevelDemand functionality with absolute error handling. #2386 #2515\nAllocation optimization with warm start for better performance. #2466\nScale storage and flow in allocation for numerical stability. #2407\nSwitch from UMFPACK to KLU sparse linear solver for performance. #2391\nUse pandera v0.25, and revert using pyarrow dtypes. #2450\nQGIS: remove editing features for simplified workflow. #2472\nUse smooth interpolation of ContinuousControl and TabulatedRatingCurve functions. #2446 #2458\nUse a Reynolds based threshold for the ManningResistance relaxed root 2544\nDemand nodes with timeseries now use block interpolation 2568\n\n\n\n\n\nCore model initialization speedup. #2548 #2533\nFix validation error on multiple incoming control links. #2535\nImprove error message for DiscreteControl with no data. #2540\nMake convergence finite to avoid numerical issues. #2534\nCache FlowDemand lookup to avoid expensive operations in water_balance!. #2523\nIncrease stacksize on Windows to 8 MB to prevent stack overflow. #2546\nAlign timestep allocated and realized results in allocation.arrow. #2554\nSupport GeoPandas 1.1. #2547",
    "crumbs": [
      "Overview",
      "Changelog"
    ]
  },
  {
    "objectID": "changelog.html#v2025.4.0---2025-06-16",
    "href": "changelog.html#v2025.4.0---2025-06-16",
    "title": "1 Changelog",
    "section": "",
    "text": "This release had a big push on the stability and performance for large models. Users can now also provide a level-storage relation in Basin / profile. This means old models need to be migrated by reading them into Ribasim Python, and writing them out. We are working on reformulating the allocation problem. Until this work is finished, allocation remains an experimental feature of Ribasim.\n\n\n\nReload Ribasim model in QGIS. #2307\nSupport storage column in Basin / profile #2278\nAllow Junction to Terminal links. #2295\nAdd model performance debugging guide #2308\nMake FlowBoundary interpolation method configurable #2285\nOutput interpolated Basin / profile in debug mode #2344\nWrite log file via BMI #2370\n\n\n\n\n\nReformulate the allocation problem. #2266\nMark allocation as experimental. #2266\nLow storage threshold based on 10 cm depth #2357\nStability: decrease relative tolerance over time. #2277\nUse block interpolation for FlowBoundary by default #2285\nRemove backtracking, add more caching #2359\nMore realistic smoothing around Δh = 0 in ManningResistance. #2365\n\n\n\n\n\nFix writing results on saveat = 0 #2305\nFix error in flow limiter #2334\nFix cyclic Basin forcing #2313\nBMI: return 1 on update if solve not successful #2341",
    "crumbs": [
      "Overview",
      "Changelog"
    ]
  },
  {
    "objectID": "changelog.html#v2025.3.0---2025-04-14",
    "href": "changelog.html#v2025.3.0---2025-04-14",
    "title": "1 Changelog",
    "section": "",
    "text": "The only breaking change in this release is to disallow connecting a single FlowBoundary to multiple Basins. There are large improvements in the ability to visualize results on the map in QGIS. We also welcome the Junction node to the family, which will help laying out networks in a recognizable manner.\n\n\n\nAdd spatio-temporal results layers to QGIS. #2208\nAdd topological (straight line) link view toggle to QGIS. #2208\nAdded Junction node type. #2175\nWrite results and log bottlenecks also on an interrupt or crash. #2191 #2200\nLog computation time and save it to solver_stats.arrow. #2209\nExperimental support for writing the model network and results into files used by Delft-FEWS, model.to_fews. #2161\nDocument results/concentration.arrow. #2165\n\n\n\n\n\nAllow max 1 outflow neighbour for FlowBoundary. #2192\nAutomatic differentiation is enabled by default again, autodiff = true, leading to better performance. #2137 #2183",
    "crumbs": [
      "Overview",
      "Changelog"
    ]
  },
  {
    "objectID": "changelog.html#v2025.2.0---2025-03-10",
    "href": "changelog.html#v2025.2.0---2025-03-10",
    "title": "1 Changelog",
    "section": "",
    "text": "In this release, time is of the essence. We now support dynamic Pumps and Outlets, as well as DiscreteControl thresholds. For each node, timeseries can be marked as cyclic, such that yearly recurring timeseries can be easily used without repetition. We also developed tools to compare model input in Python.\nThe most visible change is the renaming of Edge to Link. Like always, existing models are migrated to the new version by reading them with Ribasim Python, and writing out the updated version. For now in Python model.edge will continue to work to ease the transition.\n\n\n\nCheck Model equality in Python. #2057\nCompare two models in Python. #2080\nSupport cyclic input timeseries. #2081 #2102\nTime dependent threshold_high thresholds in DiscreteControl. #2079\nValidation error on connector nodes having the same from and to Basin. #2112\nSupport time dependent Pump and Outlet tables. #2110\n\n\n\n\n\nEdges are now called links. #2023\nAll geometries are coerced to 2D. #2111\n\n\n\n\n\nFaster initialization of large tables. #2026\nDeclare incompatibility with Pandera v0.23+. #2120\nDecrease the smoothing around Δh = 0 in ManningResistance. #2136",
    "crumbs": [
      "Overview",
      "Changelog"
    ]
  },
  {
    "objectID": "changelog.html#v2025.1.0---2025-01-17",
    "href": "changelog.html#v2025.1.0---2025-01-17",
    "title": "1 Changelog",
    "section": "",
    "text": "The first release of 2025 makes the Ribasim core more robust and stable, and speeds up initialization for large models. The biggest new feature is the experimental support for calculating tracers in Ribasim directly, which will hopefully make it easier to track where the water resources are heading.\n\n\n\nRemove Z coordinate on constructing Node in Python. #1986\nAdd “Basin / subgrid_time” table. #1975\nSign Ribasim binaries. #2007\nExperimental: Calculate tracer concentrations internally. #1849\nDocument parsing Delwaq results. #1845\n\n\n\n\n\nDrop Python 3.10 support. #2012\n\n\n\n\n\nAllocation: optimize per source. #1927\nThe Edge table no longer supports subnetwork_id; this is automatically inferred. #1956\n\n\n\n\n\nManningResistance is more stable around Δh=0. #1896\nFixes to Delwaq model generation. #1903 #1917 #1948\nAdd step limiter to avoid negative flows or too large flows. #1911 #1912\nFix README.md in builds. #1935 #1938\nSpeed up initialization. #1977\nAutomatically name index in Python. #1974\nTable sorting related fixes. #2003",
    "crumbs": [
      "Overview",
      "Changelog"
    ]
  },
  {
    "objectID": "changelog.html#v2024.11.0---2024-10-08",
    "href": "changelog.html#v2024.11.0---2024-10-08",
    "title": "1 Changelog",
    "section": "",
    "text": "This major new release contains many improvements. A new formulation allows much smaller water balance errors, which is combined with several performance improvements. Ribasim Python does more validation that was previously only done in the core. The Ribasim QGIS plugin now sets the relations between tables for easier model inspection. Adding min_upstream_level and max_downstream_level to Pump and Outlet means DiscreteControl is often no longer needed. The most significant breaking change is making the node_id and edge_id the index of the Node and Edge table; these need to be globally unique.\nStarting from this release Ribasim is labeled as beta software. Since development is currently mainly driven by applications in the Dutch water system, we expect that addition work needs to be done for general use outside the Netherlands.\nFor coupled simulation with MODFLOW and/or MetaSWAP, this release is part of the iMOD Coupler, specifically release v2024.4.0\n\n\n\nSupport discrete control based on an external concentration condition. #1660\nAdd results/solver_stats.arrow with solver statistics over time. #1677\nAdd icon to ribasim.exe on Windows. #1712\nSave QGIS styling in the model database. #1713\nAdd Delwaq coupling guide. #1619\nSolver speedup due to backtracking relaxation. #1761\nReject adding a duplicate edge in Python. #1719\nSupport transient UserDemand return factor. #1727\nDocument the interpolation of input data. #1720\nAutomate Jacobian sparsity detection. #1606\nSupport specifying the edge_id as model.edge.add(a, b, edge_id=5). #1737\nUse https://ribasim.org/ to host our documentation. #1736\nValidate geometry types in Python. #1760\nAdd relationships between tables in QGIS. #1755\nSupport migrating from older Ribasim versions in Python. #1764\nAdd quick start guide to docs. #1787\nAdd min_upstream_level and max_downstream_level to Pump and Outlet. #1792\nAdd max_downstream_level to TabulatedRatingCurve. #1795\nValidate edge connections in Python. #1765\nAdd low storage reduction factor to ManningResistance. #1796\n\n\n\n\n\nRefactor of the core to ensure smaller water balance errors. #1819\nMake node_id globally unique. #1717\nMake the Node ID the index of the Node table, and Edge ID for Edge. #1737\nMake more Python functions private. #1702\nPut the contents of the CLI zips in a folder. #1722\nChanged water balance error definition. #1767\nDisallow missing priority parameter when using allocation. #1745\nRename Outlet’s min_crest_level to min_upstream_level. #1788\nOnly allow flow under gravity in TabulatedRatingCurve. #1795\nUse dtype_backend=\"pyarrow\" for Pandas DataFrames. #1781\n\n\n\n\n\nRemove oscillations in ManningResistance. #1750\nFix GeoPandas CRS warning. #1810",
    "crumbs": [
      "Overview",
      "Changelog"
    ]
  },
  {
    "objectID": "changelog.html#v2024.10.0---2024-07-23",
    "href": "changelog.html#v2024.10.0---2024-07-23",
    "title": "1 Changelog",
    "section": "",
    "text": "For this release we said goodbye to the problematic FractionalFlow node, but welcome the ContinuousControl as a long requested feature.\n\n\n\nControl: Add ContinuousControl node type. #1602\nControl: Support listening to flow through connector nodes. #1594\nValidate that TabulatedRatingCurve levels are above Basin bottom. #1607\nValidate that Outlet minimum upstream levels are above Basin bottom. #1607\nAlways show convergence bottlenecks. #1636\nDocstrings for Ribasim Python. #1643\nAllocate to UserDemand from directly connected Basin if possible. #1581\nAdd basin_state.arrow results. #1626\nAlso write stacktraces to ribasim.log. #1653\n\n\n\n\n\nRequire QGIS 3.34 (LTR) or newer for Ribasim QGIS plugin.\n\n\n\n\n\nCompatibility with latest NumPy, Pandera and PyArrow releases. #1618\nLevelDemand can now be without min_level or max_level. #1629\n\n\n\n\n\nRemoved unused urban runoff variable from Basin. #1611\nRemoved unneeded static table from Terminal. #1624\nRemoved FractionalFlow node. #1616",
    "crumbs": [
      "Overview",
      "Changelog"
    ]
  },
  {
    "objectID": "changelog.html#v2024.9.0---2024-06-20",
    "href": "changelog.html#v2024.9.0---2024-06-20",
    "title": "1 Changelog",
    "section": "",
    "text": "Support for concentration state and time for Delwaq coupling.\nShow exact commit on ribasim --version if it is not a release. #1479\n\n\n\n\n\nOptimized performance.\nDocumentation has been overhauled to be more user-friendly.\nStricter TabulatedRatingCurve validation. #1469\nStricter Basin / profile validation. #1486\nAllocation objective function now gives equal ratios during shortage. #1386\n\n\n\n\n\nDon’t require unique node IDs. #1513\nFix QGIS crash on plugin initialization. #1580",
    "crumbs": [
      "Overview",
      "Changelog"
    ]
  },
  {
    "objectID": "changelog.html#v2024.8.0---2024-05-14",
    "href": "changelog.html#v2024.8.0---2024-05-14",
    "title": "1 Changelog",
    "section": "",
    "text": "There is more validation on the edges. #1434\nIf the model does not converge and the used algorithm supports it, we log which Basins don’t converge. #1440\n\n\n\n\n\nIf negative storages inadvertently happen, we now throw an error. #1425\nUsers of the QGIS plugin need to remove the old version to avoid two copies due to #1453.\n\n\n\n\n\nPerformance improvements have been a focus of this release, giving up to 10x faster runs. #1433, #1436, #1438, #1448, #1457\nThe CLI exe is now always in the root of the zip and makes use of the libribasim shared library. #1415",
    "crumbs": [
      "Overview",
      "Changelog"
    ]
  }
]